{"pages":[{"title":"","text":"Hello there! My name is Mark Cao. 👋 🤓I make professional 🍏macOS &amp;📱iOS Apps for a living now and also Write some blogs. 🌈 💻 Interested in full stack. Recent focus on RTC(Real-Time Communication). 👨‍🎓 With 4 years’ computer science and technology education and 9 years’ development working experience. 🎓 Master of Science in Software Engineering, B.S. in Computer Science. Major GPA 3.75/4.0, TOP 5%. 💼 Used to be a Staff Engineer at Aneesoft.cn, but now I’m a Indie developer. 🌱 Currently learning WebRTC, C++, STL, Math &amp; Psychology. 📚 Reading 《Effective Modern C++》《Effective STL》《H.264 MPEG-4 Part 10 White Paper》《新一代视频压缩编码标准H.264AVC 第2版》. ✍🏻 Writing my personal thoughts on Programming &amp; Tech &amp; daily life in my Personal Blog. 🏋 When I’m not developing and coding, you can find me in GYM, accompanying my family, watching movies or reading books.","link":"/about/index.html"}],"posts":[{"title":"++i和i++的区别","text":"简述二者的区别本质上在于++i属于左值操作，而i++属于右值操作，可分以下几种情况分析： 只有自增操作 如果只用于自增操作，++i和i++经过编译器优化之后其实是等价的，以下是二者的汇编代码（编译器为x86-64 gcc 11.2）： 123456789101112131415161718192021222324252627282930// 源代码void f1(int i) { ++i;}void f2(int i) { i++;}// 汇编代码f1(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi // 形参i赋值 add DWORD PTR [rbp-4], 1 // ++i nop pop rbp retf2(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi // 形参i赋值 add DWORD PTR [rbp-4], 1 // i++ nop pop rbp ret 此处，i++被编译优化后变成了左值操作，因此二者的汇编代码相同。那么在这种情况下它们的执行速度也是一样的。 自增后赋值 如果自增后再赋值，编译器将严格安装二者的左右值属性进行操作，比如： 123456789101112131415161718192021222324252627282930313233// 源代码void f1(int i) { i = ++i;}void f2(int i) { i = i++;}// 汇编代码f1(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi add DWORD PTR [rbp-4], 1 // ++i仍使用一行汇编指令即可完成自增和赋值 nop pop rbp retf2(int): push rbp mov rbp, rsp mov DWORD PTR [rbp-4], edi // i++则会被拆分成3条汇编指令： mov eax, DWORD PTR [rbp-4] // 右值操作：读取i值，存入临时变量中，即寄存器eax lea edx, [rax+1] // 寄存器自增加1 mov DWORD PTR [rbp-4], edx // 将自增后的右值赋值给形参i（i是左值） mov DWORD PTR [rbp-4], eax nop pop rbp ret 由于i++对应三条汇编指令，而++i只有一条汇编指令，因此这种情况下，++i的执行速度会快于 i++。 此外，由于i++会被拆分成3条汇编指令，因此在未加锁的多线程环境下，三条指令执行中可能会因为线程切换而出现中断，进而导致计算结果未知。而由于++i只有一条汇编指令，因++i还可避免因为i++引入的竞争问题。 扩展 计算 i++ + i++ 1234int i = 1;i++ + i++ = 3; // 从左往右：先执行第一个i++，返回值为字面量1，此时i = 1 + 1 = 2， // 再执行第二个i++，返回值为字面量2，此时i = 2 + 1 = 3， // 最后两个返回值相加，1 + 2 = 3 计算 ++i + i++ 和 i++ + ++i 1234567891011// ++i + i++ int i = 1;++i + i++ = 5; // 从左往右：先执行++i，返回值是i的引用r，此时i自增一次值为2 // 再执行i++，返回值为字面量2，此时i经过两次自增后值为3 // 最后两个返回值相加，r + 2 = 3 + 2 = 5// i++ + ++iint i = 1;i++ + ++i = 3; // 从左往右：先执行i++，返回值为字面量1，此时i = 2， // 在执行++i，返回值为i的引用r，此时i经过两次自增后值为3， // 最后两个返回值相加：1 + r = 1 + 3 = 4 计算 ++i + ++i 1234int i = 1;++i + ++i = 6; // 从左往右：先执行第一个++i，返回值是i的引用r1， // 再执行第二个++i，返回值为i的引用r2，此时i经过两次自增后值为3， // 最后两个返回值相加，3 + 3 = 6 计算 ++i + ++i + ++i 12345678910int i = 1;++i + ++i + ++i = 10; // 从左往右：先执行第一个++i，返回值是i的引用r1， // 再执行第二个++i，返回值是i的引用r2，此时i经过两次自增后值为3， // 此时对两个返回值相加，返回值为字面量a：r1 + r2 = 6， // 然后执行第三个++i，返回值是i的引用r3，此时i经过三次自增后值为4， // 最后执行第二个加法：a + r3 = 6 + 4 = 10 // 同理可得int i = 1;i += ++i + ++i + ++i = 4 + 10 = 14;","link":"/2020/01/07/++i%E5%92%8Ci++%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"C++之引用和指针的区别","text":"面试时被问到的一个问题，回答得不够全面，算是查漏补缺。 简述我一直都有一个疑问，为什么在C++中有了指针还要引用？在Stroustrup: C++ Style and Technique FAQ中给出了回复，原文如下： C++ inherited pointers from C, so I couldn’t remove them without causing serious compatibility problems. References are useful for several things, but the direct reason I introduced them in C++ was to support operator overloading. 翻译：C++中指针继承自C语言，出于兼容的原因保留了下来。引用的用处很多，但是C++引入它最直接的原因是为了支持运算符重载。 举例： 12345678910111213// 使用指针A operator+(const A* lhs, const A* rhs) { return *lhs + *rhs; // ugly}// 调用A a = &amp;b + &amp;c; // ugly// 使用引用A operator+(const A&amp; lhs, const A&amp; rhs) { return lhs + rhs; // better}// 调用A a = b + c; // better 比较以下是C++中指针和引用的一些主要区别： 变量绑定 指针可多次绑定同一类型的不同变量。 12345678int a = 3;int b = 7;int* ptr;ptr = &amp;a;ptr = &amp;b;*p = 9;assert(a == 3);assert(b == 9); 引用必须在初始化时完成绑定，且不可再次绑定其他任何变量。 1234int a = 3;int b = 7;int&amp; ref; // Error! A reference MUST be bound at initialization.int&amp; ref = x; // OK. 初始值 指针可初始化为nullptr。 引用理论上则必须绑定某个非空的对象。引用其实也可强制绑定到nullptr，但属于行为未知的操作，如下： 12345/* The code above is undefined. Your compiler may optimise it * differently: emit warnings or refuse to compile it. */// Having a reference to a pointer whose value is nullptr.int &amp;ref = *static_cast&lt;int *&gt;(nullptr); 内存分配 指针本质是一个变量，同普通变量一样被分配内存空间，且可通过一元操作符&amp;获取内存地址，可通过sizeof获得内存大小。 引用可理解为一个变量的别名，同临时变量一样其内存地址和空间大小是不可见的。对引用的操作都会直接作用于其所绑定的变量上，比如：使用一元操作符&amp;获取的其绑定变量的内存地址，使用sizeof获得的是其绑定变量的内存大小。 1234567int a = 1;int&amp; ref = a;int* ptr = &amp;a;int* ptr2 = &amp;ref;assert(ptr == ptr2); // &amp;a == &amp;refassert(&amp;ptr != &amp;ptr2); // Each pointer variable has its own memory address. 嵌套使用 指针可无限嵌套使用，即一级指针，二级指针等。 引用不可嵌套使用，即只有一级引用。 123456789101112int a = 1;int b = 2;int* ptr = &amp;a;int* ptr2 = &amp;b;int** pptr = &amp;ptr;**pptr = 3;pptr = &amp;ptr2; // *pptr is ptr2 now.**pptr = 4;assert(a == 3);assert(b == 4); 自我迭代 指针可作为数组的迭代器，其步幅是指针本身的长度，与指针指向的类型无关。比如可通过自增操作符++指向数组中下一个元素，亦或通过+3操作跳转到第4个元素。 引用的内存地址是访问的，因此对引用的任何操作最终都会作用于其绑定的对象上。 使用方式 访问指针所指向的内存空间需使用一元操作符“*”，操作指针所指向的对象需使用一元操作符“→”。 访问引用所绑定的对象可直接访问，操作引用所绑定的对象需使用一元操作符“.”。 数组存储 指针可作为数组元素。 引用则不能作为数组元素。 右值绑定 指针不可指向右值内存空间。 引用可绑定右值，比如临时对象。 12const int&amp; ref = int(10); // Legal in C++.int* ptr = &amp;int(10); // Illegal to take the address of temporaty. 参考资料What are the differences between a pointer variable and a reference variable in C++? Stroustrup: C++ Style and Technique FAQ","link":"/2022/04/20/C++%E4%B9%8B%E5%BC%95%E7%94%A8%E5%92%8C%E6%8C%87%E9%92%88%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"Cocoa RunLoop 系列之基础知识","text":"这篇博客主要结合Apple开发者文档和个人的理解，写的一篇关于Cocoa RunLoop基本知识点的文章。在文档的基础上，概况和梳理了RunLoop相关的知识点。 一、Event Loop &amp; Cocoa RunLoop宏观上：Event Loop RunLoop是一个用于循环监听和处理事件或者消息的模型，接收请求，然后派发给相关的处理模块，wikipedia上有更为全面的介绍：Event_loop Cocoa RunLoop属于Event Loop模型在Mac平台的具体实现 其他平台的类似实现：X Window程序，Windows程序 ，Glib库等 微观上: Cocoa RunLoop Cocoa RunLoop本质上就是一个对象，提供一个入口函数启动事件循环，在满足特点条件后才会退出。 Cocoa RunLoop与普通while/for循环不同的是它能监听处理事件和消息，能智能休眠和被唤醒，这些功能的其实现依赖于Mac Port。 二、 Cocoa RunLoop的内部结构但凡说到Cocoa RunLoop内部结构，都离不开下面这张图，来源于Apple开发者文档 结合上图，可将RunLoop架构划分为四个部分： 事件源 运行模式 循环机制 执行反馈 1. 事件源Cocoa RunLoop接受的事件源分为两种类型：Input Sources 和 Timer Sources 1.1. Input SourcesInput Sources通过异步派发的方式将事件转送到目标线程，事件类别分为两大块： Port-Based Sources ： 基于Mach端口的事件源，Cocoa和Core Foundation这两个框架已经提供了内部支持，只需要调用端口相关的对象或者函数就能提供端口进行通信。比如：将NSPort对象部署到RunLoop中，实现两个线程的循环通信。 Custom Input Sources ： 用户自定义的输入源：使用Core Foundation框架中CFRunLoopSourceRef对象的相关函数实现。具体实现可以查看另外一篇博客：Cocoa RunLoop 系列之Configure Custom InputSource Cocoa Perform Selector Sources：Cocoa框架内部实现的自定义输入源，可以跨线程调用，实现线程见通信，有点类似于Port-Based事件源，不同的是这种事件源只在RunLoop上部署一次，执行结束后便会自动移除。如果目标线程中没有启动RunLoop也就意味着无法部署这类事件源，因此不会得到预期的结果。 使用Cocoa自定义事件源的函数接口，如下： 1234567891011121314151617181920 //部署在主线程 //参数列表：Selector:事件源处理函数,Selector参数,是否阻塞当前线程,指定RunLoop模式 performSelectorOnMainThread:withObject:waitUntilDone:performSelectorOnMainThread:withObject:waitUntilDone:modes://部署在指定线程//参数列表：Selector:事件源处理函数,指定线程,Selector参数,是否阻塞当前线程,指定RunLoop模式permSelector:onThread:withObject:waitUntilDone:performSelector:onThread:withObject:waitUntilDone:modes://部署在当前线程//参数列表：Selector:事件源处理函数,Selector参数,延时执行时间,指定RunLoop模式performSelector:withObject:afterDelay:performSelector:withObject:afterDelay:inModes: //撤销某个对象通过函数performSelector:withObject:afterDelay:部署在当前线程的全部或者指定事件源cancelPreviousPerformRequestsWithTarget:cancelPreviousPerformRequestsWithTarget:selector:object: 综上，Input Sources包括基于Mach端口的事件源和自定义的事件源，二者的唯一区别在于被触发的方式：前者是由内核自动触发，后者则需要在其他线程中手动触发。 1.2. Timer Sources 不同于Input Sources的异步派发，Timer Source是通过同步派发的方式，在预设时间到达时将事件转送到目标线程。这种事件源可用于线程的自我提醒功能，实现周期性的任务。 如果RunLoop当前运行模式没有添加Time Sources，则在RunLoop中部署的定时器不会被执行。 设定的间隔时间与真实的触发时间之间没有必然联系，定时器会根据设定的间隔时间周期性的派发消息到RunLoop，但是真实的触发时间由RunLoop决定，假设RunLoop当前正在处理其一个长时间的任务，则触发时间会被延迟，如果在最终触发之前Timer已经派发了N个消息，RunLoop也只会当做一次派发对待，触发一次对应的处理函数。 2. 运行模式运行模式类似于一个过滤器，用于屏蔽那些不关心的事件源，让RunLoop专注于监听和处理指定的事件源和RunLoop Observer。 CFRunLoopMode 和 CFRunLoop 的数据结构大致如下： 123456789101112131415161718struct __CFRunLoop { CFMutableSetRef _commonModes; // Set CFMutableSetRef _commonModeItems; // Set&lt;Source/Observer/Timer&gt; CFRunLoopModeRef _currentMode; // Current Runloop Mode CFMutableSetRef _modes; // Set ...};struct __CFRunLoopMode { CFStringRef _name; // Mode Name, 例如 @\"kCFRunLoopDefaultMode\" CFMutableSetRef _sources0; // Set CFMutableSetRef _sources1; // Set CFMutableArrayRef _observers; // Array CFMutableArrayRef _timers; // Array ...}; 结合以上源码，总结以下几点： 每种模式通过name属性作为标识。 一种运行模式（Run Loop Mode）就是一个集合，包含需要监听的事件源Input Sources和Timer Soueces以及需要触发的RunLoop observers。 Cocoa RunLoop包含若干个Mode，调用RunLoop是指定的Mode称之为CurrentMode。RunLoop可以在不同的Mode下切换，切换时退出CurrentMode,并保存相关上下文，再进入新的Mode。 在启动Cocoa RunLoop是必须指定一种的运行模式，且如果指定的运行模式没有包含事件源或者observers，RunLoop会立刻退出。 CFRunLoop结构中的commonModes是Mode集合,将某个Mode的name添加到commonModes集合中，表示这个Mode具有“common”属性。 CFRunLoop结构中的commonModeItems则是共用源的集合，包括事件源和执行反馈。这些共用源会被自动添加到具有“common”属性的Mode中。 ** Note ** : 不同的运行模式区别在于事件源的不同，比如来源于不同端口的事件和端口事件与Timer事件。不能用于区分不同的事件类型，比如鼠标消息事件和键盘消息事件，因为这两种事件都属于基于端口的事件源。 以下是苹果预定义好的一些运行模式： NSDefaultRunLoopMode //默认的运行模式，适用于大部分情况 NSConnectionReplyMode //Cocoa库用于监听NSConnection对象响应，开发者很少使用 NSModalPanelRunLoopMode //模态窗口相关事件源 NSEventTrackingRunLoopMode //鼠标拖拽或者屏幕滚动时的事件源 NSRunLoopCommonModes //用于操作RunLoop结构中commonModes和commonModeItems两个属性 3. 循环机制循环机制涉及两方面： 3.1. RunLoop与线程之间的关系Apple文档中提到:开发者不需要手动创建RunLoop对象，每个线程包括主线程都关联了一个RunLoop对象。除了主线程的RunLoop在程序启动时被开启，其他线程的RunLoop都需要手动开启。 待解决的疑问： 线程中的RunLoop是一直存在还是需要时再创建？ 线程与RunLoop的是如何建立联系的？ 线程与RunLoop对象是否是一一对应的关系？ 3.2. RunLoop事件处理流程弄清楚RunLoop内部处理逻辑是理解RunLoop的关键，将单独写一篇博客进行分析。 待解决的疑问： RunLoop如何处理不同事件源？ RunLoop不同模式切换是如何实现的？ 以上两方面，将在下一篇博客Cocoa RunLoop 系列之源码解析中结合源代码来找到答案。 4. 执行反馈RunLoop Observers机制属于RunLoop一个反馈机制，将RunLoop一次循环划分成若干个节点，当执行到对应的节点调用相应的回调函数，将RunLoop当前的执行状态反馈给用户。 用户可以通过Core Foundation框架中的CFRunLoopObserverRef注册 observers。 监听节点： The entrance to the run loop. //RunLoop启动 When the run loop is about to process a timer. //即将处理Timer事件源 When the run loop is about to process an input source. //即将处理Input事件源 When the run loop is about to go to sleep. //即将进入休眠 When the run loop has woken up, but before it has processed the event that woke it up. //重新被唤醒，且在处理唤醒事件之前 The exit from the run loop. //退出RunLoop 监听类别分为两种：一次性和重复监听。 三、何时使用RunLoop由于主线程的RunLoop在程序启动时被自动创建并执行，因此只有在其他线程中才需要手动启动RunLoop。很多情况下，对于RunLoop的使用多数情况是在主线程中，包括进行RunLoop模式切换，设置RunLoop Observer等。 在非主线程中，以下几种情况适用于RunLoop: 使用基于端口或者自定义的事件源与其他线程进行通信。 需要在当前线程中使用Timer，必须部署才RunLoop中才有效。 在目标线程中调用performSelector… 函数，因为本质上使用了Cocoa自定义的事件源，依赖于RunLoop才能被触发。 线程需要进行周期性的任务，需要长时间存在，而非执行一次。 四、总结一直以来，RunLoop对我来说都属于一个比较模糊的概念，在实际编程中也有用到RunLoop的一些功能，确实感觉到很强大，但是仅仅停留在应用层面，并不是很理解具体含义。因此，为了更好的使用RunLoop，有必要研究和梳理RunLoop相关的知识点。","link":"/2015/01/05/Cocoa%20RunLoop%20%E7%B3%BB%E5%88%97%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"Cocoa RunLoop 系列之Configure Custom InputSource","text":"在上一篇博客Cocoa RunLoop 系列之基础知识介绍了RunLoop的InpuSource有两种，分别是： 是基于Mach端口且由内核触发的source1 自定义且需要手动触发的source0。 其中source0包括两种自定义形式：一种是Apple实现的自定义InputSource，提供了一系列接口，直接调用即可；另外一种就是由用户根据开发需要完全自定义实现。本文要介绍的就是后者。 自定义InputSource在实际开发过程的中，可用于在子线程实现周期性且长时间的任务，通过自定义InputSource控制任务的执行。 然而，实际开发中，大部分需要处理的InputSource都属于source1,少数需要自定义InputSource的情况也可以借助Apple的自定义InputSource函数接口来满足需求。因此，实际开发中几乎不需要用户配置自定义InputSource。既然如此，是否还有探索配置自定义InputSource的必要？我个人的答案是肯定的。通过配置自定InputSource可以窥探RunLoop的整个Routine的具体流程，而不是只停留在理论层面，有助于更深刻地理解RunLoop运行机制。 下面进入正文，结合理论和源代码阐述配置自定义InputSource的全过程。 理论概述下图是Apple开发文档中介绍自定义InputSource运行流程图： 结合上图，总结一下几点： 在工作线程创建一个自定义InputSource并部署到RunLoop中 主线程中对线程的InputSource和RunLoop进行引用，用于后续操作 主线程与工作线程共享一个指令集合，以保证指令同步 通过主线程向InputSource中添加指令和数据 指令添加结束后，主线程发送一个通知给InputSource，随后唤醒工作线程中的RunLoop 工作线程的InputSource在接受到通知后，传送指令到RunLoop中等待处理 RunLoop处理完成，进入休眠，等待下一次唤醒 代码实现以上述理论为基础，结合Apple文档提供的代码片段，实现了一个配置自定义InputSource的Demo,完整实例可以查看GitHub源码。 创建并配置InputSource对象IBRunLoopInputSource类用于管理和配置CFRunLoopSourceRef对象，以及包含一个指令集合。 以下是初始化函数： 12345678910111213141516171819202122232425262728293031323334353637@interface IBRunLoopInputSource (){ //InputSource对象 CFRunLoopSourceRef _runLoopSource; //当前指令 NSInteger _currCommand;}//指令集合@property (nonatomic , strong) NSMutableDictionary * commandInfo;@end@implementation IBRunLoopInputSource#pragma mark - Init- (id)init{ self = [super self]; if (self) { //InputSource上下文 ，共有8个回调函数，目前只实现3个 CFRunLoopSourceContext context = {0, (__bridge void *)(self), NULL, NULL, NULL, NULL, NULL, &amp;RunLoopSourceScheduleRoutine, &amp;RunLoopSourceCancelRoutine, &amp;RunLoopSourcePerformRoutine}; //初始化自定义InputSource _runLoopSource = CFRunLoopSourceCreate(NULL, 0, &amp;context); } return self;} 上述代码中可看的一共有8个与InputSource相关的回调函数，此处只配置了3个，分别是RunLoopSourceScheduleRoutine、RunLoopSourceCancelRoutine和RunLoopSourcePerformRoutine。这3个回调函数的实现会在后面进行介绍。 对InputSource的基本操作： 123456789101112131415//添加自定义InputSource到当前RunLoop- (void)addToCurrentRunLoop{ CFRunLoopRef runLoop = CFRunLoopGetCurrent(); //添加到当前RunLoop的kCFRunLoopDefaultMode模式下 CFRunLoopAddSource(runLoop, _runLoopSource, kCFRunLoopDefaultMode);}//从指定RunLoop移除自定义InputSource- (void)invalidateFromRunLoop:(CFRunLoopRef )runLoop{ CFRunLoopRemoveSource(runLoop, _runLoopSource, kCFRunLoopDefaultMode);} 对指令集合的基本操作： 12345678910111213141516171819202122//添加指令到InputSource- (void)addCommand:(NSInteger)command withData:(id)data{ if (data) { [self.commandInfo setObject:data forKey:@(command)]; } }//触发InputSource指令- (void)fireCommand:(NSInteger)command onRunLoop:(CFRunLoopRef)runloop{ _currCommand = command; //通知InputSource准备触发指令 CFRunLoopSourceSignal(_runLoopSource); //唤醒InputSource所在的RunLoop，该RunLoop必须有的InputSource所在的RunLoop CFRunLoopWakeUp(runloop);} 从上面的代码可看的，正如之前理论概述总讲的顺序：发出指令之后，先通知InputSource，再唤醒其所在的RunLoop。 指令通过RunLoop循环，触发相关的回调函数，最终派发给IBRunLoopInputSource对象，然后再处理。 123456789101112131415161718//执行InputSource指令- (void)performSourceCommands{ //根据指令获得对应的数据 id data = [self.commandInfo objectForKey:@(_currCommand)]; if (!data) { data = [NSString stringWithFormat:@\"Empty data for command : %ld\" , _currCommand ]; } //通过代理进行指令数据处理 if (self.delegate &amp;&amp; [self.delegate respondsToSelector:@selector(inputSourceForTest:)]) { [self.delegate inputSourceForTest:data]; } } 在这里，也许有同学感到困惑：为什么绕了一大圈，最终指令执行的代码还是由IBRunLoopInputSource对象来处理，不如直接把指令处理的函数接口公开，直接调用好了？我之前也有类似的困惑，后面仔细一想才想通。可以从两个角度来解答这个困惑： 自定义InputSource的一个主要目的在于在子线程中进行周期性的任务 假设在主线程中直接调用，那么执行的代码也是在主线程，背离了初衷。而通过子线程的RunLoop派发之后，指令对应的处理执行是在子线程 RunLoop的智能休眠配合自定义InputSource能将子线程长时间执行的情况下的资源开销降到最低 上述3点恰恰的自定义InputSource的精华所在。 创建并配置InputSourceContext对象IBRunLoopContext类是一个容器类，用于管理InputSource与RunLoop之间的关系。Demo中的代码实现的最简单的一对一的关系，也可以实现一对多的关系，即一个InputSource关联多个RunLoop。 初始化如下： 1234567891011121314- (id)initWithSource:(IBRunLoopInputSource *)runLoopSource andLoop:(CFRunLoopRef )runLoop{ self = [super init]; if (self) { //强引用InputSource和InputSource所在的RunLoop _runLoopInputSource = runLoopSource; _runLoop = runLoop; } return self;} 当InputSource加入RunLoop中之后，会触发相关的回调函数。在前文中提到，在创建InputSource的时候Demo中配置了3个与InputSource相关的回调函数，具体实现如下： 1234567891011121314151617181920212223242526272829303132333435//inputsource部署回调void RunLoopSourceScheduleRoutine (void *info, CFRunLoopRef rl, CFStringRef mode){ IBRunLoopInputSource* inputSource = (__bridge IBRunLoopInputSource*)info; //创建一个context，包含当前输入源和RunLoop IBRunLoopContext * theContext = [[IBRunLoopContext alloc] initWithSource:inputSource andLoop:rl]; //将context传入主线程建立强引用，用于后续操作 [(AppDelegate *)[NSApp delegate] performSelectorOnMainThread:@selector(registerSource:) withObject:theContext waitUntilDone:NO]; //InputSource弱引用context，因为context已经强引用InputSource，避免循环引用，用于后续移除操作 inputSource.context = theContext;}//inputsource执行任务回调void RunLoopSourcePerformRoutine (void *info){ IBRunLoopInputSource* inputSource = (__bridge IBRunLoopInputSource*)info; //执行InputSource相关的处理 [inputSource performSourceCommands];}//inputsource移除回调void RunLoopSourceCancelRoutine (void *info, CFRunLoopRef rl, CFStringRef mode){ IBRunLoopInputSource* inputSource = (__bridge IBRunLoopInputSource*)info; //移除主线程中InputSource对应的Context引用 if (inputSource.context) { [(AppDelegate *)[NSApp delegate] performSelectorOnMainThread:@selector(removeSource:) withObject:inputSource.context waitUntilDone:YES]; } } 上述代码分别是InputSource部署、执行和移除相关的回调函数： 部署：在InputSource部署到RunLoop之后，触发回调函数RunLoopSourceScheduleRoutine，将inputSource对象和RunLoop打包成一个context，通过Apple实现的自定义InputSource函数，发送给主线程，用于发送指令 执行：执行对应的指令 移除：在主线程中的context引用 创建并配置工作线程IBRunLoopInputSourceThread类用于配置RunLoop和InputSource。 线程入口函数实现如下： 12345678910111213141516171819202122232425- (void)main{ @autoreleasepool { //创建InputSource self.inputSource = [[IBRunLoopInputSource alloc] init]; [self.inputSource setDelegate:self]; //添加InputSource到当前线程RunLoop [self.inputSource addToCurrentRunLoop]; //配置RunLoop监听器 [self configureRunLoopObserver]; while (!self.cancelled) { //作为对照，执行线程其他非InputSource任务 [self doOtherTask]; //切入指定模式RunLoop，且只执行一次 [[NSRunLoop currentRunLoop] runMode:NSDefaultRunLoopMode beforeDate:[NSDate distantFuture]]; } }} 在子线程中的入口函数中，创建InputSource并加入RunLoop，随后启动RunLoop。这里一定要在while循环中切换RunLoop，否则RunLoop只会执行一次便退出。原因在于[[NSRunLoop currentRunLoop] runMode:NSDefaultRunLoopMode beforeDate:[NSDate distantFuture]]函数只会执行一次RunLoop，如果InputSource未添加或者已处理完或者超时会立即退出RunLoop。 完善主线程配置主线程的配置在AppDelegate类中实现，包括创建工作线程、管理InputSource引用以及添加指令和发送通知。 管理InputSource引用： 12345678910111213141516171819202122//注册子线程中InputSource对应的context,用于后续通信- (void)registerSource:(IBRunLoopContext*)sourceInfo{ [self.sourcesToPing addObject:sourceInfo];}//移除子线程中InputSource对应的context- (void)removeSource:(IBRunLoopContext*)sourceInfo{ [self.sourcesToPing enumerateObjectsUsingBlock:^(id obj, NSUInteger idx, BOOL *stop) { if ([obj isEqual:sourceInfo]) { [self.sourcesToPing removeObject:obj]; *stop = YES; } }]; } 添加指令和发送通知 123456789101112131415161718 - (void)addCommand:(NSInteger)command withData:(id)data{ NSAssert([self.sourcesToPing count] != 0, @\"Empty Input Source...\"); if (self.sourcesToPing.count &gt; 0) { //此处默认取第一个用于测试，可优化 IBRunLoopContext *runLoopContext = [self.sourcesToPing objectAtIndex:0]; IBRunLoopInputSource *inputSource = runLoopContext.runLoopInputSource; //向数据源添加指令 [inputSource addCommand:command withData:data]; //添加后并非要立刻触发，此处仅用于测试 [inputSource fireCommand:command onRunLoop:runLoopContext.runLoop]; } } 总结在写上一篇博客的时候，对与配置自定义InputSource还尚不了解。利用碎片时间和工作间隙仔细阅读了Apple开发文档的相关资料，并且在网上查阅了同行的一些博客之后，决定自己动手写了一个Demo。写Demo的过程的遇到一些新的困惑，随着Demo的完成，大部分困惑也随之而解。","link":"/2015/01/10/Cocoa%20RunLoop%E7%B3%BB%E5%88%97%E4%B9%8B%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5%E6%BA%90/"},{"title":"H264之IDR帧和I帧的区别","text":"面试时被问到的一个问题，没答上来，算是查漏补缺。 简述IDR（Instantaneous Decoder Refresh），即时解码刷新，是一种特殊的I帧。IDR帧是为了防止H264解码器在解码时参考无意义的帧而设置的。 当H264解码器收到IDR帧时，意味着后续抵达的帧不会再参考IDR帧之前的帧，因此，H264解码器会“清空”参考缓冲区（the reference buffer），而所谓的“清空”有可能是将参考缓冲区中的所有帧标识为“不可参考（unused for reference）”状态。 相较而言，当H264解码器收到普通的I帧时，后续抵达的帧有可能会参考这个I帧之前的帧，即参考缓冲区中的帧。 举例假设某一段H264视频使用了多重参照帧，且帧序列如下所示： 那么，帧在参考的同时，还有可能会参考帧。但是如果帧前后是一个场景的切换，即帧前后的场景可能会存在很大的反差，此时帧参考帧之前的帧已经没有太大的意义，反而降低了解码的效率。 此时，如果将帧替换成IDR帧，即帧序列如下所示： 由于IDR帧禁止后续的帧参考在其之前的帧，故帧不会再参考帧。 用途IDR帧的引入可解决在视频播放过程中进行点播、快进或快退等操作导致视频失真等问题。此外，H264编码器的第一个I帧通常都是IDR帧，可实现快速播放。 参考资料Difference between I frame and IDR frame","link":"/2022/04/19/H264%E4%B9%8BIDR%E5%B8%A7%E5%92%8CI%E5%B8%A7%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"原生JS代码模拟鼠标点击消息","text":"近两天都忙于更新之前做的一个关于国外某知名音乐网站项目，因为自己一直做iOS开发并没有系统的学习过JS，所以属于半吊子水平。 由于该音乐网站对网页进行了全新的改版，导致之前注入的JS代码全部失效，且原网站中使用的第三方JQuery库也被去掉了。意味着只能使用原生JS重写注入代码。 期间遇到了一个“棘手”的问题：使用原生JS代码模拟鼠标点击消息来改变音量，不同于普通的鼠标点击的是消息里面需要附带鼠标坐标。在各种尝试之后，耗费了大半天时间才得以解决，个人觉得有点价值，记录下解决思路以供参考。 以下是解决思路流程： ps：以下调试和代码均在Chrome浏览器的控制台执行。 分析DOM元素结构页面样式 DOM结构 由上图可知，DIV元素VolumeSlider作为父元素，其下有四个子元素，分,包括显示音量的slider和控制音量的handle元素。 对音量相关的DOM结构有一个大致了解，便于后面消息派发时选择触发的目标元素。如果说网站将响应鼠标消息的js绑定在父元素，那么选择任意一个子元素或者父元素本身作为触发对象都可以，因为消息会自动传递，最终会作用于父元素VolumeSlider。但是如果响应鼠标消息的js是绑定在四个子元素中的其中一个，则需要一一尝试。这个例子中只有4个子元素，所以很快就能有结果，但是如果需要测试的元素很多，那就效率太低下了。文章后面会介绍一种方法，快速定位响应鼠标消息的元素。 模拟鼠标点击消息该音乐网站改版之前，因为支持jQuery，借助于jQuery库提供的API很方便获取元素坐标和模拟鼠标点击消息。而新的版本只能用原生js编写相关代码。 第一步：获取元素的坐标位置 1234567891011121314151617181920//递归获取元素的纵坐标function getTop(e){ var offset=e.offsetTop; ／／累加父元素的坐标值 if(e.offsetParent!=null) ／／递归 offset+=getTop(e.offsetParent); return offset;}//递归获取元素的横坐标function getLeft(e){ var offset=e.offsetLeft; ／／累加父元素的坐标值 if(e.offsetParent!=null) ／／递归 offset+=getLeft(e.offsetParent); return offset; } 第二步：模拟鼠标消息 原生js的Event对象有很多属性，但是创建Event的时并不是每一个属性都需要赋值。在网上找到了一篇博客Simulating Mouse Events in JavaScript讲的比较详细。以下是我使用的示例代码： 12345678910111213141516／／offset是通过音量值转换过来的：音量level（0-1）* targetElement的长度var clientX = getLeft(targetElement) + offset; var clientY = getTop(targetElement); var event = new MouseEvent('click', { 'view': window, 'bubbles': true, 'cancelable': true, 'clientX':clientX, 'clientY':clientY }); targetElement.dispatchEvent(event); 第三步：获取响应鼠标消息的元素 如果是普通的鼠标消息，比如点击按钮消息或者不带坐标值的消息，一般很容易触发成功。但是如果是带来坐标位置的鼠标消息则很可能触发成功之后但是达不到预期效果。在这个问题上我困惑了蛮久，明明代码执行之后，返回触发消息成功，但是音量值并没有改变。 我在想有没有办法将真实的鼠标点击消息内容输出到终端，这样通过对比真实的鼠标消息就能找到模拟的鼠标消息的差异所在。 于是，在控制台输入了以下代码： 12345678910//全局变量var windowClickEvent = nullwindow.onclick = function(ev){ var oEvent = ev||event; ／／获取当前鼠标消息对象 windowClickEvent = oEvent;} 上述代码能获得当前鼠标消息对象。使用鼠标点击音量条，在控制台获得如下结果： 对比真实的鼠标消息，确定模拟的鼠标消息中的坐标值是吻合的。但是二者的target元素不同，这也正是原因所在。修改了target元素之后，代码执行结果达到了预期的结果。通过这个方法可以快速定位响应鼠标消息的目标元素。 小结在刚开始要使用原生js模拟鼠标消息的时候，感觉一片茫然。在网上查了很多资料，没有找到满足需求的代码。最后只能硬着头皮自己写，期间各种不确定性都需要一一测试，折腾了大半天，好在最终达到预期的结果。与此同时，对模拟鼠标消息也有了新的体会，至少以后能够比较轻松的完成类似的功能。","link":"/2017/02/23/JS-%E6%A8%A1%E6%8B%9F%E9%BC%A0%E6%A0%87%E7%82%B9%E5%87%BB%E6%B6%88%E6%81%AF/"},{"title":"JavaScript的this关键字","text":"这是一篇翻译文章，原文地址*点击这里*。 JavaScript中一个常用的语法特征就是this关键字，同时这也是JavaScript最容易被误解和造成困惑的特征。this关键字的含义是什么且决定其含义的依据是什么？ 这篇文章试着解开这个的疑惑并给出一个简单清晰的解释。 对于有其他语言编程经验的人来说应该也使用过this关键字，且多数情况下this指向的是一个通过构造函数创建的新对象。举例来说，假设有一个Boat类，里面包含一个成员方法moveBoat()，我们可以在moveBoat()方法中通过this关键字访问当前的对象实例。 在JavaSctript中，当使用new关键字创建一个新对象后，在构造函数中可以通过this关键字访问当前对象。然而，JavaScript中的this关键字指向的对象是随着函数调用的上下文变化而变化的。如果你不是很了解关于JavaScript执行上下文的知识，我推荐你看看我的另外一篇关于这个话题的文章。好了，讲得够多了，让我们看几个代码实例： 1234567// Global scopefoo = 'abc';alert(foo); //abcthis.foo = 'def';alert(foo); //def 无论何时，只要是在全局上下文而非函数体内使用this关键字，那么this总是指向全局对象的（JavaSctript中的全局对象一般是Windows，NodeJS中是global）。接下来看看在函数中使用this关键字的情景： 12345678910111213141516var boat = { size: 'normal', boatInfo: function() { alert(this === boat); alert(this.size); }};boat.boatInfo(); // true, 'normal'var bigBoat = { size: 'big'};bigBoat.boatInfo = boat.boatInfo;bigBoat.boatInfo(); // false, 'big' 上述代码中的this关键字指向是如何判断的？上述代码中有一个boat对象，包含了一个size属性和boatInfo方法。在boatInfo方法中有两条输出语句，分别是判断this关键字是否指向boat对象和输出this关键字指向的对象的size属性。因此，当执行代码boat.boatInfo()时，输出结果分别是true和normal。 随后我们创建了另外一个对象bigBoat，里面同样有一个值为big的size属性。然而，bigBoat对象没有boatInfo方法，因此通过语句bigBoat.boatInfo = boat.boatInfo拷贝一个boatInfo方法。现在，当我们执行语句bigBoat.boatInfo()时，输出的结果分别是false和big。为什么会输出false? boatInfo方法中的this指向的对象是如何发生变化的？ 首先你得明白任何函数中的this关键字指向的值都不是定值，它根据你每次调用函数前的上下文来决定，这个上下文就是函数被调用时所作的生命周期。更为重要的是函数具体的调用语句。 当一个函数被调用时，如果函数是被某个对象调用时，那么函数中this关键字指向的是调用该函数的对象，否则指向的全局对象。下面举例说明： 123456789101112131415function bar() { alert(this);}// global - because the method bar() belongs to the global object when invoked//this指向全局对象bar(); var foo = { baz: function() { alert(this); }}// foo - because the method baz() belongs to the object foo when invoked//this指向foo对象foo.baz(); 如果事情有这么简单，那么上述代码显然解决了我们的疑惑。但是还有更为复杂的情况，看似同一个的函数，调用的语句不同也会导致this关键字的指向不同。如下所示： 1234567891011121314var foo = { baz: function() { alert(this); }}// foo - because baz belongs to the foo object when invoked//this指向foo对象foo.baz(); var anotherBaz = foo.baz;// global - because the method anotherBaz() belongs to the global object when invoked, NOT foo//this指向全局对象，即使anotherBaz是由foo.baz赋值而来，但是this的指向最终还是由调用的方式决定。anotherBaz(); 通过上述代码我们看到由于调用语句的不同，baz方法中的this关键字指向的对象也不一样。现在我们来看看this关键字处于内嵌时的指向是如何的： 12345678910111213141516171819var anum = 0;var foo = { anum: 10, baz: { anum: 20, bar: function() { console.log(this.anum); } }}// 20 - because left side of () is bar, which belongs to baz object when invoked//输出的值是20，因为bar方法是通过baz对象调用的foo.baz.bar(); var hello = foo.baz.bar;// 0 - because left side of () is hello, which belongs to global object when invoked//输出的是0，因为hello函数没有显示的调用对象，缺省调用对象为全局对象globalhello(); 另外一个被常问到的问题是：如何判断事件监听函数中的this关键字指向？答案是处于事件监听函数中的this关键字通常指向触发该事件的DOM元素。下面举例说明： 123456789101112131415&lt;div id=\"test\"&gt;I am an element with id #test&lt;/div&gt;function doAlert() { alert(this.innerHTML); } //指向全局对象，但是因为全局对象没有相应的属性，因此输出undefineddoAlert(); // undefined var myElem = document.getElementById('test'); myElem.onclick = doAlert; alert(myElem.onclick === doAlert); // true //this指向myElem对象myElem.onclick(); // I am an element 上述代码中，第一次调用doAlert函数，输出的是undefined，因此此时this指向的是全局对象global。当我们将doAlert函数设置为myElem元素对象的click消息监听函数时，意味着每次触发click消息时，doAlert等价于被myElem对象直接调用，因此this关键字指向的就是myElem对象。 最后，我想提醒大家的是this关键字的指向是可以通过call()和apply()函数手动修改的，这将导致我们上面讨论的内容都不再适用。另外一点是，在某个对象的构造函数中的this关键字默认是指向当前新建的对象，因为构造函数是使用new关键字调用的，系统会将构造函数中的this关键字指向即将创建的对象。 总结 希望今天的博客能够清除你对this关键字的疑惑，并且以后都能正确地判断this关键字的指向。现在我们知道了this关键字的指向的动态变化的且具体的值取决于this所在函数的调用方式。","link":"/2017/06/07/JavaScript%E7%9A%84this%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"KVO的缺陷","text":"最近在学习和研究Cocoa库的KVO特性，期间发现大神Mike Ash的一篇关于讲述KVO缺陷的博客，觉得很有学习价值，遂想试着翻译以加深理解。 原文地址 翻译Cocoa的KVO特性强大和实用。可惜它的API真的有点糟糕，一些实现方式存在着固有的缺陷。我想探讨一下缺陷所在以及提供一套完善的方案。 缺陷何在？KVO的API中存在三个主要的问题，全部都与类的多重继承结构注册监听器相关。这很重要，因为即便是基类NSObject（通过实现函数-bind:toObject:withKeyPath:options:）也会创建监听。 1、-addObserver:forKeyPath:options:context:函数不接受一个自定义的回调函数 如果你查阅过相似的APIs，比如NSNotificationCenter，你会发现在为一个指定的消息注册监听器时通常涉及到传入一个回调函数作为注册函数的参数。这样可以很容易将当前类的监听事件与父类进行区分，因为你可以直接将消息导向你自己的回调方法。然而，你使用KVO则不得不重载-observeValueForKeyPath:ofObject:change:context:函数，然后在其中处理你监听的事件或者调用父类实现。判断是否需要处理一个消息或是传递给继承链的上一层处理是个复杂的问题，事实上父类也有可能监听了同样的键值路径或者对象。 2、上下文指针变成鸡肋 这个是上一个问题的推论。因为你不能自定义监听的回调函数，也无法通过检测键值路径或者对象来判断父类是否也监听了某个消息。你需要采取其他途径来区分一个消息对象是否属于当前类或是其父类。上下文指针就是为此而生的。你必须创建一个唯一的指针且不会被父类使用，然后做完上下文参数传入函数-addObserver:forKeyPath:options:context:中。随后，你必须在回调函数-observeValueForKeyPath:ofObject:change:context:中检测参数context是否属于当前类。因此，你不能用上下文指针指向一个上下文，也意味着失去了其本该有的功能。 3、-removeObserver:forKeyPath:接受的参数不完善 这个函数不能传入上下文指针。这意味着如果当前类和父类在不同时期都监听了同样的对象或是键值路径，你没办法移除你自己的监听。调用这个函数可能注销你的监听，也可能是注销父类的，或是甚至同时注销两者。 很可惜一个如此强大的工具会有这么严重的缺陷。尤其Apple开始在新的APIs中弱化NSNotification和代理回调的功能，取而代之的是KVO。一个典型的例子是NSOperation：获知一个NSOperation任务完成的唯一途径是通过使用KVO监听它的“isFinished”属性。 完善方案那么我们能为此做点什么？我不想一味地抱怨，所以我写了一个类来解决这个问题。你可以从我的public svn repository获取它，使用如下方式： svn co http://www.mikeash.com/svn/MAKVONotificationCenter/ 你也可以点击上面的链接查看源代码。 那么这个类具体实现是怎么样的？它利用了一个可以保证唯一性的指针：self指针。它不再直接使用目标对象注册某个监听通知（键值路径或者对象），取而代之的是为每个通知创建一个唯一的helper对象并且注册消息监听。随后，这个helper对象接收消息并派发给原有的监听者。因为helper对象对每一个监听者而言是唯一的，所以它可以以实例变量的方式持有关于监听者的元数据，而不需要依赖于上下文指针，至此上下文指针也完全作为函数所需的唯一指针。由于helper对象的职责就是监听KVO通知，监听者持有helper对象的生命周期，我们可以假设父类，NSObject，要么没有注册任何监听，要么监听同样持有一个helper作为监听助手。 MAKVONotificationCenter避开了上述的三个缺陷： 1、函数-addObserver:…中接受自定义回调函数作为参数，当被监听的键值路径发生变化时，自定义的回调函数会被调用。由于父类的回调函数是另外一个不同的函数，所以确保二者的监听不会互相干扰。 2、注册监听的函数中提供一个userinfo参数。可以是一个包含监听者任意信息的对象。 3、函数-removeObserver:…不再仅仅接受监听者和键值路径，还可以接受一个回调函数。这样即便子类和父类注册了同一键值路径或者同样的对象，二者都可以通过指定的回调函数注销监听，而不会影响彼此。 代码中一些值得注意的特征： 函数+defaultCenter中使用了a simple lockless atomic call保证了单例模式的线程安全，不需要每次访问时进行加锁处理。这是一个不错的技术，创建一个安全的单例对象，不需要在每次被访问时提前初始化或是进行加解锁处理。 以NSObjct分类的方式提供一组更为轻便和更优的API。这是一个相比于直接访问MAKVONotificationCenter类的单例更好的方式。在一个极端的情况，MAKVONotificationCenter类可能会从头文件移除，留下的只有NSObject的分类实现。 这份代码压根没有被测试过。我所做过的测试都在代码Tester.m中。在你使用之前不要轻易相信这份代码。150行代码并不算多，但是使用的后果自负。 如果你希望在你的项目里使用它，你也许只要注明代码出处就可以了。如果发现了代码的不足欢迎提供补丁。","link":"/2015/05/10/KVO%E7%9A%84%E7%BC%BA%E9%99%B7/"},{"title":"macOSX开发之Safari App Extension初探","text":"Safari App Extension简介什么是Safari App ExtensionSafari App Extension，即Safari浏览器应用拓展。它是苹果新推出的一种Safari扩展开发技术，最低支持Safari10.0，主要由三个部分组成分别是： Safari App Axtension: 扩展app本身，使用JS、CSS等前端脚本语言。主要功能是包括两方面： 在插件运行之前注入js和css代码到当前的Safari浏览器页面，进而实现对页面的增删改查等功能 调用Safari提供的JS API接口与Containing app进行交互通信。 Containing App: 扩展app的容器，属于Native App。主要功能包括四方面： 配置和加载扩展app 与扩展app进行通信 提供可在Safari工具栏显示的原生界面 与Host App进行交互通信和共享数据 Host App: 主程序，也属于Native App。主要功能包括三方面： 加载Containing App 与Containing app通信交互 发布Safari App Extension到Apple App Store 结合上述的分析，Safari App Extension可使用两种组合的形式发布产品。一种是三个部分的App同时存在；另外一种是Host App只是作为发布工具，仅在第一次打开并完成扩展app安装之后就不再需要，因为安装好的扩展可在Safari-&gt;偏好设置-&gt;扩展中找到。 与 Safari Extension 的异同Safari App Extension和Safari Extension的名称很相似，以至于在最开始研究的时候，我错以为二者是同一个东西，结果瞎忙活的一天才发现自己南辕北辙。不过，二者确实存在一些相似的地方。苹果的这篇官方文档具体介绍了如何将Safari Extension转换为Safari App Extension。简单来说，二者共同点在于js和css代码是完全可以复用的，不同的地方是Safari Extension的配置、开发以及发布平台都是基于Safari浏览器，而Safari App Extension则是基于Xcode，且产品发布平台是Apple App Store。 创建一个Safari App Extension 创建 因为Safari App Extension是以插件（plugin）的形式存在于Host App中的，因此需要首先创建一个Host App，也就是普通的Mac OSX的应用程序。然后再添加一个Safari App Extension的Target即可。 配置info.plist Safari App Extension在被加载之前，Safari浏览器会通过读取info.plist文件以获得扩展的一些基本信息。 NSExtension，包括： NSExtensionPointIdentifier：定值，必须是com.apple.Safari.extension，表示Safari扩展 NSExtensionPrincipalClass：扩展的核心类名，默认是SafariExtensionHandler类，里面一些部分实现了NSExtensionRequestHandling和SFSafariExtensionHandling协议，作为与Safari扩展通信和交互的接口。 SFSafariContentScript：用于指定注入的js脚本，以数组的形式表示，在扩展加载之前注入Safari浏览器当前的tab页。缺省值是只有一个文件script.js，也可以注入多个js文件，注入顺序依据数组中的顺序。 SFSafariToolbarItem：用于配置Safari扩展在工具栏中按钮的类型、图片以及tooltip等。按钮类型包括comman、popover等。 SFSafariWebsiteAccess：包括Allowed Domains和Level两个属性，分别表示允许访问的网站域名列表和网页访问权限。其中Level可以是Some和All，分别表示部分访问和无限制访问。 NSHumanReadableDescription 顾名思义，用于向用户阐述扩展基本功能的文字描述。在Safari浏览器的扩展管理器中选择某个插件就会显示对于的描述。 运行 这里有一个坑，如果是Xcode中运行Host App并不会加载包含于其中的Safari App Extension，解决办法是编辑Safari App Extension的scheme，指定可执行文件为Host App，再编译运行即可。此外，如果是双击的方式打开某个已经编译好的Host App也会自动加载其中的扩展插件。然后在Safari-&gt;Preference-&gt;Extensions中可看到对应的扩展。值得注意的是，如果扩展插件不是从Apple App Store中下载的，那么是不能正常加载的，即便App在本地已经打包签名也一样。解决方法是勾选Safari Menu-&gt;Develop-&gt;Allow Unsigend Extensions即可。 调试 Safari App Extension调试有两个值得注意的地方，第一，因为扩展插件是依附于Host App运行的，因为Xcode默认激活的是Host App进程，因此想要设置断点调试扩展插件，需要手动激活扩展进程。步骤是：在通过Xcode编译运行扩展进程之后，进入Safari Menu-&gt;Debug-&gt;Attach to process，选择对应的扩展进程。第二，在扩展插件中添加的NSLog调试信息不能在Xcode的终端输出，只能在电脑的控制台中查看。但是，lldb可以正常使用和输出。更多细节参考这篇博客 附录一个关于Safari App Extensions的Demo:GitHub Demo 苹果2016年WWDC关于Safari App Extensions的介绍：Extending your App with Safari App Extensions WWDC 2016","link":"/2018/08/06/OSX%E5%BC%80%E5%8F%91%E4%B9%8BSafari%20App%20Extension%E5%88%9D%E6%8E%A2/"},{"title":"Objective-C Category 深入浅出系列-第1话","text":"Objective-C Category（分类）之于我而言有种神秘感，虽然自己已经在实际开发过程中已经多次使用它，且感受到了它带来的便利与高效。但是我却仅仅是停留在对它的基本使用层面，除此之外一无所知。我能感觉它的强大，心中也一直有种对它内部实现一探究竟的冲动，奈何迟迟没有行动。时间愈久，这种情绪愈发浓烈，今天终究是按耐不住了… 知其然对于苹果应用开发者来说，开发者想要快速地了解或是回顾某个知识点，Apple开发者文档往往是不二首选。 文档上如是说：你可以使用Category为一个已经存在的类添加额外的方法，比如Cocoa库中的类，即便是这个类的源代码是不可见的-不能子类化。使用Category给类添加的方法能被其子类继承，且在Runtime下其与类原有的方法是无差别的。 分类的使用场景： 在不改变某个类源文件和不使用继承的前提下，为该类添加先的方法 声明类的私有方法 将一个类的实现拆分为多个独立的源文件 很明显，Category其实就是设计模式之一的装饰者模式的具体实现。 注意，Category是一个类的拓展，为不是一个新类。 借助Apple开发者文档了解到Category的“知其然”，然后就是基于Apple Opensource来解决“知其所以然”的问题？ 知其然所以然 此处使用的源码版本是objc4-532.2。与本文相关的代码都在源文件objc-runtime-new.mm中，接下来就结合关键的代码与注释进行分析。 Catrgory的定义 12345678910 typedef struct category_t { const char *name; classref_t cls; struct method_list_t *instanceMethods; struct method_list_t *classMethods; struct protocol_list_t *protocols; struct property_list_t *instanceProperties;} category_t; 通过Category的定义可以看出，Category与Class存在很相似。不过Category没有isa指针，这也说明Category不是一个类，只能作为一个类的拓展存在。 关键Method-1: _read_images() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889 void _read_images(header_info **hList, uint32_t hCount){ ... #define EACH_HEADER \\hIndex = 0; \\crashlog_header_name(NULL) &amp;&amp; hIndex &lt; hCount &amp;&amp; (hi = hList[hIndex]) &amp;&amp; crashlog_header_name(hi); \\hIndex++ ... // Discover categories. //遍历工程中所有的头文件 for (EACH_HEADER) { //Category列表 category_t **catlist = _getObjc2CategoryList(hi, &amp;count); //遍历Category列表 for (i = 0; i &lt; count; i++) { category_t *cat = catlist[i]; //Category拓展的类的指针 class_t *cls = remapClass(cat-&gt;cls); if (!cls) { // Category's target class is missing (probably weak-linked). // Disavow any knowledge of this category. catlist[i] = NULL; if (PrintConnecting) { _objc_inform(\"CLASS: IGNORING category \\?\\?\\?(%s) %p with \" \"missing weak-linked target class\", cat-&gt;name, cat); } continue; } // Process this category. // First, register the category with its target class. // Then, rebuild the class's method lists (etc) if // the class is realized. //检测目标类是否已实现 BOOL classExists = NO; if (cat-&gt;instanceMethods || cat-&gt;protocols || cat-&gt;instanceProperties) { addUnattachedCategoryForClass(cat, cls, hi); if (isRealized(cls)) { remethodizeClass(cls); classExists = YES; } if (PrintConnecting) { _objc_inform(\"CLASS: found category -%s(%s) %s\", getName(cls), cat-&gt;name, classExists ? \"on existing class\" : \"\"); } } //Categoty存在方法列表或者协议列表 if (cat-&gt;classMethods || cat-&gt;protocols /* || cat-&gt;classProperties */) { //关键函数块 //添加Category到目标类 addUnattachedCategoryForClass(cat, cls-&gt;isa, hi); //重构目标类的方法列表 if (isRealized(cls-&gt;isa)) { //关键函数！ remethodizeClass(cls-&gt;isa); } if (PrintConnecting) { _objc_inform(\"CLASS: found category +%s(%s)\", getName(cls), cat-&gt;name); } } } } // Category discovery MUST BE LAST to avoid potential races // when other threads call the new category code before // this thread finishes its fixups. // +load handled by prepare_load_methods() #undef EACH_HEADER} _read_images()是赋值读取镜像文件的函数，函数末尾就是处理Category的代码块。其中将工程中所有的Category分别与其目标类建立关联，然后调用了remethodizeClass()对目标类的进行重构。 关键Method-2: remethodizeClass() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 static void remethodizeClass(class_t *cls){ category_list *cats; BOOL isMeta; rwlock_assert_writing(&amp;runtimeLock); //识别目标类是否为元类 isMeta = isMetaClass(cls); // Re-methodizing: check for more categories //重构目标类的方法列表 if ((cats = unattachedCategoriesForClass(cls))) { chained_property_list *newproperties; const protocol_list_t **newprotos; if (PrintConnecting) { _objc_inform(\"CLASS: attaching categories to class '%s' %s\", getName(cls), isMeta ? \"(meta)\" : \"\"); } // Update methods, properties, protocols BOOL vtableAffected = NO; //添加Category中的方法到目标类 //关键函数！ attachCategoryMethods(cls, cats, &amp;vtableAffected); //将Category中的属性插入属性链表的头部，只有匿名Category才能额外添加属性 newproperties = buildPropertyList(NULL, cats, isMeta); if (newproperties) { newproperties-&gt;next = cls-&gt;data()-&gt;properties; cls-&gt;data()-&gt;properties = newproperties; } //将Category中的协议加入目标类 //查看buildProtocolList函数得知，新的协议的加入目标类原有协议的尾部 newprotos = buildProtocolList(cats, NULL, cls-&gt;data()-&gt;protocols); if (cls-&gt;data()-&gt;protocols &amp;&amp; cls-&gt;data()-&gt;protocols != newprotos) { _free_internal(cls-&gt;data()-&gt;protocols); } cls-&gt;data()-&gt;protocols = newprotos; _free_internal(cats); // Update method caches and vtables flushCaches(cls); if (vtableAffected) flushVtables(cls); }} remethodizeClass()函数的功能比较简单，进一步细化了对Category中的方法列表、协议列表和属性列表的处理。其中，属性列表的处理则是直接插入原属性链表头部，协议列表则是附加到原协议列表的尾部。接下来，重点分析处理Category方法列表的attachCategoryMethods函数。 关键Method-3: attachCategoryMethods() 12345678910111213141516171819202122232425262728293031323334static void attachCategoryMethods(class_t *cls, category_list *cats, BOOL *inoutVtablesAffected){ if (!cats) return; if (PrintReplacedMethods) printReplacements(cls, cats); BOOL isMeta = isMetaClass(cls); //为每个Category分配函数列表 method_list_t **mlists = (method_list_t **) _malloc_internal(cats-&gt;count * sizeof(*mlists)); // Count backwards through cats to get newest categories first int mcount = 0; int i = cats-&gt;count; BOOL fromBundle = NO; //汇总所有Category的拓展方法 while (i--) { method_list_t *mlist = cat_method_list(cats-&gt;list[i].cat, isMeta); if (mlist) { mlists[mcount++] = mlist; fromBundle |= cats-&gt;list[i].fromBundle; } } //关键函数! //将Category中的拓展方法加入到目标类 attachMethodLists(cls, mlists, mcount, NO, fromBundle, inoutVtablesAffected); _free_internal(mlists); } attachCategoryMethods()函数的功能也比较简单，对与目标类的Category中所有方法进行汇总，然后调用attachMethodLists函数进行处理。 关键Method-4: attachMethodLists() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788static void attachMethodLists(class_t *cls, method_list_t **addedLists, int addedCount, BOOL baseMethods, BOOL methodsFromBundle, BOOL *inoutVtablesAffected){ rwlock_assert_writing(&amp;runtimeLock); ... // Method list array is NULL-terminated. // Some elements of lists are NULL; we must filter them out. //方法列表以NULL作为结束符，因此需要过滤掉目标类中的NULL函数 method_list_t *oldBuf[2]; method_list_t **oldLists; int oldCount = 0; if (cls-&gt;data()-&gt;flags &amp; RW_METHOD_ARRAY) { oldLists = cls-&gt;data()-&gt;method_lists; } else { oldBuf[0] = cls-&gt;data()-&gt;method_list; oldBuf[1] = NULL; oldLists = oldBuf; } if (oldLists) { while (oldLists[oldCount]) oldCount++; } int newCount = oldCount; //同上，过滤掉Category方法列表中的NULL函数 for (int i = 0; i &lt; addedCount; i++) { if (addedLists[i]) newCount++; // only non-NULL entries get added } //创建新的方法列表 method_list_t *newBuf[2]; method_list_t **newLists; if (newCount &gt; 1) { newLists = (method_list_t **) _malloc_internal((1 + newCount) * sizeof(*newLists)); } else { newLists = newBuf; } // Add method lists to array. // Reallocate un-fixed method lists. // The new methods are PREPENDED to the method list array. newCount = 0; int i; //先将Category加入到新的方法列表 for (i = 0; i &lt; addedCount; i++) { method_list_t *mlist = addedLists[i]; if (!mlist) continue; // Fixup selectors if necessary if (!isMethodListFixedUp(mlist)) { mlist = fixupMethodList(mlist, methodsFromBundle, true/*sort*/); } ... // Fill method list array newLists[newCount++] = mlist; } // Copy old methods to the method list array、 //再将目标类原方法加入新的方法列表 for (i = 0; i &lt; oldCount; i++) { newLists[newCount++] = oldLists[i]; } if (oldLists &amp;&amp; oldLists != oldBuf) free(oldLists); // NULL-terminate newLists[newCount] = NULL; //更新目标类的方法列表 if (newCount &gt; 1) { assert(newLists != newBuf); cls-&gt;data()-&gt;method_lists = newLists; changeInfo(cls, RW_METHOD_ARRAY, 0); } else { assert(newLists == newBuf); cls-&gt;data()-&gt;method_list = newLists[0]; assert(!(cls-&gt;data()-&gt;flags &amp; RW_METHOD_ARRAY)); }} attachMethodLists才是最关键的函数。函数中为目标类分配了一个新的函数列表，先加入Category中的方法，再加入目标类原有方法。这也就是为什么如果Category中的函数与目标类中的函数重名，那么目标类的函数会被覆盖的原因。因为Runtime在遍历方法列表时会先发现Category中的函数。 小结这篇博客基于源代码对Category与目标类的组合过程进行了分析，明白了Category中的方法、协议和属性的处理流程。因此，我们可以更加高效和准确地使用Category，甚至利用其中存在的“漏洞”实现一些小魔法。","link":"/2015/03/25/Objective-C%20Category%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"title":"Objective-C中布尔类型","text":"Objective-C中的BOOL类型在iWatch和64位iOS上的原始类型为bool，而在其它情况下是signed char。 用@encode去看看BOOL的类型串： 12@encode(BOOL) // 64位iOS系统：\"B\"@encode(BOOL) // 32位iOS系统，32/64位OS X：\"c\" 众所周知，在C\\C++语言中bool类型中的两个常量false为0，true为1，且非0值都被认为true。Objective-C是建立在C++基础的面相对象的语言，因此bool的定义应该也是如此。 下面对两种情况分别讨论： typeof BOOL bool 12345678BOOL a = 7;if( a == YES ) NSLog(\"This is YES.\")else NSLog(\"This is NO.\") 输出结果：This is YES。说明变量被赋值为1，而非数字7。 typeof BOOL signed char 12345678BOOL a = 7;if( a == YES ) NSLog(\"This is YES.\")else NSLog(\"This is NO.\") 输出结果：This is NO。说明变量被赋值为数字7。 综上所述，在Objective-C中进行布尔比较时，不建议直接将布尔变量和YES或者true做比较，即：if( a == YES )。但是可以和NO或者false做比较，即：if( a != NO )，也可以写成if( a )或者if( !a )的形式。","link":"/2016/10/15/Objective-C%E7%9A%84%E5%B8%83%E5%B0%94%E7%B1%BB%E5%9E%8B/"},{"title":"RGB格式详解","text":"简述RGB色彩模型是工业界的一种颜色标准，又称三原色光模式，是一种加色模型。简单地说，因为红、绿、蓝这三种颜色是人眼的感知最为敏感的颜色，故称之为三原色。因此，将红、绿、蓝三原色的色光按照不同比例叠加，可以合成产生各种色彩光。 RGB色彩模型主要用于电子设备显示，比如电视或电脑，利用大脑强制视觉模糊化（失焦），将红绿蓝三原色分量合成一色彩色像素，进而产生感知层面的色彩，并不需要物理上将三种原色叠加。因此三原色背后的原理是基于生理原因而非物理原因。 RGB颜色模式所产生的颜色几乎覆盖了人类所能感知的所有色彩，因此是目前运用最广的色彩模型之一。 两种格式RBG色彩模型有两种数据格式，分别是： 索引格式 这种格式是一种比较老的格式，所能表达的色彩有限，但相对于像素格式而已更节省空间。RGB对应的像素空间存储的不是像素值而是一个索引，通过索引可找在调色板找到对应的颜色。 常用的类型有RGB1、RBG4和RGB8，分别表示用1 bit、4 bits和8 bits来表示一个像素，因此它们分别能表示的颜色范围为2种、16种和256种。 像素格式 像素格式是一种新型的格式，RGB对应的像素空间中直接存储对应的像素值，这样不再需要调色板便可以直接表示色彩值。 常用的类型有以下几种： RGB565 每个像素使用2个字节表示，即16 bits，RGB分量从高到底分别占用5 bits、6 bits和5 bits 123high low | 5 bits | 6 bits | 5 bits | |----R-----|-----G-----|-----B-----| RGB555 每个像素使用2个字节表示，即16 bits，RGB分量从高到底分别占用5 bits、5 bits和5 bits，且最高位保留。 123high low | | 5 bits | 5 bits | 5 bits | |-|----R-----|-----G-----|-----B-----| RGB24 每个像素使用3个字节表示，即24 bits，RGB分量各占用1个字节，即8 bits。注：RGB24在内存中的存放顺序为BGR。 123high low | 8 bits | 8 bits | 8 bits | |----B-----|-----G-----|-----R-----| RGB32 每个像素使用4个字节表示，即32 bits，RGB分量各占用1个字节，即8 bits，且最低位的1个字节保留。注：RGB32在内存的存放顺序为BGR。 123high low | 8 bits | 8 bits | 8 bits | 8 bits | |----B-----|-----G-----|-----R-----|--reserved--| ARGB32 每个像素使用4个字节表示，即32 bits，RGB分量各占用1个字节，即8 bits，最低位的1个字节用于表示透明度alpha。注：ARGB32在内存的存放顺序为BGRA。 123high low | 8 bits | 8 bits | 8 bits | 8 bits | |----B-----|-----G-----|-----R-----|---alpha----| 参考资料三原色光模式 - 维基百科，自由的百科全书 图解RGB565、RGB555、RGB16、RGB24、RGB32、ARGB32等格式的区别_mb5ff591cb6ec96的技术博客_51CTO博客","link":"/2020/03/15/RGB%E6%A0%BC%E5%BC%8F%E8%AF%A6%E8%A7%A3/"},{"title":"StartFucks Coffee - 操蛋的咖啡","text":"写了一天的代码，看着桌上冒着热气的白开水，想到第一次去星巴克的情景：傻傻地在柜台面子，看着各种咖啡名词，踌躇许久，最终点了一份中杯柠檬茶。那位服务员小胖妞无语中掺杂点鄙视的眼神，至今记忆犹新… 身边的朋友喝咖啡的不少，咖啡这个词汇也经常萦绕耳旁：美剧中，喝咖啡已是日常；朋友聚会，问及他（她）们最爱的饮料，也是拿铁和卡布奇诺居多；特别的大学期间的坐我对面的师姐，感觉她对于喝咖啡跟喝水已经没多大区别，每一次浓浓的咖啡香从她的书桌散发出来，很难说我没有一丝要来一杯的冲动，不过，最终还是忍住了。 究其原因，一是我个人对咖啡的印象并不好，普遍观点认为长期喝咖啡对于身体健康和健身有不良影响，这种观点是否属实尚不能下定论。在此之前，我选择敬而远之。二是我狭隘的以为咖啡只有一种：苦咖啡，殊不知咖啡也是大有学问。其实我早该想到西方的咖啡应该和东方的茶一样，种类繁多，口味各异。只是先入为主的观念让我对咖啡已经失去了进一步了解的兴趣。 如今，终究是因为自尊心受到了伤害，决定整理一下关于咖啡的基本知识。更何况即便是不喝咖啡，也至少对它有一个基本的认识，这样才算得上公平。 网上已经有很多接受咖啡种类的文章，我只是顺手牵羊，秉着拿来主义，自己总结一下，加深印象。 咖啡大体上可以分为12种，其中浓缩咖啡（Espresso）最为根本，其他11种都是在Espresso的基础上添加其他的配料演变而成的花式咖啡。 通过上图，可以比较直观地感受这12种咖啡直接的关联。以下分别介绍： 浓缩咖啡（Espresso）浓缩咖啡，英文名为Espresso，Espresso是一个意大利单词，所以也叫意式浓缩咖啡，指的是一种用咖啡机在短时间内急速萃取的浓烈咖啡，几乎称得上是所有花式咖啡的基础，也是全世界咖啡馆的必备。Espresso很小杯，通常只有30毫升左右，味道很苦，表面浮着一层厚厚的油脂，会与一杯清水同上，可以选择加糖。这款是真正的咖啡爱好者和急需提神者的首选。 玛奇朵（Espresso Macchiato）Macchiato原文为意大利语，代表“印记、烙印”的意思，发音为“玛奇雅朵”，习惯称呼为玛奇朵。玛奇朵是在浓咖啡上加上薄薄一层热奶泡以保持咖啡温度，细腻香甜的奶泡能缓冲浓缩咖啡带来的苦涩冲击，想喝咖啡但又无法舍弃甜味的你，可以选择玛奇朵。经常会听到“焦糖玛奇朵”，据说这是星巴克的独创，其做法是在牛奶中加入香草糖浆，与Espresso咖啡混合，再于奶泡上覆盖一层焦糖，口味层次很丰富。 美式咖啡（Americano）很多咖啡馆的“当日咖啡”其实就是美式咖啡，这通常也是咖啡馆菜单上最便宜的一种。美式咖啡说白了，就是小半杯Esprssso兑上大半杯白开水，也有咖啡馆会使用滴滤式咖啡壶冲泡。美式咖啡味道淡、颜色浅，微酸微苦，但因为萃取时间长，所以咖啡因含量高。 拿铁（Caffè Latte）拿铁是Espresso与牛奶的经典混合，杯底先倒入少量Espresso，然后加入大量牛奶，顶端是浓密的一层泡沫，可以在奶泡上拉出各种各样的图案。经典的拿铁是70%牛奶+20%奶沫+10%咖啡，受法国人喜爱的欧蕾咖啡，是将牛奶和咖啡同时倒入杯中，两者在第一时间碰撞、混合，上加两勺打成泡沫的奶油，这在法国人的早餐中十分常见，几乎是国民饮料。 白咖啡（Flat White）关于白咖啡网上有两种说法： 白咖啡并不是马来西亚的那个特产，而是没有奶泡的拿铁。 马来西亚土特产，约有100多年的历史。白咖啡并不是指咖啡的颜色是白色的，而是采用特等咖啡豆及特级脱脂奶精原料，经特殊工艺加工后得到的咖啡，甘醇芳香不伤肠胃，保留了咖啡原有的色泽和香味，颜色比普通咖啡更清淡柔和，故得名为白咖啡。 康宝蓝（Espresso Con Panna）意大利语中，Con是搅拌，Panna是生奶油，康宝蓝即意式浓缩咖啡加上鲜奶油。有一种说法是，正宗的康宝蓝要配一颗巧克力或太妃糖，先将巧克力或太妃糖含在嘴里，再喝咖啡，让美味一起在口中绽放。 布雷维/半拿铁（Cafe Breve）很像拿铁，不同是加入了的不是牛奶，而是半牛奶、半奶油的混合物，有时会再加少许奶泡。公认的配方是：1份浓缩咖啡+0.75份热牛奶+0.75份鲜奶油+0.5份奶泡。 卡布奇诺（Cappuccino）卡布奇诺和拿铁咖啡的成分一样，都是Espresso+牛奶+奶泡，不同之处仅在于卡布奇诺奶泡比牛奶多，拿铁则是牛奶比奶泡多。传统的卡布奇诺咖啡是三分之一浓缩咖啡，三分之一蒸汽牛奶和三分之一泡沫牛奶。同等价位的卡布奇诺，通常比拿铁要小杯，但咖啡味更浓郁。卡布奇诺是意大利咖啡与牛奶的经典之作，咖啡的颜色就像卡布奇诺教会修士深褐色外衣上覆的头巾一样，咖啡因此得名。可根据自己口味调整牛奶与咖啡的比例，牛奶味重称为湿卡布奇诺，咖啡味重称为干卡布奇诺。 摩卡（Caffè Mocha）一种最古老的咖啡，得名于著名的摩卡港。摩卡的配方成分就相对比较复杂，在Espresso和牛奶的基础上，还有巧克力酱，顶端不是奶泡，而是打发的鲜奶油，还往往会挤上巧克力酱，或者撒上可可粉、肉桂粉，别有一番风味。由于“内容丰富”，通常售价较高，也比较大杯。巧克力和奶油都有甜味，因此摩卡咖啡是苦甜结合的典范。 焦糖玛奇朵（Caramel Macchiato）即加了焦糖的玛奇朵，是在香浓热牛奶上加入浓缩咖啡、香草，最后淋上纯正焦糖而制成的饮品，特点是在一杯饮品里可以喝到三种不同的口味。 爱尔兰咖啡（Irish Coffee）爱尔兰咖啡（Irish Coffee）是一款鸡尾酒，是以爱尔兰威士忌为基酒，配以咖啡为辅料，调制而成的一款鸡尾酒。据说爱尔兰咖啡背后还有一段浪漫的爱情故事，不过我觉得就像卡农背后的爱情故事一样，不必较真。 维也纳咖啡（Viennese Coffee）奥地利最著名的咖啡，是一个名叫爱因·舒伯纳的马车夫发明的，也许是由于这个原因，今天，人们偶尔也会称维也纳咖啡为“单头马车”。在温热的咖啡杯底部撒上薄薄一层砂糖或细冰糖，接着向杯中倒入滚烫而且偏浓的黑咖啡，最后在咖啡表面装饰两勺冷的新鲜奶油，一杯维也纳咖啡就做好了。 综上，发现除了浓缩咖啡和美式咖啡之外，其他咖啡的含糖量都不低。公司附近就有一家星巴克，实践是检验真理的唯一标准。一个星期上一种咖啡，也够我玩三个月了。","link":"/2016/11/23/StartFucks%20Coffee%20-%20%E6%93%8D%E8%9B%8B%E7%9A%84%E5%92%96%E5%95%A1/"},{"title":"TCP&#x2F;IP详解之第11章-UDP：用户数据报协议","text":"知识要点 UDP同TCP一样是传输层协议，且网络层均使用IP协议。 12345+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| IP header | UDP header | UDP payload |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 20 bytes 8 bytes UDP是面向数据报的，即将进程的单次输出封装成一个UDP数据报。 12345678910 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Port | Destination Port |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Length | Checksum |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Data |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ UDP和TCP的校验和均覆盖UDP首部和UDP数据，但是UPD的校验和是可选项，而TCP的校验和是必需项。 UDP数据报和TCP段计算校验和时都包含一个12字节的伪首部，其中包含了32位源IP地址和32位目的IP地址，用于检测UPD数据报是否已正确抵达目的地。 UDP校验和是端到端的，由发送端计算，接收端验证，以检测端到端之间UDP数据报是否发生任何改动。 UDP不提供传输的可靠性保障，即通过UDP发送的数据不保证能否抵达目的地。 使用UDP时应避免IP分片，因为IP层没有超时重传机制。 由于以太网帧的MTU为1500（IEEE 802的MTU为1492），因此，当UDP数据报中的用户数据大于1472（1500-20-8）时会触发IP层分片。 可利用路径MTU发现机制获取路径上最小的MTU值，可用以下命令： 123ping -D -s 8.8.8.8或 tracepath 8.8.8.8 理论上，IP数据报的最大长度为65535（2^16），即UDP数据报中用户数据最大长度为65507=65535-20-8。但是，大多数实现所提供的长度小于这个理论值，原因有二： 应用程序可能会受到程序接口限制 TCP/IP的内核实现中，IP数据报的长度小于65535。 UDP允许应用层指定可接收的最大字节数，因为IP能够发送或接收特定长度的数据包，并不意味着应用层可以读取同样长度的数据。 习题详解 在 1 1 . 5 节中，向UDP数据报中写入1473 字节用户数据时导致以太网数据报片的发生。在采用以太网IEEE 802封装格式时，导致分片的最小用户数据长度为多少?答：因为使用IEEE 802封装时，IP数据报前面存在8个额外的字节，即IEEE 802帧用户数据最大长度为1492（1500-8），因此，UDP导致分片的最小用户数据长度为1465=1492-20-8+1。 阅读RFC 791[Postel 1981a]，理解为什么除最后一片外，其他片中的数据长度均要求为8字节的整数倍? 答：这与IP报文格式的设计相关。在IP报文中，表示报文总长度值的字段占16bits，即IP报文的最大长度为65535。而表示分片偏移量的字段占13bits，能表示范围为0~8191。由于IP报文最小长度为20字节，因此IP报文用户数据的最大长度为65515（65535 - 20）个字节。如果使用8字节作为偏移量最小跨度，那么最多可表示8189（65515 / 8）个分片，这与最大分片偏移量（8191）很接近。且当偏移量取最大值时，最后一个分片的长度为3个字节 = 65535 - 20 - (8189 * 8)。 假定有一个以太网和一份8192字节的UDP数据报，那么需要分成多少个数据分片，每个数据分片的偏移和长度为多少？ 答：将8192字节的UDP数据封装成IP报文需加上8字节的UDP头部，即IP报文的数据长度为8200字节。又因为以太网帧的MTU为1500，每个分片除去20字节的IP头部，IP报文最大数据长度为1480，且刚好是8的倍数，满足IP分片要求。 分片数=8200 / 1480 + 1 = 6，8200 = 1480 * 5 + 800，分片采用tcpdump记号： 分片一：1480@0+，分片长度为1480，偏移量为0，标识位MF=1（More Fragement） 分片二：1480@1480+ 分片三：1480@2960+ 分片四：1480@4440+ 分片五：1480@5920+ 分片六：800@7400+ 一个用UDP发送数据报的应用程序，它把数据报分成4个数据分片。假定第1片和第2片到达目的端，而第3片和第4片丢失了。应用程序在10秒钟后超时重发该UDP数据报，并且被分成相同的4片（相同的偏移和长度）。假定这一次接收主机重新组装的时间为60秒，那么当重发的第3片和第4片到达目的端时，原先收到的第1片和第2片还没有丢弃。接收端能否把这4片数据重新组装成一份IP数据报？ 答：不能。IP数据报中有一个标识字段，只有标识字段相同的数据分片才能组装成一份IP数据报。当应用程序超时重传时，重传IP数据报具有新的标识，因此，其所生成的分片不能与其他IP数据报的分片重组。 在讨论分片时没有提及任何IP首部中的选项—它们是否也要复制到每个数据报片中，或者只留在第一个数据报片中？我们已经讨论过下面这些IP选项：记录路由、时间戳、严格和宽松的源站选路。你希望分片如何处理这些选项？ 答：不严格和严格的源站选路选项被复制到每一个数据包分片中。时间戳选项和记录路由选项只出现在第一个数据包分片中，而不会被复制到每一个数据包分片中。 在图1-8中，我们说UDP数据报是根据目的UDP端口号进行分配的，这正确吗？ 答：不正确，很多实现是根据目的IP地址、源IP地址和源端口号来过滤送往一个给定UDP端口号的输入数据报。 参考资料Why the ip fragments must be in multiples of 8 bytes","link":"/2020/04/20/TCP:IP%E8%AF%A6%E8%A7%A3%E4%B9%8B%E7%AC%AC11%E7%AB%A0/"},{"title":"TCP&#x2F;IP详解之第17章-TCP：传输控制协议","text":"知识要点 TCP和UDP均使用IP协议作为网络层，但TCP提供的是一种面向连接且可靠的字节流服务。 12345+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| IP header | TCP header | TCP payloa |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 20 bytes 20 bytes TCP提供的是字节流服务，不对字节流的内容作任何解释，解释权交给应用层。 应用层产生的全体数据与真正发送的单个IP数据报不存在必然的联系。 TCP提供的是双工服务，数据在两个方向上课独立地进行传输。 TCP首部的固定长度为20字节，最多可有60字节，即任选字段的范围是0~40字节。 12345678910111213141516171819 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Source Port | Destination Port |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Sequence Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Acknowledgment Number |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Data | |U|A|P|R|S|F| || Offset| Reserved |R|C|S|S|Y|I| Window || | |G|K|H|T|N|N| |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Checksum | Urgent Pointer |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Options | Padding |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| data |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP首部的“首部长度”字段占4bit，单位为4字节，表示TCP首部与数据的分界线。 TCP首部中有6个标志比特： URG：紧急指针 ACK：确认序号有效 PSH：接收端应尽快将此报文段交给应用层 RST：重建连接 SYN：启用同步序号建立连接 FIN：发送端完成发送任务 TCP可靠性保障: TCP提供了分段机制：将应用数据分段（segment）的传递给IP层，以避免触发IP层分片机制。而UDP则会将应用层产生的数据原封不动地传递给IP层。 TCP提供了ACK和超时重传机制：一旦超过RTO（Retransmission Timeout）且没有收到某个报文段的ACK就会重传此报文段。 TCP提供了端到端的检验和：检验和覆盖TCP首部和数据，一旦检验和有差错，TCP将丢弃报文段和不确认收到此报文段，以触发发送端的超时重传机制。 TCP提供了报文段乱序重排机制：TCP将收到的报文段进行重新排序，以正确的顺序传给应用层。 TCP提供了重放保护机制：TCP接收端会丢弃重复的报文段。 TCP提供了流量控制机制：TCP连接的两端都有指定大小的缓存区，TCP接收端只允许发送端发送其能缓存的数据大小，以防止接收端缓存溢出。 习题解答 我们已经介绍了以下几种分组格式：IP、ICMP、IGMP、UDP和TCP。每一种格式的首部中均包含校验和。对每种分组，说明检验和包括IP数据包中的哪些部分，以及该校验和是强制的还是可选的。 答：除了UDP的校验和之外，其他的都属强制的。IP分组的检验和只覆盖了首部，ICMP、IGMP、UDP和TCP的检验和都覆盖首部和数据，且都使用IP协议作为网络层，即整个分组就是IP的数据段。 为什么我们已经讨论的所有Internet协议（IP，ICMP，IGMP，UDP，TCP）收到有检验和差错的分组都仅作丢弃处理？ 答：当校验和出现差错时，有三种处理方式： 立即通知发送端重传 直接丢弃，等待发送端超时重传 尝试纠错，比如链路层的CRC（Cyclic Redundancy Check） 一般情况下，校验和不一致的原因主要是两种情况，分别是校验和本身出错和分组字段出错。特别是当分组中重要字段出错，比如IP地址，源端口号或协议字段等，这种情况下无法将重传反馈给发送端。因此，接收端会选择直接丢弃分组，以等待发送端超时重传。 此外，为什么只有链路层支持CRC？因为链路层处于底层，且CRC检错能力极强，足以保证较高的传输准确率，故上层协议不需要再额外支持CRC。 TCP提供了一种字节流服务，而收发双方都不保持记录的边界。应用程序如何提供它们自己的记录标识？ 答：应用层常用的标识记录的方式有两种： NVT ASCII 很多应用会使用回车字符（CR）和换行字符（LF）序列来标记某个应用记录的边界，以\\r\\n表示。比如Telnet以NVT ASCII来描述客户命令和服务器响应，详见章节26.4.1。 字节计数 通过增加一个长度字段，标识某个记录的长度，比如Sun RPC报文，在TCP头部和XID之间增加一个4字节的字段，表示此RPC的长度，详见章节29.2。 为什么在TCP首部的开始便是源和目的端口号？ 答：ICMP差错报文中包含了IP首部和IP数据报文的前8个字节，当TCP收到ICMP差错报文时，需要通过源和目的端口来确定出错的连接，因此端口号必须包含在TCP首部的前8个字节里面。至于为什么源和目的端口号放在TCP首部的4个字节，这与ICMP的具体实现相关。同理，UPD的前4个字节也是源和目的端口号。 为什么TCP首部有一个首部长度字段而UDP首部中却没有？ 答：因为TCP首部中包含固定字段和可选字段，固定字段为20字节，可选字段为040字节，因为TCP首部长度是可变的，范围为2040字节。而、因此，首部长度的作用是用于指明TCP首部的真实长度。而UDP的首部长度是固定的，长度为8个字节。","link":"/2020/05/02/TCP:IP%E8%AF%A6%E8%A7%A3%E4%B9%8B%E7%AC%AC17%E7%AB%A0/"},{"title":"TCP&#x2F;IP详解之第18章-TCP连接的建立与终止","text":"知识要点 TCP是面向连接的协议，任一方在发送数据之前必须先建立连接。 TCP建立连接需要三次握手，分别是： 客户端发送客户端的SYN报文，包括目的端口和初始序号ISN 服务端返回服务器的SYN报文，且确认序号ACK=客户端ISN+1 客户端返回确认序号ACK=服务器ISN+1 TCP的SYN报文中的初始序号ISN是随时间而变化的，因此每个连接的ISN都不同。RFC 793指出ISN为32比特的计数器，且每4ms加1，以确保服务端能识别因网络延迟而被重传的SYN报文，避免建立错误的连接。 TCP终止连接需要四次握手，原因在于TCP连接是双工的，支持半关闭状态。单一方向连接的关闭各需要一个FIN请求和ACK确认。 BSD版的TCP建立连接一个新连接的最长时间限制为75秒，超时后则放弃连接。 BSD版的TCP第一次超时时间为6秒左右，第二次超时时间则总是24秒，且精确到小数点后两位。原因在于，BSD版的TCP实现采用了500ms（1个时钟滴答）的定时器，定时器计数器在设置后的第一个时钟滴答（500ms）内任意时刻减1。 TCP可通过协商来确定最大报文段长度（MSS），如果协商失败则回退到536字节，即对应的IP数据报长度为576字节。以太网中，MSS值可达1460（1500-20-20），IEEE 802.3中，MSS值可达1452字节。 MSL（Maximum Segment Lifetime）表示任何报文段在被丢弃前在网路内的最长时间，RFC 793指出MSL为2分钟，现实中常用值为30秒，1分钟或2分钟。 TCP有序释放：发送FIN报文 TCP异常释放：发送复位报文段 TCP允许双方同时打开，需要4个报文，BSD版的TCP实现都不能正确地支持同时打开。 TCP允许双方同时关闭，需要4个报文。 TCP服务器需要使用本地地址和远端地址组成的4元组：目的IP地址、目的端口、源IP地址和源端口号来处理多个连接请求。 习题解答 在18.2节，我们说初始序号（ISN）正常情况下由1开始，并且每0.5秒增加64000，每次执行一个主动打开。这意味着ISN的最低三位通常总是001。但是图18-3中，为什么两个方向上ISN中最低三位都是521？ 答：ISN是一个uint32_t的计算器，当ISN大于2^32-1时出现回绕，第一次回绕后的值为8704 = 4294976000（4294912000 + 64000）- 2^32。第二次回绕后的值为17408，以此类推，可知ISN的最低位的数字在0、2、4、6和8之间循环。又因为系统引导时ISN是从1开始，因此ISN的最低位数字是一个奇数。 在图18-15中，我们键入12个字符，看到TCP发送了13个字符。在图18-16中，我们键入了8个字符，但TCP发送了10个字符。两种情况分别是为什么？ 答：在第一种情况下，我们使用了sock程序。 默认情况下，它把Unix的换字符（ASCII码为0x0A）原封不动地进行传输。在第二种情况下，我们使用Telnet客户端，它把Unix的换行符转换成两个ASCII字符，即回车符（ASCII码为0x0D）+换行符。 半打开连接和半关闭连接的区别是什么？ 答：一个半关闭连接是一端已经发送了FIN报文，正在等待另一端的数据或FIN报文。一个半打开连接是一端的连接因系统崩溃等异常终止连接，而另外一端并不知情。 如果启动sock程序作为一个服务端程序，然后终止它（还没有客户进程与它建立连接），我们能立即重新启动这个服务端程序。这意味着它没有经历2MSL等待状态。用状态变迁来解释这一切。 答：一个连接只有经过了已建立状态（Established）才能进入2MSL等待状态。 在18.6中，我们知道如果一个客户端的某个本地端口处于2MSL等待期间，则不能重新使用同一个本地端口。但如果sock程序作为客户程序连续运行两处，并且连接到daytime服务器上，我们就能重新使用同一个本地端口。另外，对一个仍处于2MSL等待的连接，也能为它创建一个替身。这该如何解释？ 答：daytime服务器在将时间和日期返回给客户端之后，会发送一个FIN报文，即主动关闭TCP连接，这也是为什么sock程序会打印“connection closed by peer.”。此时，客户端相对于处于被动关闭的状态，而服务端处于TIME_WAIT状态。而正如18.6.1中所述，大多数伯克利系统的TCP实现都允许一个新的连接请求仍处于TIME_WAIT状态的连接，只要新的序号大于该连接前一个替身的最后序号。 在18.6节的最后，我们介绍了FIN_WAIT_2状态，提到如果应用程序经过11分钟后实行完全关闭（不是半关闭），许多具体的实现都将一个连接由这个状态转移到CLOSED状态。如果另一端（处于CLOSE_WAIT状态）在发送FIN之前等待12分钟，这一端的TCP将如何响应这个FIN? 答：由于当前端的状态已转移到CLOSED状态，即TCP连接已经关闭，因此此后到达的FIN报文相对于RST报文。 对于一个电话交谈，哪一方是主动打开，哪一方是被动打开？是否允许同时打开？是否允许同时关闭？ 答：拨号一方为主动打开，接听一方为被动打开，不允许同时打开，但允许同时关闭。 在图18-6中，我们没有见到一个ARP请求或一个ARP应答。显然主机svr4的硬件地址一定在bsdi的ARP高速缓存中。如果这个ARP高速缓存不存在，这个图会有什么变化？ 答：由于ARP高速缓存不存在，所以会先发送ARP请求，而不是SYN报文。 为什么图18-4的服务器不将对客户FIN的ACK与自己的FIN合并，从而将报文段数减少为3个。 答：TCP是双工的，支持半关闭连接。因此，服务端在收到客户的FIN后返回ACK以关闭客户端到服务端的方向连接，但是并不一定需要关闭服务端到客户端的方向连接。 在图18-16中，RST的序号为什么是26368002？ 答：如果发送RST报文段的一端收到过ACK报文段，那么RST报文段的序号就是最近一个ACK报文段的序号。 TCP向链路层查询MTU是否违反分层的规则？ 答：违反。原因在于TCP属于传输层，在传输层和链路层之间还有网络层，MTU查询通常在IP层完成。 假定在图14.16中，每个DNS使用TCP而不是UDP进行查询，试问需要交换多少个报文段？ 答：如果使用TCP，一次查询需要11个分组，分别是3个分组建立连接，1个分组用于查询，1个分组用于确认查询，1个用于响应，1个用于确认响应，4个用于终止连接。如果将查询确认和响应结合在一个报文，则可将分组减小到10个。而如果使用UDP，一次查询只需要2个分组，分别用于查询和响应。 假定MSL为120秒，试问系统能够初始化一个新连接然后进行主动关闭的最大速率是多少？ 答：初始化一个新连接然后主动关闭，即进入TIME_WAIT状态，时长为2MSL。因此，最大速率=TCP端口最大数目（忽略知名端口） / 2MSL = (65536 - 1024) / 240 = 268。 阅读RFC 793，分析处于TIME_WAIT状态的主机收到使其进入此状态的重复的FIN时所发生的情况。 答：重复的FIN会得到确认，重新开始TIME_WAIT状态，即重新开始2MSL等待。 阅读RFC 793，分析处于TIME_WAIT状态的主机收到一个RST时所发生的情况。 答：RFC 739中提出的应对措施是在TIME_WAIT状态下忽略RST报文段，RFC 1337中仔细讨论了这个现象。 阅读Host Requirements RFC并找出半双工TCP关闭的定义。 答：当TCP实现不支持半关闭连接时，一端发送了FIN报文段，则不能再从这个连接中读取数据了。 在图1-8中，我们曾提到到来的TCP报文段可根据其目的端口号进行分用，请问这种说法是否正确？ 答：不正确。一个TCP服务器的端口号可同时建立多个连接，无法仅通过目的端口号来确定那个进程接收了一个连接请求，因此需要使用本地地址和远端地址的4元组来处理传入的多个连接请求。","link":"/2020/05/03/TCP:IP%E8%AF%A6%E8%A7%A3%E4%B9%8B%E7%AC%AC18%E7%AB%A0/"},{"title":"WebRTC之传输协议初探：TLS协议","text":"简述TLS(Transport Layer Security)协议，其前身为SSL(Secure Socket Layer)，是1994年由Netscape公司设计的一套协议，并于1995年发布了3.0版本，而TLS是IETF基于SSL3.0设计的协议，相当于SSL的后续版本。 TLS建立在传输层之上，服务于应用层，旨在于为通信双方提供一条安全通道，主要提供一下三重保障： 身份认证：认证通信双方的身份，防止第三方冒充身份参与通信。 数据安全：加密通道数据且只有通信双方可以解密，以防窃听。 数据完整：提供数据签名和校验机制，一旦数据被篡改，通信双方可立刻发现。 实现细节TLS协议分为两层，分别是握手协议层和记录层，且Handshake协议层位于Record协议层之上： 握手协议层（Handshake Protocol Layer） 主要用于通信双方的身份认证，以及使用非对称的加密算法协商Record协议中使用的对称密钥。 握手协议层有三个协议，分别是： 握手协议（Handshake Protocol） 更换加密规约协议（Change Cipher Spec Protocol） 告警协议（Alert Protocol） 鉴于非对称加密算法的优缺点： 优势：在于加解密过程需要分别依赖公钥和私钥，使用公钥加密的数据只有私钥才能解密，所以即使公钥公开或泄漏也能保证加密数据的安全性。 劣势：加解密耗时长、速度慢、效率低，只适合对少量数据进行加密。 非对称加密算法用于握手协议实现对称密钥的分发。 记录层（Record Layer） 通过握手协议获得对称密钥，使用对称加密算法对应用数据进行加密，并提供数据签名和校验机制，以实现数据的安全传输。 鉴于对称加密算法的特点： 优势：加解密耗时短、速度快、效率高，适合对大量数据进行加密。 劣势：加密和解密使用同一个秘钥，秘钥的管理和分发非常困难，难以保障安全。 对称加密算法用于记录层实现应用数据的加解密。 握手过程该过程的实现基于Handshake协议，共分两个阶段，分别是明文通信阶段、非对称加密通信阶段。 以下为TLS1.2版本的握手过程。 客户端发送Hello消息： Client Hello 客户端的Hello消息，包括以下参数： client_version： 客户端支持的TLS版本，客户端会从高到低去尝试填入自己支持的SSL版本。 random：客户端生成的随机数A， 用于后续的密钥协商。 session_id：本次会话ID。可用于恢复会话，为空则表示没有会话ID。 cipher_suites：客户端支持的加密套件列表，其中的加密套接字使用IANA中注册的名称，根据优先级从高到低排列，优先级越高表示客户端越倾向选择该加密套件。 关于加密套接字：使用的是IANA中注册的名称，可在https://ciphersuite.info/cs/中查询，IANA 名称由 Protocol，Key Exchange Algorithm，Authentication Algorithm，Encryption Algorithm ，Hash Algorithm 的描述组成。例如，TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 的含义如下： Protocol: 安全传输协议，即TLS协议。 Key Exchange: 密钥交换算法，即Elliptic Curve Diffie-Hellman Ephemeral (ECDHE) Authentication: 非对称加密算法，即Rivest Shamir Adleman algorithm (RSA) Encryption: 对称加密算法，即Advanced Encryption Standard with 128bit key in Galois/Counter mode (AES 128 GCM) Hash: 摘要算法，即Secure Hash Algorithm 256 (SHA256) compression_methods：客户端支持的压缩算法列表，根据优先级从高到低排列，优先级越高表示客户端越倾向选择该压缩算法。可为空，表示不支持压缩。在TLS1.3版本中已弃用。 extensions：客户端所支持的扩展协议簇，如果服务端未回应某个扩展协议表示不使用该扩展协议。 服务端响应客户端的Hello消息（以下消息是通过一次传输传递给客户端）： Server Hello 服务端的Hello消息，包括以下参数： server_version：服务端支持的TLS版本。 random：服务端生成的随机数B，用于后续的密钥协商。 session_id：本次会话ID。如果服务端同意客户端重用上次会话则返回与客户端相同的ID，否则返回新的会话ID。 cipher_suite：服务端支持的加密套件，且必须选于客户端支持的加密套件列表。 compression_method：服务端支持的加密算法，且必须选于客户端支持的压缩算法列表。在TLS1.3版本中已弃用。 extensions：服务端支持的扩展协议簇，且必须选于客户端支持的扩展协议簇。 Server Certificate 服务端证书，一般是X.509证书，用于客户端验证服务端身份和交换密钥，其中的密钥交换算法与ServerHello消息中所选加密算法一致。 Server Key Exchange 该消息用于将服务端的公钥发送给客户端，常用的密钥协商算法有： RSA算法：如果采用该算法，可以不发送该消息，因为RSA算法使用的公钥以包含在Server Certificate中。 EC Diffie-Hellman算法：可根据对方的公钥和自己的私钥计算共享密钥。 Certificate Request 在某些安全性要求高的场景，例如银行支付等，不仅需要验证服务端的身份，还需要验证客户端的身份，这时候服务端就会要求客户端提供客户端的身份证书。 Server Hello Done 服务端Hello阶段结束信息。 客户端校验服务端身份： 客户端会校验服务端发过来的证书的合法性，包括： 证书链是否可信 证书是否被吊销 证书是否处于有效期 证书的域名是否和当前访问的域名匹配 如果发现服务端的证书不合法，客户端可以向服务端发起告警信息。 客户端回应服务端： Certificate 可选。如果服务端发送了“Certificate Request”，要求校验客户端身份，那么客户端需要回应自己的证书，一般是X.509证书。如果客户端没有合适的证书，直接抛出告警信息让服务端处理（服务端的处理方式通常就是断开TCP连接）。其中的密钥交换算法与ServerHello消息中所选加密算法一致，用于服务端验证客户端身份。 Client Key Exchange 该消息用于将客户端的公钥发送给服务端，其中的信息用于生成最终的对称加密密钥。常用的密钥协商算法有： RSA算法 EC Diffie-Hellman算法 Certificate Verify 可选。如果服务端要求客户端要求客户端提供证书，那么在客户端在发送ClientKeyExchange消息后紧接着发送该消息。消息内容是使用客户端的私钥加密的一段基于已经协商的通信信息，服务端可以用客户端的公钥解密验证。 Change Cipher Spec 用于提示服务端在随后的连接中都使用当前已协商好的加密方式和主密钥进行通信。 Client Handshake Finished 表示客户端的握手流程结束。当所有的操作完成后，客户端发送Finish消息。该消息包含了Handshake信息和证书信息的哈希值，用于验证身份校验和密钥交换过程都完成。 Finish消息不要求服务端回复，发送该消息后可立刻对应用数据的加密并传输。 服务端回应客户端： Server Change Cipher Spec 用于提示客户端在随后的连接中都使用当前当前已协商好的加密方式和主密钥进行通信。 Server Handshake Finished 同客户端的Server Handshake Finished消息类似，表示服务端的握手流程结束。 Record层传输过程该过程为应用数据传输过程，基于Record协议实现，采样握手过程中已协商好的对称加密算法和对称密钥对数据进行加密和传输。具体过程有待深入研究。 密钥协商握手过程最重要的任务之一就是密钥协商，下面详述密钥协商的过程。 计算Pre-Master Secret 不同的密钥交换算法生成pre-master secret的方式也不同： RSA算法： 当客户端在验证服务端的身份证书后，取出包含在其中的服务端公钥，然后产生一个随机数C作为pre-master secret，并使用服务端的公钥对其进行加密，最后通过该消息发送给服务端。当服务端收到该消息后，使用私钥解密出其中的pre-master secret。 EC-DH 算法： 服务端和客户端通过KeyExchange获得对方用于DH算法的公钥，然后双方使用对方的公钥和自己的私钥，根据特殊的数学特性，计算出一个相同的结果作为共享密钥，即pre-master secret。 在KeyExchange中包含EC-DH具体采用的椭圆曲线算法，以secp256r1为例： 椭圆曲线算法需要一下几个参数： 素数p，用于确定有限域的范围 椭圆曲线方程中的a，b参数 用于生成子群的基点G 子群的阶n 子群的辅助因子h 可定义为一个六元组（p,a,b,G,n,h），在https://www.secg.org/sec2-v2.pdf中可查到secp256r1使用的参数。 假设私钥是D，那么公钥 H = DG，G即子群的基点G 服务端和客户端使用椭圆曲线算法分别计算出自己的密钥对（公钥+私钥），假设私钥分别是：{Ds, Hs} 和 {Dc, Hc}，且满足下面的等式： 1S = Ds * Hc = Ds(DcG) = Dc(DsG) = Dc * Hs 计算 Master Secret 此时，客户端和服务端都拥有相同三个随机数：random_A，random_B和pre-master secret，使用伪随机函数PRF（pseudo random function）生成一串随机数，截取48位作为主密钥Master secret。比如： 1master_secret = PRF(pre_master_secret, \"master secret\", Random_A + Random_B)[0..47] 注：TLS中PRF本质上的一个扩展后的Hash函数，具体使用的Hash算法取决于协商的密钥套件和TLS版本，对于关系如下： prf_tls10：TLS 1.0 和 TLS 1.1 协议，PRF 算法是结合 MD5 和 SHA_1 算法 prf_tls12_sha256：TLS 1.2 协议，默认是 SHA_\\256 算法(这是能满足最低安全的算法) prf_tls12_sha384：TLS 1.2 协议，如果加密套件指定的 HMAC 算法安全级别高于 SHA_256，则采用SHA_384 算法 导出Record层的对称密钥 根据握手过程中协商好的加密套件，从中可知具体的对称加密算法和校验算法，使用对应的PRF和Master Secret导出对应的密钥。 以TLS_ECDHE_RSA_WITH_AES\\128_GCM_SHA256为例： 对称加密算法：AES-128-GCM 校验算法：SHA256 使用PRF和Master Secret生成密钥块key block： 1key_block = PRF(master_secret, \"EXTRACTOR\", client_random + server_random)[length] 截取出6个参数作为通信密钥，分别是： 客户端写MAC密钥 服务端写MAC密钥 客户端写密钥 服务端写密钥 客户端IV 服务端IV 其中，客户端写、服务端读用客户端写密钥；服务端写、客户端读用服务端写密钥。另外对称加密算法是AES-GCM（AES算法除ECB模式外都需要IV），所以需要客户端IV和服务端IV。 结语由于TLS协议主要是提供加密功能以保障通道数据的安全性，因此要求底层协议提供一个可靠且有序的通信过程，这也是TLS常与TCP协议组合使用的原因。如果需要为UDP协议提供安全保障，则可以使用DTLS协议。 参考资料rfc8446 https://datatracker.ietf.org/doc/html/rfc5705#section-4 SSL/TLS发展历史和SSLv3.0协议详解 | 文章 | BEWINDOWEB ECC椭圆曲线加密算法：ECDH 和 ECDSA TLS1.2 PreMasterSecret And MasterSecret | 老青菜 HTTPS 温故知新（五） – TLS 中的密钥计算","link":"/2020/11/03/WebRTC%E4%B9%8B%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%EF%BC%9ATLS%E5%8D%8F%E8%AE%AE/"},{"title":"WebRTC之关键帧请求","text":"简述所谓关键帧，就是不需要参考其他视频帧，可单独解码的帧。比如H264中的I帧。在WebRTC中有两种关键帧请求方式，分别是： PLI：Picture Loss Indication FIR：Full Intra Request 二者的主要区别在于报文结构和使用场景不同，但实际上在发送端处理两种请求的逻辑很可能是一样的，比如，WebRTC中的实现就是如此。 报文结构在WebRTC中，PLI和FIR均被封装在RTCP反馈消息包中，详解RFC4585，其报文格式如下： 1234567891011121314151617// RFC 4585: Feedback format.// Common packet format: 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+|V=2|P| FMT | PT | length |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| SSRC of packet sender |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| SSRC of media source (unused) = 0 |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+: Feedback Control Information (FCI) :: :// FMT: Feedback message type, 5 bits// PT: Payload type, 8 bits RTCP反馈消息包根据PT可分为两类： RTPFB：Transport layer FB message, PT=205 PSFB：Payload-specific FB message, PT=206 PLI和FIR均属于PSFB，且根据FMT字段进行区分： PLI：FMT=1 在PLI报文中，FCI部分为空，故其报文结构就是RTCP反馈消息的报文。 FIR：FMT=4 在FIR报文中，可能会包含多个FCI，且FCI包括两个字段，其结构如下： 1234567891011 // FCI: 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Seq nr. | Reserved = 0 | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+// SSRC：指定发送端响应该关键帧请求的媒体流// Seq nr：当前关键帧请求对应的序列号 NOTE：由PLI和FIR报文结构的差异可知，通过PLI发送的关键帧请求会作用于发送端所有的媒体流，而通过FIR发送的关键帧请求可指定发送端响应该请求的媒体流。 使用场景PLI和FIR设计初衷就是为了应对不同的使用场景，尽管二者发送的关键帧请求在发送端有可能被一视同仁。 丢包场景 PLI，Picture Loss Indication，即丢包标识，顾名思义就是用于丢包场景请求关键帧。常见的丢包场景如下： 接收端检测到丢包过多 当丢包率过高时，重传会导致延时过大，此时可通过关键帧及时刷新画面。由于关键字可单独解码，故解码时不会出现花屏，但由于之前的视频帧都被丢弃，如果该关键帧前后的画面变化过大，渲染时会出现卡顿或跳帧的情况。 发送端无丢失包的缓存 发送端会以滑动窗口的方式缓存近期发送的包，如果某个丢失包过旧，即不在滑动窗口范围内，会导致发送端无法重传该包。 H264解码时无SPS和PPS信息 当H264解码端收到的IDR帧包未包含SPS或PPS信息，会导致解码失败，此时可发送PLI请求。 解码器获取帧数超时 解码器请求关键帧或解码失败 非丢包场景 FIR请求常用于非丢包的场景，编码端在收到FIR的关键帧请求时，通常会发送一个IDR帧用于解码端的及时刷新，故FIR请求又被称为“即时解码刷新请求（Instantaneous Decoder Refresh Request）”或“视频快速刷新请求（Video Fast Update Request）”。 FIR请求常见的使用场景如下： 视频流切换 当解码器需要切换到其它的视频流时，可通过FIR请求从编码端获取一个IDR帧，及时刷新解码器。 新参与者入会 在视频会议中，当某个新用户加入时，接收端收到的不一定是关键帧，这会导致新用户不能及时解码。此时可通过发送FIR请求从编码端获取一个IDR帧，及时刷新解码器。 参考资料Media Communication RFC 5104 - Codec Control Messages in the RTP Audio-Visual Profile with Feedback (AVPF) RFC 4585 - Extended RTP Profile for Real-time Transport Control Protocol (RTCP)-Based Feedback (RTP/AVPF)","link":"/2021/04/22/WebRTC%E4%B9%8B%E5%85%B3%E9%94%AE%E5%B8%A7%E8%AF%B7%E6%B1%82/"},{"title":"WebRTC之传输协议初探：DTLS协议","text":"简述由于TLS协议主要是提供加密功能以保障通道数据的安全性，因此要求底层协议提供一个可靠且有序的通信过程，一旦数据包出现丢包或乱序的情况则会断开连接，所以UDP协议是不能和TLS协议组合使用。 现实情况是UDP协议常用于媒体数据传输，因此为了保障媒体传输的安全性，引入了DTLS协议来对UDP通信过程进行加密。DTLS是在TLS的基础为UDP定制和改进的安全传输协议，在设计上尽可能复用TLS现有的结构。 DTLS和TLS在版本上的对应关系： DTLS1.0 → TLS1.1 DTLS1.2 → TLS1.2 DTLS1.3 → TLS1.3 握手过程由于DTLS和TLS的握手过程大体上是一致的，详见 TLS协议详解，此处只列出DTLS协议改进的地方： 结构上，在Handshake和ClientHello消息中新增字段和新增HelloVerifyRequest消息： Handshake消息中新添了三个字段：message_seq、fragment_offset、fragment_length，结构所示： 1234567891011121314151617181920struct { HandshakeType msg_type; uint24 length; uint16 message_seq; // New field uint24 fragment_offset; // New field uint24 fragment_length; // New field select (HandshakeType) { case hello_request: HelloRequest; case client_hello: ClientHello; case hello_verify_request: HelloVerifyRequest; // New type case server_hello: ServerHello; case certificate:Certificate; case server_key_exchange: ServerKeyExchange; case certificate_request: CertificateRequest; case server_hello_done:ServerHelloDone; case certificate_verify: CertificateVerify; case client_key_exchange: ClientKeyExchange; case finished: Finished; } body; } Handshake; ClientHello消息新添了Cookie字段，结构如下： 12345678struct { ProtocolVersion client_version; Random random; SessionID session_id; opaque cookie&lt;0..2^8-1&gt;; // New field CipherSuite cipher_suites&lt;2..2^16-1&gt;; CompressionMethod compression_methods&lt;1..2^8-1&gt;; } ClientHello; 新增HelloVerifyRequest消息，结构如下： 1234struct { ProtocolVersion server_version; opaque cookie&lt;0..2^8-1&gt;;} HelloVerifyRequest; 功能上，增加了一些防护机制，解决重放、丢包和乱序问题: 重传机制解决丢包问题 当客户端和服务端每次发送消息后会启动一个定时器等待远端相应的消息，一旦等待超时就理解为发送的消息或等待的消息丢失，然后重发一次消息。当重传次数超过上限时仍未收到回复消息则断开连接。 序列号+分片机制解决乱序问题 TCP是面向字节流，且内置数据包的分拆和组装功能，而UDP则是面向报文，本身不支持分片和重组。所以一旦UDP报文大于MTU，则由IP层进行分片和重组。但是一旦出现丢包则重组失败，进而导致整个UDP报文丢失。 DTLS新增了分片和重组机制，因此不再会触发IP层的分片和重组机制。具体做法是在Handshake消息中新增了fragment_offset和fragment_length，分别表示当前分片在报文中的偏移量和报文的总长度。此外。DTLS还支持丢包重传，所以即便出现丢包也能进行恢复，提高重组的成功率。 当报文重组完成后会进入客户端或服务端的缓存队列，该队列用于缓存提前到达的消息，然后根据序列号对缓存消息进行排序，以解决报文乱序问题。 消息重放检测+Cookie机制 TCP中通过SYN Cookie机制来实现消息重放检测，以防范DoS攻击，TLS在1.2及之前的版本都没有相应的防范机制，直到TLS1.3才通过新增HelloRetryRequest和Cookie来解决DoS攻击。而DTLS在1.0版本就新增了HelloVerifyRequest和Cookie，用于服务端的二次校验，以防范DoS攻击。具体实现方式如下： 当客户端首次给服务端发送 Client Hello 时，服务端只会生成一个 Cookie 并通过 HelloVerifyRequest 发送给客户端，不会执行分配缓冲区等操作，直到收到带上相同 Cookie 的 Client Hello 才会继续握手，可以使得伪造 IP 的攻击难以实现。这也只是一种时间和空间上的权衡。如果攻击者发送大量的ACK包过来，那么服务端需要花费大量的CPU时间用于在计算Cookie，最终导致正常的逻辑无法被执行。 HelloVerifyRequest 足够小，即使服务端被攻击者当枪使来攻击其他机器，也不会造成大量数据发送。 结语DTLS协议在TLS协议的基础上提供了可靠性和有序性保障，可实现基于UDP协议的安全传输。鉴于DTLS协议中防护机制的实现相对比较简单，不适合用于传输音视频数据，所以一般用于传输文本数据，比如可作为SCTP协议的底层传输协议。 参考资料RFC 6347 - Datagram Transport Layer Security Version 1.2 一文读懂 DTLS 协议_mb6004f7ec10a08的技术博客_51CTO博客_DTLS协议详解 详解 WebRTC 传输安全机制：一文读懂 DTLS 协议 SYN Cookie的原理和实现_zhangskd的专栏-CSDN博客_syncookie DoS攻击手法与解决办法","link":"/2020/11/10/WebRTC%E4%B9%8B%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%EF%BC%9ADTLS%E5%8D%8F%E8%AE%AE/"},{"title":"WebRTC之包组的时间间隔计算","text":"简述在WebRTC中，使用的GCC（Google Congestion Control）作为拥塞控制算法，且该算法有新旧两个版本。二者的主要区别之一就是基于延迟的带宽估计算法的实现不同：旧版采用的是基于接收端的Kalman滤波器带宽评估算法，而新版则是基于发送端的Trendline滤波器带宽评估算法。 此前在 WebRTC之抖动估计 中简单介绍过关于时延的概念，简单说就是指一个数据包或信号从发送端抵达接收端所需的时长。由于网络拥塞等原因，即便是以均匀时间间隔连续发送的数据包，在抵达接收端时的时间间隔也很可能是不均匀的。 新版采用的Trendline滤波器算法，是一种基于包的时延梯度的变化来评估当前网络变化趋势的算法，而时延梯度的计算基于发送时间间隔（inter-departure）和抵达时间间隔（inter-arrival）。 关于Trendline滤波器带宽评估算法的具体实现留待后续，本文介绍的是关于包组时间间隔的计算方式。 在WebRTC中，引入了包组的概念，以此来计算发送时间间隔和抵达时间间隔，而非并基于单个包或帧进行计算，理由有二： 由于同一帧的所有包的发送时间是相同的，所以理论上计算发送时间间隔的粒度为帧。但是当一帧数据被拆分成多个包发送后，可能因为丢包或乱序等原因，导致在接收端不能再还原成一个完整的帧。 由于WebRTC在发送端会采用Pacer模块按簇发送包，因此包一般也是按簇抵达接收端。同一簇一般包含多个包，且包之间的抵达时间间隔很小。因此，使用包组不仅可以减少计算量，而且更符合网络传输中的真实情况，可以更好处理突发数据、丢包或乱序等情况。 代码导读在WebRTC中有一个专用于计算包组时间间隔的类：InterArrivalDelta，具体的计算过程包括以下几个步骤： 包组划分 计算包组的时间间隔的第一步就是划分包组，且至少有两个包组才能计算时间间隔。 包组的划分是基于包的发送时间间隔，在WebRTC中，如果新抵达的包的发送时间与当前包组中第一个包的发送时间之间的间隔时长大于5毫秒，则被视为新包组的第一个包。以下是GCC-02 草案给出的相关说明： The Pacer sends a group of packets to the network every burst_time interval. RECOMMENDED value for burst_time is 5 ms. 由于突发数据的存在，在划分包组之前需要对包进行预处理，避免因突发数据导致的计算误差。 处理突发数据 由于网络中断等非网络拥塞原因，路由器中待处理的数据包会被滞留在路由器的网络缓冲区。等网络重新恢复后，路由器为了及时清空缓冲区，会在短时间内将缓冲区的包发送出去，这些包就属于突发数据包。 以下是判断突发数据包的相关代码： 1234567891011121314151617181920212223242526272829bool InterArrivalDelta::BelongsToBurst(Timestamp arrival_time, Timestamp send_time) const { RTC_DCHECK(current_timestamp_group_.complete_time.IsFinite()); // NOTE：由于突发数据包之间的发送和抵达时间间隔很短，因此，在判断突发数据包时， // 应该使用包组最新的发送时间和抵达时间来计算发送时间间隔和抵达时间间隔。 // 当前包的抵达时间与当前包组最新抵达时间之间的间隔差值。 TimeDelta arrival_time_delta = arrival_time - current_timestamp_group_.complete_time; // 当前包的发送时间与当前包组的最新发送时间之间的间隔差值。 TimeDelta send_time_delta = send_time - current_timestamp_group_.send_time; // 发送时间间隔差值为0，表示当前包与当前包组中最近抵达的包属于同一帧，因为也属于当前包组。 if (send_time_delta.IsZero()) return true; // 当前包与当前包组的时延差值，即时延梯度。 TimeDelta propagation_delta = arrival_time_delta - send_time_delta; // 判断当前包是否属于突发数据包，需同时满足一下三个条件： // 1. 时延梯度小于0，即抵达时间间隔大于发送时间间隔； // 2. 抵达时间间隔小于或等于5ms，即接收端的抵达时间间隔小于发送端的发送时间间隔， // 此外，结合条件1可得：发送时间间隔一定是小于5ms的； // 3. 当前包与当前包组中最早抵达的包之间的抵达时间间隔小于100ms，因为突发数据包一定是在短时间内抵达的； if (propagation_delta &lt; TimeDelta::Zero() &amp;&amp; arrival_time_delta &lt;= /*5ms*/kBurstDeltaThreshold &amp;&amp; arrival_time - current_timestamp_group_.first_arrival &lt; /*100ms*/kMaxBurstDuration) return true; // 当前包不属于突发数据包。 return false;} 划分包组 如果当前包不属于突发数据包，则根据发送时间间隔判断当前包是否属于新的包组： 12345678910111213141516171819bool InterArrivalDelta::NewTimestampGroup(Timestamp arrival_time, Timestamp send_time) const { if (current_timestamp_group_.IsFirstPacket()) { // 当前包组的首个抵达的包一定是属于当前包组的。 return false; } else if (BelongsToBurst(arrival_time, send_time)) { // 突发数据包属于当前包组。 return false; } else { // NOTE：此处使用的包组中最早抵达的包的发送时间来计算发送时间间隔，原因在于： // 包组在接收新包时已经将乱序包过滤掉，保证了包组中的其他所有包的发送时间都是 // 小于首个包的发送时间。换言之，包组中的所有包可以理解为是有序的。 // 计算当前包与当前包组中最早抵达的包之间的发送时间间隔，如果大于|send_time_group_length| //（默认值为5ms），则当前包被划分为新的包组，否则属于当前包组。 return send_time - current_timestamp_group_.first_send_time &gt; send_time_group_length_; }} 计算包组的时间间隔 相关的代码位于InterArrivalDelta::ComputeDeltas中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293bool InterArrivalDelta::ComputeDeltas(Timestamp send_time, Timestamp arrival_time, Timestamp system_time, size_t packet_size, TimeDelta* send_time_delta, TimeDelta* arrival_time_delta, int* packet_size_delta) { // 计算包组的时间间隔的前提是：已有两个完成的包组，因此每次更新满足不一定会满足计算条件。 bool calculated_deltas = false; // 当前包是当前包组首个抵达的包，加入当前包组。 if (current_timestamp_group_.IsFirstPacket()) { // We don't have enough data to update the filter, so we store it until we // have two frames of data to process. current_timestamp_group_.send_time = send_time; current_timestamp_group_.first_send_time = send_time; current_timestamp_group_.first_arrival = arrival_time; } else if (current_timestamp_group_.first_send_time &gt; send_time) { // 如果当前包的发送时间早于比当前包组首个抵达的包，则视为乱序包。 // 过滤乱序包，即包组中的其他包都是在首个抵达的包之后发送的， // 以确保在函数NewTimestampGroup中划分新包组时的有效性。 // Reordered packet. return false; } else if (NewTimestampGroup(arrival_time, send_time)) { // 不包括新的包组，当前已经有两个完整的包组，则开始计算包组的时间间隔。 // First packet of a later send burst, the previous packets sample is ready. if (prev_timestamp_group_.complete_time.IsFinite()) { // 计算相邻的两个包组的发送时间间隔。 *send_time_delta = current_timestamp_group_.send_time - prev_timestamp_group_.send_time; // 计算相邻的两个包组的抵达时间间隔。 *arrival_time_delta = current_timestamp_group_.complete_time - prev_timestamp_group_.complete_time; // 计算包组的系统时间偏差值。 TimeDelta system_time_delta = current_timestamp_group_.last_system_time - prev_timestamp_group_.last_system_time; // 系统时钟的偏差过大，超过3s，则重置包组信息。理由是什么？ if (*arrival_time_delta - system_time_delta &gt;= kArrivalTimeOffsetThreshold) { RTC_LOG(LS_WARNING) &lt;&lt; \"The arrival time clock offset has changed (diff = \" &lt;&lt; arrival_time_delta-&gt;ms() - system_time_delta.ms() &lt;&lt; \" ms), resetting.\"; Reset(); return false; } // 如果接收端在某一段时间内收到大量的重传包或乱序包，可能会导致包组划分也出现乱序的情况。 // 因此，在计算包组的时间间隔之前需要判断当前的两个包组是否是乱序的。 // 如果当前相邻的两个包组是乱序的，则不计算包组的时间间隔。 if (*arrival_time_delta &lt; TimeDelta::Zero()) { // 记录包组乱序的累积次数，如果累积超过3次，表示当前时段网络中的重传包或乱序包就较多， // 则重置包组信息。 // The group of packets has been reordered since receiving its local // arrival timestamp. ++num_consecutive_reordered_packets_; if (num_consecutive_reordered_packets_ &gt;= kReorderedResetThreshold) { RTC_LOG(LS_WARNING) &lt;&lt; \"Packets between send burst arrived out of order, resetting.\" &lt;&lt; \" arrival_time_delta\" &lt;&lt; arrival_time_delta-&gt;ms() &lt;&lt; \" send time delta \" &lt;&lt; send_time_delta-&gt;ms(); Reset(); } return false; } else { // 如果当前相邻的两个包组是顺序的，则忽略之前的乱序包组，使用当前的包组计算。 num_consecutive_reordered_packets_ = 0; } // 计算包组之间数据大小的差值 *packet_size_delta = static_cast&lt;int&gt;(current_timestamp_group_.size) - static_cast&lt;int&gt;(prev_timestamp_group_.size); // 表示更新了包组的时间间隔 calculated_deltas = true; } // 将新包组更新为当前包组 prev_timestamp_group_ = current_timestamp_group_; // The new timestamp is now the current frame. current_timestamp_group_.first_send_time = send_time; current_timestamp_group_.send_time = send_time; current_timestamp_group_.first_arrival = arrival_time; current_timestamp_group_.size = 0; } else { // 使用包组中最新发送的包的发送时间作为包组的发送时间 current_timestamp_group_.send_time = std::max(current_timestamp_group_.send_time, send_time); } // 更新当前包组的信息 // Accumulate the frame size. current_timestamp_group_.size += packet_size; current_timestamp_group_.complete_time = arrival_time; current_timestamp_group_.last_system_time = system_time; return calculated_deltas;} NOTE：系统时钟是以系统启动为基准点开始计时的，因此每次系统启动后都会重新计时，具体介绍可参考 计算机中几个与时间相关的概念 。 参考资料draft-ietf-rmcat-gcc-02","link":"/2021/04/20/WebRTC%E4%B9%8B%E5%8C%85%E7%BB%84%E7%9A%84%E6%97%B6%E9%97%B4%E9%97%B4%E9%9A%94%E8%AE%A1%E7%AE%97/"},{"title":"WebRTC之抖动估计","text":"时延和抖动时延和抖动是两个不同但又相互关联的概念。时延是网络通信中的一个重要指标，用于衡量数据包从一个端点传送到另外一个端点所需的时间。 在网络通信中，连续发送的数据包即便使用相同的路径也会产生不同的时延。原因在于，路由器一次只能处理一个数据包。当数据包抵达的速度大于路由器处理数据包的速度，会被暂时放入路由器的网络缓冲区，等待路由器的处理和转发，从而增加了数据包的传输时延。 抖动就是用于表示数据包之间传输时延的不一致性，即用来衡量数据包传输时延的变化程度。 导致抖动产生的原因有很多，比如网路拥塞，网路错误，丢包等。 抖动缓冲区抖动的幅度过大和过于频繁会影响用户体验，比如抖动会使接收端接受到的帧率变低，进而导致后续的解码和播放出现卡顿。因此，常用的作法是在接收端引入抖动缓冲区，用于缓存并处理一段时间内的数据包，然后再把累积的数据包以均匀的间隔传送给后续操作。 使用抖动缓冲区会引入一个新的问题，即增加播放时延。所谓播放时延是指数据包抵达接收端的时间到最终播放之间的时延。播放时延过长会影响用户体验，因此，抖动缓冲区设计和采用的缓存策略很重要。在WebRTC中，分别使用NetEQ和JitterBuffer处理音频和视频的抖动，以消减抖动造成的影响，尽可能地降低播放时延。 抖动估计RFC3550 中给出的计算公式： 首先，使用分别表示第个数据包发送和接收的时间，使用分别表示第个数据包发送和接收的时间，那么这两个数据包传输时延时延的差异值为： 然后，使用一次指数平滑法来消除噪音和过滤掉突发数据的影响，最终得到一个较为合理的估计值： 其中，表示当前的估计值， 表示上一次的估计值，表示当前观测值，即 ，表示加权系数，即增益参数，WebRTC中。 在WebRTC中有两种抖动的估计算法，分别用于以下两处: 抖动缓冲区 WebRTC中NetEQ和JitterBuffer使用的抖动估计算法比较复杂：除了在计算时考虑了时间回绕，还将计算结果作为观测值传递给卡尔曼滤波器，最终获得一个较为精确的jitter估计值，用于后续的解码和同步播放。详细内容留待后续。 统计参数 本文介绍的是用作统计参数的抖动估计算法。由于这个抖动估计值只是作为统计参数以提供感观参考，所以使用的估计算法相对比较简单：使用一次指数平滑过滤噪音。 这个抖动估计值对应于RTCP Report block包的interarrival jitter字段： 123456789101112130 1 2 30 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| fraction lost | cumulative number of packets lost |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| extended highest sequence number received |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| interarrival jitter |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| last SR (LSR) |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| delay since last SR (DLSR) |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ 代码导读WebRTC中统计参数jitter的估算代码位于文件/src/modules/rtp_rtcp/source/receive_statistics_impl.cc中，函数调用栈为： StreamStatisticianImpl::UpdateCounter 该函数用于统计Rtcp report block中相关的参数，在接收端收到RTP包时被调用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748void StreamStatisticianImpl::UpdateCounters(const RtpPacketReceived&amp; packet) { RTC_DCHECK_EQ(ssrc_, packet.Ssrc()); int64_t now_ms = clock_-&gt;TimeInMilliseconds(); // 接受端码率统计 incoming_bitrate_.Update(packet.size(), now_ms); // 最近一个RTP包的抵达时间 receive_counters_.last_packet_received_timestamp_ms = now_ms; // 统计所有接收到的RTP包，包括重发包 receive_counters_.transmitted.AddPacket(packet); --cumulative_loss_; // 包序号解回绕 int64_t sequence_number = seq_unwrapper_.UnwrapWithoutUpdate(packet.SequenceNumber()); // 接收到的第一个包 if (!ReceivedRtpPacket()) { received_seq_first_ = sequence_number; last_report_seq_max_ = sequence_number - 1; received_seq_max_ = sequence_number - 1; receive_counters_.first_packet_time_ms = now_ms; // 过滤掉乱序包 } else if (UpdateOutOfOrder(packet, sequence_number, now_ms)) { return; } // 正常包 // In order packet. cumulative_loss_ += sequence_number - received_seq_max_; received_seq_max_ = sequence_number; // 更新当前包序号以便下一次计算 seq_unwrapper_.UpdateLast(sequence_number); // 更新抖动需同时满足的两个条件： // 1、新接收的包与上一次接收的包源于不同帧，因为同一帧的数据包发送的时间戳是相同的。换言之，抖动估计的最小粒度为帧而非单个数据包。 // 2、收到的正常包的个数比乱序包至少多1个以上，以确保抖动估计的参考价值，此处存疑？？ // If new time stamp and more than one in-order packet received, calculate // new jitter statistics. if (packet.Timestamp() != last_received_timestamp_ &amp;&amp; (receive_counters_.transmitted.packets - receive_counters_.retransmitted.packets) &gt; 1) { // 计算抖动估计值 UpdateJitter(packet, now_ms); } last_received_timestamp_ = packet.Timestamp(); last_receive_time_ms_ = now_ms;} StreamStatisticianImpl::UpdateJitter 该函数用于计算抖动估计值，且计算结果采用Q4格式表示。 123456789101112131415161718192021222324252627282930313233343536void StreamStatisticianImpl::UpdateJitter(const RtpPacketReceived&amp; packet, int64_t receive_time_ms) { // 接收端时延，单位为毫秒 int64_t receive_diff_ms = receive_time_ms - last_receive_time_ms_; RTC_DCHECK_GE(receive_diff_ms, 0); // 计算接收端时延，并将单位转换成采样时间戳单位 uint32_t receive_diff_rtp = static_cast&lt;uint32_t&gt;( (receive_diff_ms * packet.payload_type_frequency()) / 1000); // 计算发送端时延，此处未考虑时间回绕问题，我认为原因有两个： // 1、简化计算，毕竟只是一个统计参数 // 2、出现时间回绕时，|send_diff_rtp|会是一个负数，使用uint32_t表示则会是极大值。 // 导致接下来计算的|time_diff_samples|也会是极大值，在更新时被视为突发数据而被过滤掉。 uint32_t send_diff_rtp = packet.Timestamp() - last_received_timestamp_; // 计算接收时延与发送时延的差值，单位为采样时间戳 int32_t time_diff_samples = receive_diff_rtp - send_diff_rtp; // 取时延差值的绝对值以方便计算 time_diff_samples = std::abs(time_diff_samples); // 过滤因为突发数据导致的剧烈抖动，对应的时延差值为5秒 // lib_jingle sometimes deliver crazy jumps in TS for the same stream. // If this happens, don't update jitter value. Use 5 secs video frequency // as the threshold. // 出于优化考虑，默认使用视频的采样率，450000=5s x 90000kbps. if (time_diff_samples &lt; 450000) { // 使用Q4格式以避免浮点数计算 // Note we calculate in Q4 to avoid using float. // 由于|jitter_q4_|采用的是Q4格式，因此需要将|time_diff_samples|转换成Q4格式再进行计算。 int32_t jitter_diff_q4 = (time_diff_samples &lt;&lt; 4) - jitter_q4_; // 一次指数平滑法，参考上述公式（2）： // J(i) = J(i-1) + (|D(i-1,i)| - J(i-1))/16 // = jitter_q4_ + jitter_diff_q4 / 16 // = jitter_q4_ + (jitter_diff_q4 &gt;&gt; 4) jitter_q4_ += ((jitter_diff_q4 + /*四舍五入*/8) &gt;&gt; 4); }} 由于抖动估算值采用的是Q4格式，且单位为采样时间戳，因此，在作为统计参数使用时需要进行如下转换： 12345// 从Q4格式还原成普通数值uint32_t jitter = jitter_q4_ &gt;&gt; 4;// 将单位从采样时间戳转换成毫秒，clock_rate_hz为音频或视频的采样率double jitter_ms = static_cast&lt;double&gt;(jitter * 1000 / clock_rate_hz) 参考资料RFC 3550 - RTP: A Transport Protocol for Real-Time Applications 抖动和延迟之间的区别","link":"/2021/04/05/WebRTC%E4%B9%8B%E6%8A%96%E5%8A%A8%E4%BC%B0%E8%AE%A1/"},{"title":"WebRTC之传输协议初探：DTLS协议在WebRTC中应用","text":"简述DTLS在WebRTC中主要提供两个功能： 协商SRTP加密密钥 虽然DTLS协议提供了解决丢包和乱序的机制，但是具体实现方案比较简单，对于音视频这类对丢包和乱序更为敏感的数据包有点力不从心。因此WebRTC中RTP（Real-time Transport Protocol）协议作为音视频包的传输协议。而SRTP（Secure Real-time Transport Protocol）在RTP协议之上，为RTP包提供了加密、消息认证和完整性以及重放攻击等保护。 SRTP作为安全协议，采用的是对称加密算法，而密钥协商则是通过DTLS协议，具体协商过程留待下文。 为SCTP协议提供加密通道 SCTP是一种在网络连接两端之间同时传输多个数据流的协议，提供的服务与UDP和TCP类似，同样SCTP本身不提供加密功能。因此在WebRTC中使用DTLS作为SCTP的底层协议，为SCTP中的消息提供加密等一系列安全保护。 SCTP密钥协商过程由于SCTP密钥协议依赖于DTLS协议，因此其过程包含了DTLS的握手过程。 DTLS同TLS一样，握手过程中有client和server的两个角色。但是在WebRTC中没有这样的角色划分，因此在使用DTLS之前需要先进行角色协商。 此外，DTLS的握手过程还可能需要进行身份验证，因此在还需要进行证书交换。 注：角色协商和证书交换的可靠性在于SPD是通过安全的信令通道完成交换的，比如信令通道是是基于Https协议。 角色协商 在WebRTC中DTLS协商角色是通过SDP（Session Description Protocol）协议实现的，在SDP的描述如下： 1a=setup:actpass setup属性有三个值，分别是： setup:active，表示 client，主动发起协商 setup:passive, 表示 server，等待发起协商 setup:actpass, 表示既可以是 client也可以是server 详见 rfc4145 证书交换 在WebRTC中，通信的双方通常无法获得由知名根证书颁发机构（CA）签名的身份验证证书，因此自签名证书通常的唯一的选择。WebRTC采用机制是：将自签名证书的哈希值，即证书指纹，通过SDP传输给对方。因为在角色协商之前任一方都可能是sever，所以双方都必须获得对方的证书指纹，用于后续DTLS的身份验证。如果DTLS中对方提供的证书与SDP中的指纹匹配，则可以表示对方是可信任的。 DTLS协议握手 DTLS协议握手过程不再赘述，详见 DTLS协议初探 但是，由于WebRTC中DTLS需要支持SRTP密钥的协商，因此在ClientHello和ServerHello中加入了use_srtp扩展，用于协商SRTP使用的加密套件。 导出STP密钥 使用DTLS协商后导出的master_secret，client_random，server_random生成key block: 1key_block = PRF(master_secret, \"EXTRACTOR-dtls_srtp\", client_random + server_random)[length] 计算需要从SRTP的master_secret的字节数： 在rfc5764中描述了计算公式： 123// 2 *（主密钥长度 + 主密钥盐值长度）/ 8 srtp_master_secret_bytes = 2 * (SRTPSecurityParams.master_key_len + SRTPSecurityParams.master_salt_len) bytes of data use_srtp扩展可知SRTP协商使用的加密套件，常用的SRTP加密套件及其描述如下: 详见：rfc5764 12345678910111213141516171819202122232425262728293031323334SRTP_AES128_CM_HMAC_SHA1_80 cipher: AES_128_CM cipher_key_length: 128 cipher_salt_length: 112 maximum_lifetime: 2^31 auth_function: HMAC-SHA1 auth_key_length: 160 auth_tag_length: 80SRTP_AES128_CM_HMAC_SHA1_32 cipher: AES_128_CM cipher_key_length: 128 cipher_salt_length: 112 maximum_lifetime: 2^31 auth_function: HMAC-SHA1 auth_key_length: 160 auth_tag_length: 32 RTCP auth_tag_length: 80SRTP_NULL_HMAC_SHA1_80 cipher: NULL cipher_key_length: 0 cipher_salt_length: 0 maximum_lifetime: 2^31 auth_function: HMAC-SHA1 auth_key_length: 160 auth_tag_length: 80SRTP_NULL_HMAC_SHA1_32 cipher: NULL cipher_key_length: 0 cipher_salt_length: 0 maximum_lifetime: 2^31 auth_function: HMAC-SHA1 auth_key_length: 160 auth_tag_length: 32 RTCP auth_tag_length: 80 假设协商的加密套件是SRTP_AES128_CM_HMAC_SHA1_80，那么master secret的字节数为： 123srtp_master_secret_bytes = 2 * (cipher_key_length + cipher_salt_length) / 8 = 2 * (128 + 112) / 8 = 240 / 4 = 60 // 字节 导出SRTP密钥 获得master secret后，按顺序分别逐段截取出：客户端master_key，服务端master_key，客户端master_salt，服务端master_salt，详见：rfc5764 12345678// 客户端master_key，长度为16字节client_write_SRTP_master_key[SRTPSecurityParams.master_key_len];// 服务端master_key，长度为16字节server_write_SRTP_master_key[SRTPSecurityParams.master_key_len];// 客户端master_salt，长度为14字节client_write_SRTP_master_salt[SRTPSecurityParams.master_salt_len];// 客户端master_salt，长度为14字节server_write_SRTP_master_salt[SRTPSecurityParams.master_salt_len]; 随后，使用master_key和master_salt作为SRTP或SRTCP的KDF（Key Derivation Function）的参数分别生成用于加密和签名密钥。如下图所示： 123456789101112131415161718192021222324252627TLS master secret label | | v v +---------------+ | TLS extractor | +---------------+ | +------+ SRTP +-&gt; client_write_SRTP_master_key ----+---&gt;| SRTP |-&gt; client | | +-&gt;| KDF | write | | | +------+ keys | | | +-&gt; server_write_SRTP_master_key -- | | +------+ SRTCP | \\ \\---&gt;|SRTCP |-&gt; client | \\ +-&gt;| KDF | write | | | +------+ keys +-&gt; client_write_SRTP_master_salt ---|-+ | | | | +------+ SRTP | +---&gt;| SRTP |-&gt; server +-&gt; server_write_SRTP_master_salt -+-|---&gt;| KDF | write | | +------+ keys | | | | +------+ SRTCP | +---&gt;|SRTCP |-&gt; server +-----&gt;| KDF | write +------+ keys 至此，完成基于TLS协商的master_secret导出SRTP密钥的全过程。 参考资料详解 WebRTC 传输安全机制：一文读懂 DTLS 协议 RFC 5764 - Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP)","link":"/2020/11/16/WebRTC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%E4%B9%8BDTLS%E5%8D%8F%E8%AE%AE%E5%9C%A8WebRTC%E4%B8%AD%E5%BA%94%E7%94%A8/"},{"title":"YUV格式详解","text":"简述YUV色彩模型不同于RGB的新模型，其原理是利用人类视觉对色彩的亮度比色差更为敏感的特点，将亮度信息从色度信息中分离出来，即使没有色度信息一样可以显示完整的图像，只不过是黑白的。这样的设计很好的解决了彩色电视与黑白电视兼容的问题。 YUV使用三个分量来表示像素颜色，分别是： Y：Luma 表示明亮度，描述像素的灰度值 U 和 V ：Chroma 表示色度，描述像素的色调及饱和度 YUV可以通过缩放和偏移衍生出很多变种，其中YCbCr是在计算机系统中应用最多的一种，JPEG和MPEG均采用这种格式。YCbCr中的Y表示亮度分量，Cb表示蓝色色度分量，Cr表示红色色度分量。 多种采样格式YUV色彩模型支持Y（亮度分量）和UV （色度分量）使用不同的采样率，主流的采样方式有三种，分别是： YUV4:4:4 采样 Y分量和UV分量的采样比例相同，即每1个Y分量对于1组UV分量。这种采用方式和RGB色彩模型的图像大小一样。 YUV4:2:2 采样 Y分量和UV分量按照2:1的比例采样，即每采样两个Y分量才采样一组UV分量，因此每2个Y分量对于1组UV分量。这种采用方式比RGB格式节省1/3的存储空间。 YUV4:2:0 采样 Y分量和U或V分量按照2:1的比例采样，即每采样两个Y分量才采样一个U分量或V分量，因此每4个Y分量对于1组UV分量。这种采用方式比RGB格式节省1/2的存储空间。因此，YUV4:2:0被选为主流的采样方式。 两种存储格式YUV有两种存储格式，分别是： planar格式 先连续存储所有像素点的Y分量，然后是所有像素点的U分量，最后是所有像素点的V分量。比如YUV422P、YUV420P、YUV420SP、YV12和YU12 (属于YUV420)等。 packed格式 每个像素点的Y、U、V分量连续交叉存储。大部分的采样方式都是采用packed格式的存储方式。 以16x16的图像为例，以下是常见的YUV存储格式： YUYV格式 YUYV格式属于YUV422采样格式，采用packed存储方式。像素点还原方式：相邻的两个Y分量共用其相邻的两个Cb、Cr分量，比如像素点Y00和Y01共用Cb00和Cr00，其他的像素点以此类推。 1234start + 0: Y00 Cb00 Y01 Cr00 Y02 Cb01 Y03 Cr01start + 8: Y10 Cb10 Y11 Cr10 Y12 Cb11 Y13 Cr11start + 16: Y20 Cb20 Y21 Cr20 Y22 Cb21 Y23 Cr21start + 24: Y30 Cb30 Y31 Cr30 Y32 Cb31 Y33 Cr31 UYVY格式 ，采用packed存储格式 UYVY格式属于YUV422采样格式，采用packed存储方式。与YUYV格式区别在于UV的排列顺序不同，还原像素点的方式与YUYV一样。 1234start + 0: Cb00 Y00 Cr00 Y01 Cb01 Y02 Cr01 Y03start + 8: Cb10 Y10 Cr10 Y11 Cb11 Y12 Cr11 Y13start + 16: Cb20 Y20 Cr20 Y21 Cb21 Y22 Cr21 Y23start + 24: Cb30 Y30 Cr30 Y31 Cb31 Y32 Cr31 Y33 YUV422P YUV422P，又叫I422，属于YUV422采样格式，采用planar存储方式。 123456789101112131415-------------------------------Y分量start + 0: Y00 Y01 Y02 Y03start + 4: Y10 Y11 Y12 Y13start + 8: Y20 Y21 Y22 Y23start + 12: Y30 Y31 Y32 Y33-------------------------------U分量start + 16: Cb00 Cb01 start + 18: Cb10 Cb11 start + 20: Cb20 Cb21 start + 22: Cb30 Cb31-------------------------------V分量start + 24: Cr00 Cr01 start + 26: Cr10 Cr11 start + 28: Cr20 Cr21 start + 30: Cr30 Cr31 I420、YV12 I420和YV12都属于YUV420采用格式，采用planar存储方式。I420格式和YV12格式的不同处在U分量和V分量存放的顺序不同。在I420格式中，U分量在V分量之前，故又叫YU12。YV12则恰好相反，U分量在V分量之后。以下是I420的存储格式： 1234567891011-------------------------------Y分量start + 0: Y00 Y01 Y02 Y03start + 4: Y10 Y11 Y12 Y13start + 8: Y20 Y21 Y22 Y23start + 12: Y30 Y31 Y32 Y33-------------------------------U分量start + 16: Cb00 Cb01 start + 18: Cb10 Cb11-------------------------------V分量start + 20: Cr00 Cr01 start + 22: Cr10 Cr11 NV12、NV21 NV12和NV21属于YUV420采样格式，是一种two-plane模式，Y分量视为一个plane，UV合并视为一个plane。Y和UV两个plane采用planar存储方式，但是UV内部为packed存储方式。 12345678-------------------------------Y分量start + 0: Y00 Y01 Y02 Y03start + 4: Y10 Y11 Y12 Y13start + 8: Y20 Y21 Y22 Y23start + 12: Y30 Y31 Y32 Y33-------------------------------UV分量start + 16: Cb00 Cr00 Cb01 Cr01start + 20: Cb10 Cr10 Cb11 Cr11 YUV与RGB转换鉴于使用YUV422格式或YUV420格式，能够在RGB格式的基础上显著地减少的数据量，且YUV422和YUV420的数据量为RGB的2/3和1/2。因此常将RGB转换成YUV格式进行传输，然后再将YUV格式转换成RGB格式进行显示。二者的转换公式如下： YUV转RGB： 123Y = 0.299 * R + 0.587 * G + 0.144 * BU = -0.168 * R - 0.331 * G + 0.5 * B + 128V = 0.5 * R - 0.419 * G - 0.081 * B + 128 RGB转YUV: 123R = Y + 1.13983 * (V - 128)G = Y - 0.39465 * (U - 128) - 0.58060 * (V - 128)B = Y + 2.03211 * (U - 128) 参考资料YUV - 维基百科，自由的百科全书 YUV色彩模型与RGB色彩模型详解_jane_6091的博客-CSDN博客_yuv颜色模型 YUV编码格式 图文详解YUV420数据格式","link":"/2020/03/20/YUV%E6%A0%BC%E5%BC%8F%E8%AF%A6%E8%A7%A3/"},{"title":"Cocoa程序退出前发送HttpRequest请求","text":"最近在视频投送项目中遇到一个奇葩问题，花费了一整天时间才得以解决。这个问题比较隐晦，值得记录一下。 根据功能需要，需要在cocoa程序退出前，发送一个关闭设备的指令，本质上就是post一个Http请求，用于中止当前出于投送状态的设备。 具体代码如下： 在回调函数- (void)applicationWillTerminate:中调用停止投送API 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 - (void)applicationWillTerminate:(NSNotification *)aNotification { // Insert code here to tear down your application [[CastHelper sharedInstance] stopCast]; }````将stop指令集成到URL里面，加入投送队列castOperationQueue中，然后通过HttpRequest发送出去。```objc - (void)stopCast { dispatch_async(castOperationQueue, ^{ for (ZDCastDevice * device in self.connectedDeviceInfo.allValues ) { //发送stop请求 [self sendRequestURL:@\"192.168.1.1/xxx/stop\" HTTPMethod:@\"POST\" completionHandler:completionHandler]; } }); } //异步请求 - (void)sendRequestURL:(NSURL *)url HTTPMethod:(NSString *)httpMethod { NSMutableURLRequest *request = [[NSMutableURLRequest alloc] init]; [request setURL:url]; [request setHTTPMethod:httpMethod]; [request setValue:@\"application/json;charset=UTF-8\" forHTTPHeaderField:@\"Content-Type\"]; [request setHTTPBody:nil]; [[[NSURLSession sharedSession] dataTaskWithRequest:request completionHandler:^(NSData * _Nullable data, NSURLResponse * _Nullable response, NSError * _Nullable error) { //Error if (error) { }else { NSInteger statusCode = [(NSHTTPURLResponse *)response statusCode]; //successed if ( statusCode == 200) { //failed }else { } } }] resume]; } 在程序正常运行期间，使用上述代码能够正常的执行stop指令，并接受相应的响应。但是，如果在applicationWillTerminate这一函数中调用，通过断点调试发现Request并未成功发送出去，程序就退出了。 一开始以为是异步发送请求的原因，于是使用dispatch_semaphore_t信号量进行同步，执行结果一样，未解锁之前程序就退出了。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //异步请求 - (void)sendRequestURL:(NSURL *)url HTTPMethod:(NSString *)httpMethod { NSMutableURLRequest *request = [[NSMutableURLRequest alloc] init]; [request setURL:url]; [request setHTTPMethod:httpMethod]; [request setValue:@\"application/json;charset=UTF-8\" forHTTPHeaderField:@\"Content-Type\"]; [request setHTTPBody:nil]; //创建信号量 dispatch_semaphore_t semp = dispatch_semaphore_create(0); [[[NSURLSession sharedSession] dataTaskWithRequest:request completionHandler:^(NSData * _Nullable data, NSURLResponse * _Nullable response, NSError * _Nullable error) { //Error if (error) { }else { NSInteger statusCode = [(NSHTTPURLResponse *)response statusCode]; //successed if ( statusCode == 200) { //failed }else { } } dispatch_semaphore_signal(semp); }] resume]; //等待接受到请求响应才执行后续代码 dispatch_semaphore_wait(semp, DISPATCH_TIME_FOREVER); } 同步请求方式的方式也试过，结果同样达不到预期效果。代码如下： 123456789101112131415NSURLResponse* response = nil; NSError * error = nil; [NSURLConnection sendSynchronousRequest:request returningResponse:&amp;response error:&amp;error]; if (error) { HTTPLogInfo(@\"%s:%d - Error: %@\" , __func__ , __LINE__ , [error localizedDescription]); }else { HTTPLogInfo(@\"%s:%d - response: %@\" , __func__ , __LINE__ , [response description]); } 思来想去，觉得可能是程序退出去前，只有主线程有效，其他线程均被释放了。于是，把调用stop指令的代码放入主线程队列： 123456789101112131415161718- (void)stopCast{ //加入主线程队列 dispatch_async(dispatch_get_main_queue(), ^{ for (ZDCastDevice * device in self.connectedDeviceInfo.allValues ) { //发送stop请求 [self sendRequestURL:@\"192.168.1.1/xxx/stop\" HTTPMethod:@\"POST\" completionHandler:completionHandler]; } }); } 执行结果还是同之前一样。最后，仔细回想了一下RunLoop的执行过程，很可能是RunLoop在执行了applicationWillTerminate函数所在的任务之后就直接退出了，也就不会执行主线程队列后续的任务了。 于是，直接把调用stop指令的函数放在与applicationWillTerminate同一个任务中，代码如下： 123456789- (void)stopCast{ //发送stop请求 [self sendRequestURL:@\"192.168.1.1/xxx/stop\" HTTPMethod:@\"POST\" completionHandler:completionHandler]; } 果然不出所料，Request执行成功，并获得相应的Response。 小结上述言论都是基于我的猜测，我暂时没有去验证。这个问题比较隐晦，有点违背习惯性的思维。改天抽空结合Apple源代码进行分析验证，此处留坑。","link":"/2017/05/05/cocoa%E7%A8%8B%E5%BA%8F%E9%80%80%E5%87%BA%E5%89%8D%E5%8F%91%E9%80%81Request%E8%AF%B7%E6%B1%82/"},{"title":"iOS开发之storyboard中三种常用的页面跳转方式","text":"页面跳转属于iOS开发中很常用的一个功能，然而即便是这个看似简单的功能也可以根据不同需求有三个实现方式。下面一一介绍。 方式一：建立Button与目标VC之间Segue这种方式可直接在storyboard上完成，右击源VC上的一个按钮会出现一个接菜单，选择菜单中的“Triggred Segues”下的“action”，然后与目标VC建立一条指定跳转类型（比如Present Modally）的segue。 特点：操作简单，在storyboard上即可完成，不需要额外的手写代码。 方式二：建立源VC与目标VC之间Segue这种方式是在两个VC之间建立一条segue，然后在代码中根据Identify来获取对应的segue对象，调用performSegue函数来触发跳转。 特点：可以将跳转操作的触发与任意的控件绑定，需要添加额外的手写代码来完成绑定功能。 方式一：基于既有的Segue重复显示同一个目标VC这种方式其实是建立在第二种方式之上的，不同的地方在于这种方式会retain目标VC，这样确保在除第一次跳转之后不会再创建新的VC。因为前面两中方式都会在每次跳转时创建一个新的VC。 特点：可以重复使用和显示目标VC的数据。 GitHub Demo","link":"/2015/06/12/iOS%E5%BC%80%E5%8F%91%E4%B9%8B%E4%B8%89%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BD%AC%E6%96%B9%E5%BC%8F/"},{"title":"iOS开发之真机测试问题：Could not locate device support files","text":"最近在做iOS真机测试时出现了运行失败的提示：“Could not locate device support files”。原因在于我的iPhone6上的iOS版本上11.4，而Xcode的版本是8.3.3，当前的Xcode过低不能将App安装到iOS11.4上。 在目录**/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/DeviceSupport/**下可以查看当前Xcode所能支持的最高iOS版本。在我的电脑上，Xcode8.3.3自带（默认）所能支持最高的iOS版本是10.3.1 (14E8301)，版本号后面的括号时该iOS版本的编译ID，可以忽略。 解决方法一般有两种： 安装与iPhone中iOS版本对应的Xcode版本，或者直接安装最新的Xcode版本。这种虽然简单，但是安装Xcode耗时太长，除非你恰巧有升级Xcode的需求，可以考虑这种方案。 拷贝与iPhone中iOS版本对应的Device Support文档到目录**/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/DeviceSupport/**中，然后重启Xcode即可。 至于Device Support文档的来源，我想这个GitHub仓库应该能够满足你的需求。","link":"/2015/07/25/iOS%E5%BC%80%E5%8F%91%E4%B9%8B%E7%9C%9F%E6%9C%BA%E6%B5%8B%E8%AF%95%E9%97%AE%E9%A2%98%EF%BC%9ACould%20not%20locate%20device%20support%20files/"},{"title":"memset函数的使用陷阱","text":"memset是C/C++编程中常用的函数，一般用于申请内存后的初始化操作，比如： 12char* buffer = (char*)malloc(1024);memset(buffer, 0x0, 1024); memset接收三个参数： 第一个参数是开始填充的地址 第二个参数是填充的byte 第三个参数要填充的字节数（注意是字节数） 这个函数看似简单，但是如果使用不当则会导致一些未知的bug。以下是目前遇到的几个陷阱。 陷阱一： memset是按字节赋值，虽然第二个参数是int类型，但有效值只取低位的一个字节。这也是为什么第三个参数强调的是填充的字节数而非填充长度，如下。 1234int a[2]; memset(a, 0x1203, 2);// expect: a = {0x00000003, 0x00000003}// actual: a = {0x03030303, 0x03030303} 使用建议： 最好只用于单字节数组的初始化，e.g., char[]，uint8_t[]。这样不需要担心第二个或第三个参数的取值。 用于非单字节的数组的初始化时，第二个参数只能是0（b00000000）或-1（b11111111）。 陷阱二： memset函数的第三个参数慎用sizeof的结果。 因为静态数组作为参数传入某个函数的时候，就会退化成指针，也就是该数组的首地址，其数组的长度信息就丢失。如下： 123456int a[] = {1,2,3,4,5};// sizeof(a) = 20// 静态数组a退化成指针，因此sizeof的结果为4.memset(s, 0, sizeof(a)/*the result = 4*/);// expect: a = {0, 0, 0, 0, 0}// actual: a = {0, 2, 3, 4, 5} 参考资料 1. 性能杀手：”潜伏”的memset_华仔-技术博客-CSDN博客_memset性能","link":"/2019/03/10/memset%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%E9%99%B7%E9%98%B1/"},{"title":"《Effective Modern C++》条款1：理解模板型别推导","text":"简述一个函数模板的声明和调用大致形如： 123456// 声明template&lt;typename T&gt;void f(ParamType param); // ParamType表示形参型别// 调用f(expr); // expr表示调用时传入的实参 模板型别推导的结果，不仅依赖于传入实参的型别，还依赖函数形参的型别。 具体可分三种情况： 函数形参ParamType是一个指针或普通引用（非万能引用） ParamType是引用 ParamType是一个普通引用，传入实参的引用性会被忽略，但保留其常量性。 12345678910111213// 模板函数template&lt;typename T&gt;void f(T&amp; param); // param是个普通引用// 型别推导int x = 27; // x的型别是intconst int cx = x; // cx的型别是const intconst int&amp; rx = x; // rx的型别是const int的引用// 推导过程：保留实参的常量性（constness），忽略实参的引用性（reference-ness）f(x); // T的型别是int, param的型别是int&amp;f(cx); // T的型别是const int, param的型别是const int&amp;f(rx); // T的型别是const int, param的型别是const int&amp; ParamType是一个const引用，传入实参的引用和常量性都会被忽略。 123456789101112// 模板函数template&lt;typename T&gt;void f(const T&amp; param); // param是个const引用int x = 27; // x的型别是intconst int cx = x; // cx的型别是const intconst int&amp; rx = x; // rx的型别是const int的&amp;// 推导过程：传入实参的常量性（constness）和引用性（reference-ness）都会被忽略f(x); // T的型别是int, param的型别是const int&amp;f(cx); // T的型别是int, param的型别是const int&amp;f(rx); // T的型别是int, param的型别是const int&amp; 因为ParamType已经是一个const类型，因此T的类型推导没必要再包含const。 传入实参是一个数组或函数，ParamType会被推导成数组引用 123456789101112// 模板函数template&lt;typename T&gt;void f(T&amp; param); // param是个普通引用const char name[] = \"iceberg\"; // name的型别是const char[7]f(name); // T的型别是数组本身，即const char[7]， // param的型别数组引用，是const char(&amp;)[7]void someFunc(int, double); // someFunc是个函数，其型别是void(int, double)f(someFunc); // T的型别是函数本身，即void(int, double)， // param的型别是函数引用，即void(&amp;)(int, double) 扩展：可用于在编译期计算数组大小 12345678// 以编译器常量形式返回数组的大小template&lt;typename T, std::size_t N&gt;constexpr std::size_t array_t arraySize(T (&amp;)[N]) noexcept { return N; // 返回数组大小}const int keys = {1, 3, 7, 9 , 11, 22, 43};std::array&lt;int, arraySize(keys)&gt; mapped; // 编译期就可以确定mapped数组的大小 ParamType是指针 ParamType是一个普通指针，传入实参的常量性会被保留 123456789101112// 模板函数template&lt;typename T&gt;void f(T* param); // param是指针int x = 27; // x的型别是intint* px1 = &amp;x; // px1的型别是int*const int* px2 = &amp;x; // px2的型别是const in*// 推导过程：传入实参的常量性会被保留f(x); // T的型别是int，param的型别是int*f(px1); // T的型别是int，param的型别是int*f(px2); // T的型别是const int，param的型别是const int* ParamType是一直const指针，传入实参的常量性会被忽略 123456789101112// 模板函数template&lt;typename T&gt;void f(const T* param); // param是指针int x = 27; // x的型别是intint* px1 = &amp;x; // px1的型别是int*const int* px2 = &amp;x; // px2的型别是const in*// 推导过程：传入实参的常量性会被忽略f(x); // T的型别是int，param的型别是const int*f(px1); // T的型别是int，param的型别是const int*f(px2); // T的型别是int，param的型别是const int* 函数形参ParamType是万能引用 万能引用既可以绑定左值，也可以绑定右值。因此，当ParamTyep是万能引用时，传入实参即可以是左值，也可以是右值。 传入实参是左值，T和ParamType都会被推导为左值引用 NOTE：这是在所有的模板型别推导中， T被推导为引用型别的唯一情形。 1234567891011// 模板声明template&lt;typename T&gt;void f(T&amp;&amp; param); // param是万能引用int x = 27; // x的型别是intconst int cx = x; // cx的型别是const intconst int&amp; rx = x; // rx的型别是const int&amp;f(x); // x是个左值，T和Param的型别均为int&amp;f(cx); // cx是个左值，T和Param的型别均为const int&amp;f(rx); // rx是个左值，T和Param的型别均为const int&amp; 传入实参是右值，则使用情况1中的规则。 1234567891011121314// 模板声明template&lt;typename T&gt;void f(T&amp;&amp; param); // param是万能引用int x = 27; // x的型别是intconst int cx = x; // cx的型别是const intint&amp; rx = x; // rx的型别是int&amp;const int&amp; crx = x; // crx的型别是const int&amp;f(27); // 27是个右值，T的型别是int，Param的型是int&amp;&amp;f(std::move(x)); // T的型别是int，Param的型是int&amp;&amp;f(std::move(cx)); // 编译错误！右值引用不能绑定到const型别f(std::move(rx)); // T的型别是int，Param的型别int&amp;&amp;f(std::move(crx)); // 编译错误！右值引用不能绑定到const型别 函数形参ParamType是既不是指针，也非引用，即值传递 由于是值传递，因此不管传入实参是左值还是右值，其的引用性和常量性都会被忽略 1234567891011// 模板声明template&lt;typename T&gt;void f(T param); int x = 27; // x的型别是intconst int cx = x; // cx的型别是const intint&amp; rx = x; // rx的型别是const int&amp;f(x); // x是个左值，T和Param的型别均为intf(cx); // cx是个左值，T和Param的型别均为intf(std::move(rx)); // 传入右值，T和Param的型别均为int 当传入实参是一个数组，数组会退化成首元素指针 1234567891011// 模板函数template&lt;typename T&gt;void f(T param); const char name[] = \"iceberg\"; // name的型别是const char[7]f(name); // T和Param的型别均为const char*void someFunc(int, double); // someFunc是个函数，其型别是void(int, double)f(someFunc) // T的型别是函数本身，即void(int, double)， // param的型别是函数指针void(*)(int, double)","link":"/2019/04/10/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE1/"},{"title":"《Effective Modern C++》条款10：优先选用enum class，而非enum","text":"简述众所周知，使用C++98中的枚举型别定义的枚举量，会泄漏到枚举型别所在的作用域中，这也意味着在此作用域内不能再有其他实体取相同的名称。因此，C++98中的枚举型别又称之为：不限作用域的枚举型别。 C++11为了解决这一问题，引入了限定作用域的枚举型别。由于限定作用域的枚举型别是通过”enum class“声明的，所以有时它们也被称为枚举类。 三个优点C++11中限定作用域的枚举型别相较于C++98中不限定作用域的枚举型别，有三个明显的优点，分别是： 解决名称冲突 使用C++11限定作用域的枚举型别定义的枚举量，会被限定在枚举型别内： 1234567// C++98enum Color { red, green, blue }; // red、green、blue的作用域和Color相同auto red = false; // 编译错误！red已在当前作用域内被声明过了// C++11enum class Color { red, green, blue }; // red、green、blue的作用域被限定在Color内auto red = false; // 编译成功，当前作用域内无“red“声明 拒绝隐式转换 使用C++11中限定作用域的枚举型别定义的枚举量，在于其他类型比较时不会被隐式转换，只能是同类型的比较。 123456789101112131415161718// C++98enum Color { red, green, blue };Color c = red;if (c &lt; 2.5) { // 将Color型别与double型别比较时会发生隐式转换，结果为true ....}// C++11enum enum Color { red, green, blue };Color c = Color::red;if (c &lt; 2.5) { // 编译错误！不能将Color型别与double型别比较 ....}// 可通过强制转换进行比较if (static_cast&lt;double&gt;(c) &lt; 2.5) { // 编译成功，结果为true ...} 可进行前置声明 C++11中限定作用域的枚举型别可以进行前置声明，即型别的名字可以比较其中枚举量先声明。 12enum Color; // 编译错误！enum class Color; // 编译成功 一切枚举型别在C++眼里都会由编译器来选择一个整数型别作为其底层型别。 因此，C++11中限定作用域的枚举型别之所以能进行前置声明，本质上是因为其底层型别是已知的，默认为int。 而C++98中不限定作用域的枚举型别处于空间优化的目的，并未为其指定底层型别。换言之，如果想让C++98中不限定作用域的枚举型别支持前置声明，只需要在前置声明时为其指定底层型别即可。 1enum Color: uint8_t; // 指定不限定作用域的枚举型别的底层型别为uint8_t","link":"/2019/04/21/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE10/"},{"title":"《Effective Modern C++》条款15：只要可能使用constexpr，就使用它","text":"constexpr是C++11引入的关键字，主要目的是为了解决const关键字的二义性，constexpr既可用于修饰对象，又可用于修饰函数。 constexpr对象 所谓const二义性是指const既用于表示变量的只读性，又常用于修饰常量。但是const并不能代表“常量”，它只是变量的一个修饰，告诉编译器这个变量只能被初始化但不能被直接修改（实际上可以通过堆栈溢出等方式修改）。因此这个变量的值，可以在运行时也可以在编译期指定。比如： 12345678910// 形参array_size是一个只读变量，其值在运行期指定void func(const int array_size) { std::array&lt;int, array_size&gt; arr; // 编译错误！因为array_size的在编译期未知，即非编译器常量 }void func2() { // 实参array_size是一个只读变量，其值在编译期指定，因此是一个常量 const int array_size = 5; std::array&lt;int, array_size&gt; arr; // 编译通过，因为array_size的值编译期已知，即编译期常量。} 因此，const并不能保证对象是编译期已知，而constexpr可以保证其修饰的对象一定是编译期常量。如下所示： 1234int sz; // 普通变量const auto array_size = sz; // 编译通过，array_size是sz的一个const副本constexpr auto array_size2 = sz; // 编译错误！sz的值在编译期未知 简而言之，所有的constexpr对象都是const对象，而并非所有的const对象都是constexpr对象。 因此，C++11 标准中，建议将 const 和 constexpr 的功能区分开，即凡是表达只读语义的场景都使用 const，凡是要求编译期常量的语境中都使用 constexpr。 constexpr函数 使用constexpr修饰函数的好处在于可以拓展函数的使用语境，即既可在编译期调用，又能在运行时调用。 编译期 如果constexpr函数调用的语境是在编译期，那么必须确保传入的实参都是编译期常量，且内部调用的函数只能是constexpr函数，否则编译失败。 好处是程序运行更快，坏处是编译时间更长。 运行期 如果constexpr函数调用的语境在运行时，那么其运行方式与普通函数无异。 由于constexpr函数必须在传入编译期常量时能返回编译期结果，它们的实现就必须加以限制。且C++11和C++14中的限制还有所差异： C++11的限制条件 保证constexpr函数返回值和参数必须是字面值（即可在编译期决议的值）， 只能有且只有一行return代码，通常使用三目运算符（替代if-else语句）或递归（替代循环语句）来扩展表达力。 C++14的限制条件 只要保证返回值和参数是字面值，函数体中可有多条语句，这样更为方便灵活。 注：在C++11中除void以外的所有内建型别都是字面值，而C++14中所有内建型别都是字面值，包括void。 参考资料： C++11/14 constexpr 用法 C++11 constexpr和const的区别详解","link":"/2019/04/27/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE15/"},{"title":"《Effective Modern C++》条款16：保证const成员函数的线程安全性","text":"简述使用const修饰对象的成员函数的本意在于告诉调用者调用该函数不会修改对象的成员变量，即在其中只能对成员变量进行只读操作。 确保线程安全由于在多线程环境下执行读操作是安全的，因此const成员函数被认为是线程安全的。 换言之，从调用者的角度来说调用一个const成员函数应该是线程安全的，但这只是一种字面上的约定，因为使用const修饰的成员函数并不能保证一定是线程安全。 比如可以在const成员函数中可对使用mutable修饰的成员变量进行写操作。如下： 1234567891011121314151617181920212223class Widget {public: int CachedValue() const { if (cache_valid_) { return counter_; } else { first_cache_ = true; // 编译错误！first_cache_被视为const对象 cache_valid_ = true; // 编译通过，mutable修饰的成员变量可被修改 cache_value_ = DoExpensiveComputaion(); // 同上 } }private: bool first_cache_{false}; mutable bool cache_valid_{false}; mutable int cache_value_{0};};Widget w;/*----线程1-----*/int cached_value = w.CachedValue(); // 可能出现data race，存在未定义行为/*----线程2-----*/int cached_value = w.CachedValue(); // 同上 解决方案有两个，分别是： 使用互斥量mutex 如果需要同时修改多个成员变量，使用mutex更方便。 1234567891011121314151617class Widget {public: int CachedValue() const { std::lock_guard&lt;std::mutex&gt; lock(mutex_); // 加上互斥量 if (cache_valid_) { return counter_; } else { cache_valid_ = true; // 编译通过，mutable修饰的成员变量可被修改 cache_value_ = DoExpensiveComputaion(); // 同上 } } // 解除互斥量private: mutable std::mutex mutex_; mutable bool cache_valid_{false}; mutable int cache_value_{0};}; NOTE：由于std::mutex是个只移型别（move-only type），将mutex加入Widget的副作用就是使Widget失去了可复制性，但仍可移动。 使用原子数据型别std::atomic 如果修改的成员变量只有一个，使用std::atomic的开销更低（是否真的成本更低取决于硬件以及互斥量的实现）。 123456789class Widget {public: int Counter() const { ++counter_; // 带原子性的自增操作 } // 解除互斥量private: mutable std::atomic&lt;int&gt; counter_{0};}; NOTE：与std::mutex一样，std::atomic也是只移型别。因此Widget也变成了只移动型别。","link":"/2019/04/30/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE16/"},{"title":"《Effective Modern C++》条款17：理解特种成员函数的生成机制","text":"简述在C++的官方用语中，所谓特种成员函数是指那些C++编译器会自行生成的成员函数。这些函数仅在需要时才会生成，即某些代码使用了它们，但在类中并未显式声明。 C++11中有以下六种特种函数，其中前四种同属于C++98，后两种则是C++11新加入的成员： 默认构造函数 默认构造函数仅当类中没有声明任何构造函数时才会被生成。 析构函数 除了析构函数其他的特种函数都一定是非虚的。当基类的析构函数是一个虚函数时，编译器为派生类生成的析构函数也是一个虚函数。 C++11中析构函数默认为noexcept。 复制构造函数和复制赋值运算符 两种复制操作是彼此独立的：即只显示地声明其中一个不会阻止编译器生成另外一个。 NOTE：尽管在已存在其中一个复制操作或析构函数的前提下，编译器仍生成另外一个复制操作，但是这成为被废弃行为。因此建议遵守大三律原则。 移动构造函数和移动赋值运算符 两种移动操作并非彼此独立：即显式地声明了其中一种会阻止编译器生成另外一个。理由在于：一旦显示地声明了其中一种移动操作，编译器会理解为你需要的移动操作实现与编译器默认生成的实现会存在差异，因此希望你自己实现另外一个以统一移动逻辑。 NOTE：调用移动构造或移动赋值并不能保证移动操作真的会发生，更像是一种移动请求。对于不可移动的型别，比如C++98中遗留的型别，将通过其复制操作实现”移动“。 大三律指导原则大三律是指：如果声明了复制构造函数、复制赋值运算符或析构函数中的任一个，就得同时声明两位两个。 理由： 如果有改写复制操作的需求或声明了析构函数，往往意味着该类需要执行某种资源管理。即： 如果在一种复制操作中进行了任何资源管理，那么在另外一种复制操作也极有可能需要进行 该类的析构函数也极有可能会参与到资源管理中，比如内存释放操作等。 推论： 如果用户声明了析构函数，那么复制操作就不应该被自动生成，因此他们的行为极可能出错。但可惜地是C++98未支持该推论，即显示声明析构不会阻止编译器生成复制操作。C++11出于兼容C++98的原因也未加以限制，否则会破坏太多的遗留代码。 但是由于移动操作是C++11新引入的函数，因此，基于该推论，C++11规定：只要显示地声明了析构函数，编译器便不再生成移动操作。 总结 复制操作和移动操作相互压抑，即显示地声明了任意一种复制操作都阻止编译器生成移动操作，反之亦然。 复制操作彼此相互独立，即声明其中一个复制操作不会阻止编译器生成另外一个。 移动操作相互抑制，即声明其中一个复制操作会阻止编译器生成另外一个。 编译器生成移动操作需要同时满足三个条件： 该类未显示声明任何复制操作 该类未显示声明任何移动操作 该类未显示声明任何析构函数 C++11中可使用”=default“要求编译器自动生成某个特种函数： 1234567class Widget {public: ~Widget(); // 用户定义的析构函数 Widget(Widget&amp;&amp;) = default; // 使用编译器生成的移动函数 Widget&amp; operator=(Widget&amp;&amp;) = default; // 使用编译器生成的移动赋值运算符} 成员函数模板在任何情况下都不会阻止特种成员函数的生成。","link":"/2019/05/05/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE17/"},{"title":"《Effective Modern C++》条款18：使用std::unique_ptr管理专属的资源","text":"简述std::unique_ptr是C++11用表达专属所有权的方式，一个非空的std::unique_ptr总是拥有其所指的资源。因此，std::unique_ptr不允许复制，即只能通过移动操作将所有权转移。 三个优点使用std::unique_ptr相对于其他智能指针或裸指针而已，具有一下三个优点： 防止内存泄漏 std::unique_ptr内封装了一个原始指针，通过构造函数和析构函数实现对原始指针的内存管理。即在构造函数中通过new申请原始指针的内存，在析构函数中调用delete释放原始指针。 因此，使用std::unique_ptr时不再需要担心内存泄漏。 快速小巧 在默认情况下，即使用默认析构器，std::unique_ptr和裸指针占用的内存空间基本相同。 由于std::unique_ptr重载了“→”和“*”运算符，所以可以像使用裸指针一样使用它。 因此，std::unique_ptr几乎和裸指针一样，足够小且足够快。这就意味着在任何使用裸指针的场合都可以使用裸指针替代，包括内存和时钟周期紧张的场合。 可高效地转成std::shared_ptr std::unique_ptr可以方便且高速地转换成std::shared_ptr。 1234std::unique_ptr&lt;Widget&gt; CreateAWidget();// 转换成std::shared_ptrstd::shared_ptr&lt;Widget&gt; sp = CreateAWidget(); 自定义析构器自定义析构器相较于使用默认析构器的好处在于：可以在原始指针释放之前做一些操作，比如添加日志等。 在使用默认析构器的前提下，std::unique_ptr和裸指针占用的内存大小基本相同。但是，如果std::unique_ptr使用自定义析构器，情况则有所不同。 自定义析构器的实现主要分以下三种类型： 无捕获的lambda 由于lambda在没有捕获变量的情况下可以直接转换成函数指针。因此，可使用无捕获的lambda来实现std::unique_ptr的析构器，其所占用内存大小与使用默认析构器一样，即不会增加内存。 123456auto deletor = [](Widget* pWidget) { // Make some logs. delete pWidget;};std::unique_ptr&lt;Widget, decltype(deletor)&gt; sp(new Widget(), deletor); 函数指针 std::unique_ptr使用函数指针来实现析构器时，其占用内存一般至少增加一个函数指针的大小。 123456void deletor(Widget* pWidget) { // Make some logs. delete pWidget;}std::unique_ptr&lt;Widget, void(*)(Widget*)&gt; sp(new Widget(), deletor); 函数对象 如果一个类或结构体重载了“()”运算符，则称之为函数类。这个类的对象即为函数对象，该对象可以被当做普通函数进行调用。 函数对象的优势： 编译器可以内联执行函数对象的调用。 函数对象可以有自己的状态，在函数对象被多次调用时可共享状态。普通函数则只能使用全局变量来共享状态。 函数对象有自己特有的类型，而普通函数则无清晰的类型界限。因此，在使用模板函数时，可以通过传递类型函数来实例化相应的模板。 使用无状态的函数对象来说实现析构器，与使用无状态的lambda一样不会占用额外内存。因此，如果析构器是函数对象，其带来的内存变化与该函数对象中存储状态的数量成正比。 123456789class Deletor {public: void operator()(Widget* pWidget) { // Make some logs. delete pWidget; }};std::unique_ptr&lt;Widget, Deletor&gt; sp(new Widget());","link":"/2019/05/07/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE18/"},{"title":"《Effective Modern C++》条款24：区分万能引用和右值引用","text":"简述万能引用和右值引用都用”T&amp;&amp;“表示。 万能引用 所谓万能引用，即它既可以绑定左值，又可以绑定右值。一般用于表示型别推导的结果。 右值引用 右值引用，顾名思义就是只能绑定到右值，它的主要作用是作为可移动对象的标识。 详解 万能引用 万能引用有两种最常见的场景，这两种场景都涉及型别推导，它们分别是： 模板函数的形参 12345678template&lt;typename T&gt;void f(T&amp;&amp; param); // param是个万能引用Widget w;f(w); // param的型别是左值引用，即Widget&amp;f(std::move(w)); // param的型别是右值引用，即Widget&amp;&amp; 用于auto声明 12345Widget w;auto&amp;&amp; w1 = w; // w1是个左值引用，即Widget&amp;auto&amp;&amp; w2 = std::move(w); // w2是个右值引用，即Widget&amp;&amp; 万能引用首先是一个引用，所以初始化是必须的，且初始化的对象决定了它代表的是左值还是右值引用。 几个要点： 万能引用的声明形式必须是”T&amp;&amp;“，且型别推导必须是涉及param本身： 模板函数的形参并不一定涉及型别推导 1234567template&lt;typename T&gt;void f(std::vector&lt;T&gt;&amp;&amp; param); // param是个右值引用， // 因为型别已确定是std::vector&lt;T&gt;&amp;&amp;， // 而非T&amp;&amp;std::vector&lt;int&gt; v;f(v); // 编译错误！不能给一个右值引用绑定一个左值f(std::move(v)); // 编译通过 位于模板内并不能保证涉及型别推导 12345678910111213141516// vector的类声明template&lt;class T, class Allocator = allocator&lt;T&gt;&gt;class vector {public: ... void push_back(T&amp;&amp; param); // param是个右值引用，虽然形参的声明形式为”T&amp;&amp;“， // 但是调用该函数并不涉及型别推导， // 因为T的类型在创建vector时已确定。 template&lt;class... Args&gt; void emplace_back(Args... args); // args是个万能引用 ...};std::vector&lt;Widget&gt; v; // 此时push_back的形参型别已确定为Widget, // 但是emplace_back的形参需要推导。 使用const修饰的”T&amp;&amp;”一定是右值引用 12template&lt;typename T&gt;void f(const T&amp;&amp; param); // param是个右值引用","link":"/2019/05/18/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE24/"},{"title":"《Effective Modern C++》条款23：理解std::move和std::forward","text":"简述 std::move std::move，即移动语义。它的设计初衷在于让编译器用一种低成本的移动操作替换昂贵的复制操作。与之相关的两个函数分别是移动构造函数和移动赋值运算符。 此外，std::move使得创建一个只可移动不可复制的对象成为可能，比如std::unique_ptr、std::future和std::thread等。 std::forward std::forward，即完美转发。它的设计初衷是使对任何一个函数模板，都可以将当前函数所接受的实参原封不动地转发给其它函数，且目标函数接受到的实参与传入当前函数的实参完全相同，包括实参的左右值属性。 形参总是左值 所谓左值，简单地说就是可寻址变量，而右值则是不可寻址的临时变量。 123int a = 3; // a是左值，3是右值a = a + 1; // 等号左边的a是右值，等号右边的a是右值 // CPU取a的值存入临时变量，即寄存器，然后+1，再将寄存器的值赋值给a 实参既可以是左值，也可以是右值。而形参总是左值，原因在于形参是为了传递实参的值或指针或引用而出现的，因此必须是可被赋值的左值。即便形参的类别是右值引用，如下： 1void fun(Widget&amp;&amp; w); // 形参w是一个左值 详解 std::move std::move本质上就是使用std::remove_reference_t将传入实参的引用属性移除（但不包括const属性，移除const属性需要使用std::remove_const_t），再将其强制转换成右值引用。以下是C++14中std::move的实现： 12345template&lt;typename T&gt;decltype(auto) move(T&amp;&amp; param) { using ReturnType = std::remove_reference_t&lt;T&gt;&amp;&amp;; // 即便param是一个左值引用，移除引用后变成左值类型 return static_cast&lt;ReturnType&gt;(param); // 强制转换成右值引用} 鉴于std::move不会移除实参中的const属性，因此只能保证其返回值是一个右值，但是不能保证返回值的可移动能力。比如： 12345678910class A {public: A(const std::string&amp; s); // 复制构造函数 A(std::string&amp;&amp; s); // 移动构造函数};const std::string a = \"hello\"; // a是一个常量左值std::string b = \"hello\"; // a是一个非常量左值A(std::move(a)); // 调用复制构造函数A(std::move(b)); // 调用移动构造函数 std::forward std::forward是一种有条件的强制型别转换：仅当传入的实参是一个右值时，才会执行右值型别的强制转换。 std::forward本质上就是转发实参的左右值属性。如果传入的实参是左值，那么转发之后仍是左值。如果传入的实参是右值，那么转发之后仍是右值。比如： 123456789101112131415void process(const Widget&amp; lval); // 函数1，处理左值void process(Widget&amp;&amp; rval); // 函数2，处理右值template&lt;typename T&gt;void logAndProcess(T&amp;&amp; param) { ..... // add a log process(std::forward&lt;T&gt;(param)); // param是一个形参，由于所有形参都是左值，理论上只会调用函数1。 // 解决机制：param所接收的实参的左右属性被编码进目标参数T中， // 当param传递给std::forward后，std::forward再将编码的信息 // 解码，获取传入实参的左右属性。}Widget w;logAndProcess(w); // 传入左值，调用函数1logAndProcess(std::move(w)); // 传入右值，调用函数2 总结std::move实际上不会进行任何移，而std::forward实际上也不会进行任何转发。二者都是编译期的行为，在运行期不会有任何行为，即不会生成任何可执行代码。 相同点 二者本质上都仅是执行强制类别转换的函数模板。 不同点 std::move是无条件地将实参强制转换成右值，而std::forward则是在满足特定条件下才执行同类别强制转换（即转发）。","link":"/2019/05/13/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE23/"},{"title":"《Effective Modern C++》条款7：在创建对象时注意区分()和 {}","text":"在C++11中有三种指定初始化值得方式，分别是使用小括号()、等号=和大括号{}。其中，前两种在C++98中就已经存在，而使用大括号的初始化语法则是C++11引入的。 这三种初始化语法只有大括号适用于所有初始化场景，比如： 初始化非静态成员变量 可使用等号=或大括号{}，不能使用小括号() 1234567class Widget { ...private: int x{ 0 }; // 可行 int y = 0; // 可行 int z(0); // 不可行！}; 初始化不可复制对象 可使用小括号()或大括号{}，不能使用等号= 123std::atomic&lt;int&gt; a_1{0}; // 可行std::atomic&lt;int&gt; a_2(0); // 可行std::atomic&lt;int&gt; a_1 = 0; // 不可行，无赋值函数 大括号初始化语法的三个独有的特性： 禁止隐式窄化类别转换（narrowing conversion） 1234double x, y ,z;int sum1{x + y + z}; // 报错！double之和可能无法用int表达，存在窄化转换int sum2(x + y + z); // 可行，double之和被截断（窄化）为intint sum3 = x + y + z; // 可行，同上 对C++解析语法免疫 C++规定：任何能够解析为声明的语句都要解析为声明。 因此，当使用默认构造方式来创建对象时会被解析为一个函数声明，如下： 12345Widget w1(10); // 正确，调用Widget的带形参的构造函数，w1被解析为对象Widget w2(); // 错误！本意是想调用Widget的默认构造函数创建w2对象， // 结果w2被解析为函数声明，且返回一个Widget对象Widget w3{} // 正确，由于函数声明不能使用大括号来指定形参列表， // 所以w3不会被解析为函数声明，而是调用默认构造函数创建w3对象 优先选择使用std::initializer_list模板为形参的构造函数，甚至劫持复制或移动构造函数 根据std::initializer_list模板中的型别，具体可分四种情况： 构造函数的参数可被隐式强制转换成std::initializer_list模板中的型别，如下int和bool都可以强制转换成long double。 1234567891011121314151617181920212223class Widget {public: Widget(); // 默认构造函数 Widget(int i, bool b); // 第一个构造函数 Widget(int i, double d); // 第二个构造函数 Widget(std::initializer_list&lt;long double&gt; i); // 第三个构造函数 operator float() const; // 强制转换成float ...};Widget w1(10, true); // 调用第一个构造函数Widget w2{10, true}; // 调用第三个构造函数，10和true均被强制转换成long doubleWidget w3(10, 5.0); // 调用第二个构造函数Widget w4{10, 5.0}; // 调用第三个构造函数，10和5.0均被强制转换成long doubleWidget w5(w4); // 调用复制构造函数Widget w6{w4}; // 调用第三个构造函数，w4的返回值被强制转换成float， // 随后又被强制转换成long doubleWidget w7(std::move(w4)); // 调用移动构造函数Widget w8{std::move(w4)}; // 调用第三个构造函数，同w6 构造函数的参数可被隐式窄化转换成std::initializer_list模板中的型别 比如上列中的std::initializer_list模板中的型别是bool，即std::initializer_list。由于int或double转换成bool属于窄化转换，而窄化转换在大括号初始化中是被禁止的，因此会编译报错。 构造函数的参数无法隐式强制转换成std::initializer_list模板中的型别 比如上列中的std::initializer_list模板中的型别是std::string，即std::initializer_liststd::string。由于int或double无法被隐式转换成std::string，因此编译器会退而求其次去找其他的构造函数。 空大括号 空大括号{}表示的语义是”没有实参“，而非”空的std::initializer_list“，因此使用空大括号调用的是默认构造函数。 1234567Widget w1; // 调用默认构造函数Widget w2{}; // 同上，调用默认构造函数Widget w2(); // 被解析为函数声明Widget w4({}) // {}作为实参表示一个空的std::initializer_list， // 因此调用std::initializer_list为形参的构造函数Widget w5{{}} // 同上","link":"/2019/04/18/%E3%80%8AEffective%20Modern%20C++%E3%80%8B%E6%9D%A1%E6%AC%BE7/"},{"title":"《三体1》读后感之死亡还是生存","text":"《三体》是我看的第一本科幻小说，与很多在学生时期就接触了这本书的朋友比起来，即将三十而立的我觉得有点相见恨晚。书中涉及了天文学、物理学、计算机学等众多专业知识。在阅读这本书的过程中，总会时不时地感叹作者想象力之丰富，知识之渊博。与作者刘欣慈一样同为程序员的我读起来多了一丝亲切感。过去的自己对科幻小说存在一些误解，认为科幻小说无非只是天马行空的想象罢了，这类超现实的小说只适合用来消遣，并没有太多实用性。现在我为自己愚蠢的想法道歉：一本好的小说一定都蕴含着一个深刻的内核，或是对生命的思考，或是对人性的剖析等等。而小说的功能则是通过虚构一个故事或世界让读者更好的理解作者要表达的想法，并引导读者产生共鸣。《三体》这本书在我看来，它提出的是对人类的究极拷问：生存还是死亡？ 这本书采用的是倒叙和插叙的叙述方式，让读者在阅读的过程中不断地处于产生疑惑和解答悬念的循环中，也使整个阅读过程都充满紧张和刺激的感觉，直到最后一刻谜底揭开之时不自觉地陷入深思并自我审视：当自己面临同样的困境会如何抉择？是选择生存还是死亡？ 在给出自己的答案之前，我觉得很有必要按照时间顺序将整个故事的来龙去脉理一遍，这样可以更好地理解作者想要表达的想法。 起源：文化大革命这本书的主角无疑是叶文洁，整本书都是围绕着叶文洁坎坷悲催的成长历程展开，她的遭遇让她看清了人性的丑恶，对人类文明也逐渐失去了信心，而这一切的源头毫无疑问是文化大革命。文革大致可以分为三个阵营：坚守真理的知识分子，疯狂无知的红卫兵以及为求自保的利己主义者。而叶文洁的一家四口恰巧分属这三个阵营，也为这个不幸的家庭埋下了悲惨结局的注脚。 叶文洁的父亲叶文泰，属于坚守真理的知识分子代表。在文革时期，作为物理学界的泰斗的他成为了众矢之的。但是，面对持续的残酷打击，他自始至终地捍卫着自己内心由知识和理性构筑的思想大厦，直到生命的最后一刻也不曾有一丝妥协。他内心其实早已看透：“在中国，任何超脱飞扬的思想都会怦然坠地，因为现实的引力太沉重了”，更何况是在这个疯狂的年代，坚守真理需要付出的是生命的代价。而作为红卫兵的叶文洁，站在台下红卫兵的队伍中目睹了父亲整个的批斗过程，除了强忍悲痛与泪水之外显得无能为力。那时候的她还是学生，同其他的红卫兵一样没有科学信仰，缺乏分辨是非的能力，并且对至高无上的权利都有着天生的崇拜。但她又不同于妹妹那样完全失去理智，六亲不认。这是因为她内心真正崇拜的人是自己的父亲，也意味着她和父亲有着同样的科学信仰。只是她那时候太年轻，很轻易地就被文革浪潮吞没，同时被吞没的还有个人的信仰。那时候的她本能地选择活下去，而加入红卫兵就是最好的选择。和叶文洁做出同样选择的还有父亲的两个研究生，我相信他们内心是崇尚科学的，这也让他们在批斗自己老师的时候尚且表露出一丝人性。但是他们内心又惧怕成为革命对象，为了生存只能将自己隐藏在红卫兵的外衣之下。但是当她在大兴安岭接受劳动改造时，面对他人的栽赃陷害以及上层对父亲的二次批斗，她选择了和父亲一样的斗争方式：以死捍卫自己的尊严和信仰。而与叶文洁及其父亲形成鲜明对比的是同为物理学教授的母亲，她则是一位精致的利己主义者，她既不像叶文泰那样甘愿为科学献身，也不像红卫兵那样愚昧无知，她所做的一切都是为了让自己活着，并且活得更好。早在文革初期她就嗅出了知识界的政治风向，做出很多超前的举动，试图告诉学生：所有的科学成果都是广大劳动人民的智慧结晶，而那些资本阶级的学术权威不过是窃取了这些智慧，试图得了文革主流的认可，从而使自己能在这场自己为革命对象的斗争中生存下来。为了达到这个目的，她不惜一切代价：在文革时期上台协助红卫兵批斗自己的丈夫；在文革后期眼光独到地嫁给了一位尚未平反的教育部高干，在文革结束后不久便再次回到上层阶层；为了与过去的历史旧账撇清关系而不惜与女儿决裂。为自己活着无可厚非，但是将自己的幸福建立在他人的痛苦之上就是可耻的。 文革结束后，叶文洁找到了当年将自己父亲批斗致死的三个红卫兵，试图让她们为当年的罪行忏悔，哪怕是人性的一点点复归。然而得到的答复是：“她们也是受害者，文革剥夺了她们的青春和未来，历史已经将她们遗忘，她们内心只有怨狠没有忏悔”。那一刻起，叶文洁对于人类文明彻底失去了信心，期待宇宙间更高的文明来引导人类文明已然成为了她坚定不移的信念。 经过：寻找更高级的文明叶文洁因为自己大一的一篇名为《太阳辐射层内可能存在能量界面和其反射特性》的论文将她从文革二次迫害中拯救出来，进入了神秘的红岸基地。毫无疑问，红岸基地的出现不仅拯救了叶文洁的性命，也让早已心如死灰的叶文洁重新燃起了对生的欲望，因为在这里有了探索外星文明的可能性。 在红岸基地，因为特殊身份和遭遇叶文洁被隐形地的隔离与疏远，而工作成为了她生活的全部。只有全身心地投入工作才能暂时忘记过去的痛苦，加上叶文洁夯实的学术研究功底，为后续叶文洁成为第一个发现“太阳是一个电波放大器”这一理论的人增加了可能性。苏联天体物理学家卡达谢夫曾建议，可以根据宇宙中不同文明用于通讯的能量，来对它们分级。他将想象中的文明分为Ⅰ、Ⅱ、Ⅲ三种类型；Ⅰ型文明能够调集与地球整个输出功率相当的能量用于通讯。当时他的估计，地球的功率输出约为1015～16瓦。Ⅱ型文明能够把相当于一颗典型恒星的输出功率，1026瓦用于通讯。Ⅲ型文明用于通讯的功率达1036瓦，约等于整个星系的功率输出。红岸基地所能发射的最大功率虽然连Ⅰ文明都达不到，但是它可以满足穿越太阳对流层到达反射层的阈值，经过太阳放大后的功率可达到Ⅱ型文明能量级，意味着地球文明找到了探索更高文明的钥匙。在接触《三体》这本书之前，我就一直存在一个疑问：长期以来人类以自己的认知方式去探索其他文明真的可以建立联系吗？这就好比有一条寄生虫无法感知人类存在一样。因此，如果有一个文明以人类无法感知的方式进行交流，即便真的存在我们周围我们也是无从得知的。在与三体文明取得联系之后，叶文洁向三体星球发出了“求救”信，期望着更高的文明降临拯救人类。这几乎成为了她那时唯一的信仰，为了捍卫这一信仰不惜以雷志成和丈夫杨卫宁的性命为代价。 随着文革风波的平息，与文革同样疯狂的“红岸计划”也逐步停滞瓦解。因为与失去了与宇宙文明通讯的平台，重新回归正常生活的叶文洁本以将人类的命运寄托于自己的美好期望中，直到遇到了同样对人类文明失去信心的还有伊文斯。伊文斯是一位物种共产主义者，他的信仰是：地球上的所有物种生来平等。然而人类文明的首要规则是：“保证人类的生存和舒适的生活，其他都是第二位的”。与叶文洁不同的是伊文斯有更多的选择，以及继承了父亲巨额遗产，这让他可以根据自己的意愿去探索人性，证明自己的理论是否可行。可惜他的信仰与人类文明是背道而驰的，这注定了他在人类社会是一个失意者。叶文洁的出现为伊文斯指明了新的探索之路：借助更高的文明来引领地球文明。因此也有了第二红岸基地的诞生。 如果说叶文洁是搭建与三体文明交流桥梁的先驱者，那么伊文斯则是在地球传播三体文明的领军人。尽管在他们的共同的努力下，三体文明的已经将地球锁定为他们希望的生存之地并开始向地球文明靠近，但是他们对于三体文明的降临地球后的期许却截然不同，因而三体叛军中产生了不同的派别，主要分为三派： 降临派：这是三体叛军最本原最纯粹的一脉，主要由伊文斯物种共产主义的信奉者组成。他们对人类本性都已彻底绝望，这种绝望最初来源于现代文明导致的地球物种大灭绝。伊文斯的一句话已成为降临派的座右铭：我们不知道外星文明是什么样子，但知道人类。他们期望三体文明的彻底摧毁人类文明。 拯救派：拯救派的成员大多都是通过《三体》游戏认识三体文明，以高级知识分子居多，并对于三体文明有着宗教般的崇拜。但是对于人类文明的态度远没有降临派那样极端。他们的终极理想是拯救主，也就是三体文明。为了达到这一目的可以一定程度上牺牲人类世界。 幸存派：幸存派的成员都来自较低的社会阶层，他们期望自己和子孙成为三体文明和地球文明那场终极战争中的幸存者，他们认为现在就为三体服务更有利于实现这一目的。这一派的主张很符合中庸思想，因此也以中国人居多。 这三个派别相互制约和对立，在三体文明降临之前他们有着共同的大目标，共同为三体服务。但是一旦三体文明降临，他们便会了各自的利益各自为战。就像当年文革时期，在“革命军”这一大群体中也有着很多的派系，他们借以文革的名义谋求着各自的利益，而最后沦为牺牲品的只有年幼无知的红卫兵和坚守真理的人。历史总是惊人的相似，因为人性如此，人类文明如此。 结果：三体文明降临不同于地球得天独厚的的自然环境，可以让人类在登上食物链顶端之后不必再考虑如何生存下去，而是考虑如何生活地更好。人类的文明发展史从另一个角度来讲就是一部环境和资源的破坏史，为了短期的利益而忽视地球环境和人类未来至始至终贯穿人类史。每当出现能源危机时都有新的技术突破带领人类走出困境，这也让大部分人类可以更加肆意地追求物质上的享受，因为他们相信当人类出现危机时总会有新的技术出现将危机化解。曾几何时，三体世界也像地球一样，有民主自由的社会，有着丰富的文化遗产。然而在生存危机面前，文明则变成了最脆弱的环节，如同温室的花朵一般。如今三体人挣扎于自己的星球的三体困境中，为了生存而不断地寻求技术突破，包括寻找或者践踏其他星球的文明，甚至抹灭了三体人生而为人的尊严与自由，剥夺作为人的基本情感需求，没有财富没有地位没有爱情，也没有希望。三体世界里的人类大多数都像1379号监听员那样孤独的过完一生，要么工作至死，要么脱水封存。当他接受到来自地球的信息，得知宇宙的另一个角落存在一个星球，那里有着自己向往的生活。这对他而言这是人生中最有价值的时刻，然而第一时间想到的是对上级隐瞒消息，内心不忍地球文明被三体占有和摧毁。我想这不仅是因为对地球这颗美丽的星球心生怜悯，更多的是因为对三体世界的绝望。然而他却不知道此时地球上也有一群人像他一样对自己身处的世界和文明感到绝望，正期待着三体文明的降临。 为了阻止人类文明与科技的发展，三体高层研发出了智子，试图对人类进行降维攻击。说起智子工程不得不再次感叹作者天马行空的想象，将整个人类世界想象成一个CPU，智子以接近光速的速度在地球穿梭，这让处于低速层面的地球人类感觉到智子无处不在。 抉择：生存还是死亡面对更为高级文明的降临，地球人面临着前所未有的抉择：生存还是死亡？ 相较于普通百姓，高级知识分子显得更为悲观，而这些高级知识分子中又以科学家最为悲观。因为他们更接近真相，更清楚事情的严重性。与此同时，他们作为三体文明首要的攻击对象，当理性和科学的大厦被击溃时，活着似乎显得毫无意义，这也是杨冬自杀的原因所在。 作为大多数存在的普通人，对于科学没有那么虔诚的信仰，出于生存的本能而选择自救。尽管在三体人看来地球人就像虫子一样卑贱。但是就像人类和蝗虫之间的战争一样，人类用尽各种方法试图消灭蝗虫，最终却不得不承认一个事实：虫子从未被真正意义上战胜过，","link":"/2018/12/01/%E3%80%8A%E4%B8%89%E4%BD%931%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F%E4%B9%8B%E7%94%9F%E5%AD%98%E8%BF%98%E6%98%AF%E6%AD%BB%E4%BA%A1/"},{"title":"《入殓师》观后感-职业有贵贱之分吗？","text":"职业有贵贱之分吗？这个问题我一直没有去思考过，因为在主流教育中这不应该是一个问句而是肯定句，恰巧我就是从小接受主流教育长大的。 从小到大身边的人都在给我灌输一种价值观：努力读书，以后找一个体面的好工作。而他们口中体面的好工作不外乎都市白领、医生、公务员等看起来光鲜亮丽的职业，而像清洁工、销售、快递员等门槛低的职业似乎有着与生俱来的卑微与低下。曾几何时，我并不觉得这种价值观有什么不妥之处，直到我最近看了一部日本的电影《入殓师》让我觉得应该重新审视自己的价值观。这部电影我先后一共看了三遍，里面有很多打动我的元素，而关于职业是否有贵贱之分就是其中一个。 电影的男主人公原本是一位大提琴手，拥有一份体面的工作。但是随着乐团的解散而失业在家。在一个机缘巧合的机会他应聘了入殓师这份职业，但是由于这并不是一份光彩的工作他选择对身边的人隐瞒真相。在最开始阶段男主人公很排斥这份工作，并且身心都备受折磨，但是高额的报酬让他选择继续坚持下去。直到有一次，他随社长一同为一位平凡的家庭主妇入殓，静静地做在旁边的他看着社长有条不紊又带着敬意地为死者进行入殓仪式时，明白了入殓师这份职业的意义所在：让死者以最美的姿态离开这个世界，这也是对死者最后的尊敬。电影中这一幕的背景音乐是久石让先生的《memory》，这首曲子也是贯穿整部电影的主旋律。当时我的内心也受到了很大的触动，同时脑海里浮现的是我今天要思考的问题：职业有贵贱之分吗？除了电影的主人公之外，里面还有两个卑微工作的从业者，一个是经营澡堂的阿婆，一个是殡仪馆的老头，显然他们的职业在主流价值观中是不被尊重的，但是他们都坚守了一辈子。 在主流的价值观中，财富和地位几乎是衡量成功的唯一标准，因此职业是否能带来财富和地位决定了职业的贵贱。这是外界给予一个职业的评判标准，也是大多数人的标准，也是我的标准。这种普世的价值观让我们忽视了职业背后的意义和对社会的贡献，忽视了工作的主体是通过自己劳动获取报酬的人，习惯性地将职业的“卑贱”映射到职业从事者的身上以获得优越感。更让人觉得惶恐的是这种价值观似乎已经根深蒂固，以致于在很多人看来是理所当然的事情，就像太阳从东边升起那样的习以为常。 不过这终究是道德层面的话题，而道德只能律己不能律人。作为一个农村出来的孩子，我从心底里面是同情和尊重底层劳动者的，会用微笑对他们报以最大的善意。即便如此，我还是有时会不经意间在内心通过“贬低”他们来获得优越感，这就是我需要自我反省的地方。","link":"/2018/11/25/%E3%80%8A%E5%85%A5%E6%AE%93%E5%B8%88%E3%80%8B%E8%A7%82%E5%90%8E%E6%84%9F/"},{"title":"《刻意练习》读书笔记","text":"这是一本严谨的好书，书中围绕“刻意练习”这一主题，给出了明确的定义和方法论，并从多个角度分析其可行性。以下是我的学习心得： 一、大脑是终生学习者未成年人在学习新事物时大脑的前额灰质也会随之增加，以创建心理表征，而成年人则是通过修剪已有的大脑突触连接来重塑心理表征。虽然二者重塑大脑的方式存在差异，但是最终都可获得对应的心理表征。 二、什么是心理表征简而言之，心理表征是大脑对某一事物形成的心理结构，或具体或抽象。大脑存在多种心理表征，彼此之间存在关联，可以帮助我们快速思考和学习。 心理表征有好坏之分，好的心理表征包含对事物本质更深刻的理解。刻意练习可以帮助我们获得更为有效的心理表征。 三、什么是刻意练习刻意练习不是盲目地重复，而是属于一种有目的的练习。但刻意练习又不同于其他类型的有目的联系，差别主要存在于两方面：一是刻意练习只针对成熟的行业或领域，该行业或领域存在直接竞争，且有客观的评价标准；二是刻意练习需要有效的引导。 简而言之，刻意练习具有以下特点： 需要高水平的引导和行之有效的训练方法； 需要突破个体的舒适区； 包含定义明确的目标和清晰的计划； 基于个体的主观能动性； 包含良好的正向反馈机制； 既能产生有效的心理表征，又能优化改进已有心理表征； 包含对已有技能的针对性强化和改善。 四、是否存在真正的天才所谓天才是那些天生就具备某个领域顶尖能力的人。但可惜的是这只是世俗的一厢情愿。每个“天才”背后都经历了有意或无意的刻意练习，其中很多“天才”在孩童时期便获得了有效的引导和训练。由于过去信息闭塞，“天才”背后的艰辛往往不被外界所知，取而代之的是横空出世的震撼感，而这也是大众喜闻乐见的。久而久之便衍生出各种天才神话。 五、自我实现预言之天才效应自我实现预言是指我们对待他人的方式会影响到他们的行为，并最终影响他们对自己的评价。 我们都会不自觉地认为处于某个领域顶尖水平的那群人一定是有天分的，要么拥有高智商，要么对某个领域有着天生的兴趣。之所以造成这种局面的原因主要是先天的优势确实可以让某个领域的初学者获得比其他人更快的进步，这会使得智商较高的人获得更多的鼓励和引导，从而更容易成为领域的佼佼者。反之，智商较低的人则会容易受到冷落。 但研究表明，这种先天优势会随着练习的积累而逐渐消失。换言之，同处于某个领域顶尖水平的两个人，智商高的人并一定比较低智商的人厉害。事实往往是智商较低的人水平更高一些，这是因为他们练习的时间更长，获得的心理表征的质量更高。 看完这本书更加坚定了我想做一位练习人的决心。所谓“练习人”，是反映人在一生之中能够通过练习来掌握自己的命运，使得人生充满各种可能。","link":"/2020/11/27/%E3%80%8A%E5%88%BB%E6%84%8F%E7%BB%83%E4%B9%A0%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"《如何阅读一本书》读书笔记","text":"种一棵树最好的时候的是十年前，其次就是现在 如何阅读一本书？这是一个一直困扰我的难题。几年前有幸拜读了莫提莫·J·艾德勒和查尔斯·范多伦写的《如何阅读一本书》。但是这本书本身的阅读难度不小，所以阅读过程感觉如鲠在喉一般的难受，看完之后仍然对书中提及的阅读方法论一知半解。今天在网路上看到了一份关于阅读方法的PPT文案，里面提及的方法恰好是对这本书的概括与总结。下面内容是我对这篇文稿的摘要与理解。 阅读是分类型的 阅读类型 典型案例 对作者要求 阅读目的 娱乐消遣 网路小说、小报 可比读者低 消遣、轻松、愉快 获取资讯 杂志、畅销书 略高于读者 增长知识 增进理解 《物种起源》 远高于读者 依据一定方法、促进理解力 阅读是分层次的阅读的四个层次是分别是： 基础阅读：摆脱文盲状态基础阅读能力，能理解字句的表面含义 检视阅读：有限时间最好的完整阅读法，能理解这本书的主题思想 分析阅读：无限时间最好的完整阅读法，能输出自己对这本书的理解 主题阅读：最主动最花费力气的阅读法，能指出同一主题下这本书观点的异同 以上四个阅读层次由上至下是渐进掌握的，上一层次的阅读方法包括在下一层次中。 阅读者必须主动了解的四个问题 整体来说，这本书在谈论什么？ 作者具体说了什么？表达方式是怎样的？ 你是否认同书中的观点？是全部认同还是部分认同？ 这本书带给你什么？与你有什么关系？ 主动阅读与被动阅读的效果有着天壤之别。被动阅读者仅仅满足于被作者引导，而主动阅读带着问题阅读，能引发更多的思考和感悟。 基础阅读：学阅读的四个阶段基础阅读是其它阅读层次的基础，即便到更高层次也会遇到基础问题。 阶段 参考时间 关键能力 阅读准备 三岁前 保持注意力 看图识字 六岁前 认识500字 扩大视野 九岁前 可跳过生字 阅读理解 十二岁后 能阅读课本 检视阅读：粗略或略读的技巧检视阅读是一种几分钟到一个小时了解书的方法，掌握检视阅读才算开始真正阅读。检视阅读包括系统略读或粗读。 系统略读6个步骤 步骤 具体说明 了解书籍主题 先看书名页，特别注意副标题。如果有序就先看序，或其他相关的宗旨说明 了解整体架构 研究目录页，对本书基本架构做概括性了解 了解关键词目 如书中有索引，翻阅索引，发现重要词目。快速翻阅和词目相关的几页 了解作者介绍 查看作者介绍，要么有助于你了解这本书，要么让你看穿作者的宣传伎俩 了解重点章节 开始挑几个跟主题紧密相关的章节快速翻阅 了解逻辑线索 把书打开随意翻阅，阅读其中部分内容，几段或几页即可，留意后记 粗读的妙处假如读一本有难度的书，一开始就选择精度很可能是个错误。检视阅读的规则是：先粗读，头一次面对一本难懂的书，从头到尾先读一遍，碰到不懂得地方不要停下来检索或思考。这与我们应试教育阶段接触的阅读习惯恰好相反。 粗读的目的粗读的目的，在于通过短时间内快速地浏览全书，从而确定这本书是否值得继续深入。并不是每一本书都值得精读，但是一定有值得你认真阅读的书。假如确定是一本值得你精读的书，那么你就得掌握分析阅读的方法，这才是真正会读书的人。 分析阅读：三阶段+十一规则第一阶段：了解范围，这本书是谈论什么？规则一-学会给书做分类知道自己读的是哪一类书，而且越早越好，最好在你阅读前就知道书的类型，不同的书有不同的读法。 类型 举例 虚构类 小说、戏剧、诗歌 论说类 实用性、理论性 理论性作品是告诉读者这是什么，它会经常出现“什么是什么”这样的句子结构，比如康德的《纯粹理性批判》 实用性作品是告诉读者如何去做，它会经常出现“应该”和“应当”，“好”和“坏”，“结果”和“意义”这样的字眼。 很多作者自己都搞不清楚理论和实用的区别，去经常要教你“如何思想”… 规则二-找到一本书的骨架使用一个句子，或一小段文字来叙述整本书的内容，如下列《国富论》： 本书在探讨国家财富的资源。任何一个以劳力分工为主的经济体制，都要考虑到薪资的给付，资本利润的回收，积欠地主的租金等关系。这些就是物品价格的基本因素。本书讨论到如何更多元化地有效利用资本，并从金钱的起源与使用，谈到积累资本及使用资本。本书借着检验不同国家在不同状态下的富裕发展，比较了不同的政经系统，讨论了自由贸易的好处。 为什么大多数读者在被要求说出一本的重点时会一脸茫然？原因有二： 今天的读书普遍不会用简明语言表达自己 大多数读者忽视了这条主动阅读的规则 规则三-为一本书拟大纲将书中的重要章节列举出来，说明它们如何按照顺序组成一个整体的架构。 作者制造骨架，却要想办法用血肉隐藏骨架，让读者去发现它。大多数书读不出头绪，恰恰是因为作者没有制作好骨架。 读者做的大纲完全有可能比书原来的大纲好。 规则四-发现作者的意图找出作者要问的问题。如果问题复杂你应该能够分成或是很多部分，或是不同主次，或是不同先后的问题。 总结第一个阶段的四个规则分析阅读第一阶段运用四规则解答：整本书谈的是什么的问题？ 规则 解答的问题 1-分类 这本书的种类或主题是什么？ 2-概括 这本书主要内容是什么？ 3-梳理 这本书用怎样的结构写的？ 4-总结 作者关注或想解决的问题是什么？ 第二阶段： 判断作者的主旨规则五-找出重要单字透过关键字与作者达成共识。第一要找出重要单字，第二要确认单字最精确的意义。 规则六-找出最重要的句子将一本书中最重要的句子圈出来，找出其中的主职。 一本书最重要的句子在哪里？ 越重要的地方理解越相对吃力 阅读的一部分本质是被困惑 在困惑处慢读，而不是感兴趣的地方 测验是否理解一句话主旨的最佳方法就是：用自己的话表达出来 规则七-从最重要句子之间的关联中，设法架构出一本书的基本逻辑 首先，记住所有论述都包含了一些声明，其中有些是你为什么该接受作者这个论述的理由。如果你先找到结论，就去看看理由是什么。如果你先看到理由，那就看看这些理由引导到哪些结论上。 其次，要区别两种论述，一种是以一个或多个特殊的事实用归纳法证明某种共通的概念，另外一种是以连串的通则用演绎法来证明更进一步的共通概念。 每个论述都要有开端，一种是作者和读者都认可的假设，一种是无法否认的道理。找出作者认为哪些事情是假设，哪些是能证实的或有根据的，以及哪些是不需要证实的自明之理。 注：有些书的架构比较松散，段落也比较零乱。你经常要读完整章的段落，才能找出几个可供组合一个论述的句子。有些书会让你白费力气，有些书甚至不值得这么做。 规则八-找出作者的解答你跟作者有共识，并抓住作者的主旨和论述： 作者想要解决的问题哪些解决了？ 为了解决问题是否提出了新问题？ 无论新旧问题作者是否知道自己哪些没解决？ 总结第二阶段的四个规则 规则 解决的问题 五-定义 本书各种名词术语的含义？ 六-理解 本书作者想让你关注的话？ 七-逻辑 本书是怎样推导出结论的？ 八-答案 作者自己的观点是什么？ 第三阶段：公正地评价一本书 必须能评论，提出批评，才算真正完成阅读。最能学习的读者，也就是最能批评的读者。 公平评价书的技巧： 不要带入主观情绪去讨论 好的辩论不会为假设争吵 要能站在对方立场想一想 规则九-了解全书再做评价 在你说出“我同意”，“我反对”或“我暂缓评论之前”，你一定要能肯定地说：“我了解这本书的内容了”。 规则十-理性表达个人意见 当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。 规则十一-评价需有理有据 尊重知识和个人观点的不同，在做任何评断之前都要找出理论依据。 主题阅读主题阅读是最高层次的阅读，建立在前面三个层次之上。因此，必须完成前面三个层次才能进行主题阅读。 五个步骤 步骤 描述 找到内容 在主题阅读中，主题才是重点，而不是阅读的书。最主要的工作不是理解整本书的内容，而是找出这本书对你研究的主题有什么参考价值。 引导作者 由阅读者建立共识，带引你的作者们与你达成共识，而不是你跟他们走。用自己的语言消化不同作者的词汇，消除歧义，融会贯通 厘清问题 最好的方法是先列出一些可以把我们的主旨说得比较明白的问题，然后让那些作者来回答这些问题，不过我们不能把思想强加给作者。 界定议题 如果一个问题很清楚，如果我们也确定各个作者会用不同的方式来回答，不论赞同还是反对，那么这个议题就被定义出来了，有矛盾回答的议题才是真议题。 分析讨论 身为主题阅读的读者，我们的责任不只是要子回答这些问题。我们可以找到的问题答案，与其说是立足任何一组答案不如说是立足顺序清楚的讨论本身。 总结我个人觉得，对绝大多数人来说，能到达掌握分析阅读的方法去阅读一本书，基本就够了。但是我觉得只是用这个方法读完一本书，并不算完成阅读一本书。阅读完一本书，只是完成了吸取知识，还要做一下自己的思考，然后输出。如果只是输入，而没有思考输出，对于要从阅读中获得心智成长这个目的来说还远远不够。 其实说白了就是要把“阅读—思考—输出”这个流程跑通，才算是真正完成阅读一本书： 做书摘2 写书评 写读后感 做读书笔记（文字） 思维导图读书笔记 PPT读书笔记","link":"/2018/12/06/%E3%80%8A%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"《如何高效的学习》读书笔记","text":"正如作者所言，这本书的书名是作者基于统计学分析后得出的，也就意味着多少有一点“哗众取宠”的成分。如果你没有提前考虑到自己与作者在学习方法之外的差异性，因为书名而盲目地相信自己也可以达到与作者相近的水平，那可能会事与愿违。但不可否认的是这本书还是有一些干货，辅以大量的练习，对提高我们的学习效率是有帮助的。 这本书的优点：作者提出了一种新的学习方法：即整体性学习法。整体性学习法本质上就是运用大脑已有的神经元网络吸收、整合信息，用已知理解未知，而非死记硬背。 作者归纳了整体性学习法的三个基本要素：结构、模型、高速公路，并且用类比的方式进行解释：结构是一系列紧密相连的知识，比如属于同一学科或者主题的知识点。作者将结构比喻成一座城市，不同的知识集合对应不同的城市。模型则是对应城市中的建筑物，已压缩的形式对知识进行抽象整合并存储。最后连接不同城市之间的高速公路则对应不同知识集合之间的神经元连接。我觉得高速公路这个比喻很贴切，既体现了神经元网络的传输速度，又暗示了建立神经元连接需要高成本高难度。 作者提出了一套的整体性学习技术，包括五个步骤：获取、理解、拓展、纠错和应用。每个步骤都提出了一些可行性较高的方法，比如针对快速获取信息的指读法和高效笔记法，针对理解信息的比喻法、内在化、图表法，针对随意信息记忆的联想法和挂钩法。 另外，作者基于个人学习经验，提出了一些基于整体性学习法的实现更高效率学习的建议和方法，以及强调自我教育的重要性。 这本书的不足之处：首先，作者对书中的一些核心概念，比如整体性学习的基础概念：结构和模型解释的不够清晰，对二者的关系和区别的描述有点模棱两可。 其次，对于书中有些承前启后的关键结点，作者都没有进行个人分析，而是通过推荐相关书籍来“推脱”责任。我觉得即便是因为个人局限性或者篇幅限制需要推荐其他更专业的书籍，也可以先给出自己的理解与分析。 我对学习方法论的看法：我一直坚信让一个人形成习惯最重要的因素不是毅力而是科学的计划。这本书给我们提供了一些值得借鉴且科学的学习方法，比如针对不同的信息使用不同的处理方式，但是任何习惯的形成都离不开持之以恒的练习。正所谓“纸上得来终觉浅，绝知此事要躬行”，方法和实践是相辅相成的，而且需要根据个体差异不断的自我调整和优化。","link":"/2020/04/09/%E3%80%8A%E5%A6%82%E6%9E%9C%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"《学会提问》读后感","text":"如果只是提出一个问题不难，但是要提出一个正确的问题很难。任何问题的提出都依托于上下文，在提出一个正确问题之前我们需要对上下文有一个尽可能客观且全面的认识，而完成这一过程的关键在于学会使用批判性思维方式。 全书围绕着解决三个问题进行论述，这个三个问题分别是： 为什么要使用批判性思维？ 为什么要通过学习才会使用批判性思维？ 如何学习批判性思维？ 首先，我们为什么要使用批判性思维？我总结出以下几个方面的理由： 可以帮助我们更快的发现这个世界的运行规律。我们生活的世界是复杂的，包括文化差异、宗教信仰的冲突、政治立场的不同等等，简单的线性思维很难帮助我们接近事物的真相。 可以帮助我们质疑和挑战专家和权威 我们往往会习惯性选择相信的专家和权威的观点，然而专家本身有自己的局限性以及需要维护的阶层利益。 可以帮助我们形成淘金式的思维模式。我们接受的教育中缺失批判性思维教育，这让我们在潜移默化中形成了海绵式的思维模式。 可以帮助我们转向强批评性思维。我们可能已经具备一定的批判性思维，但批判的目的可能是为了捍卫自己的信念，属于弱批判性思维。而真正的批判性思维是一种强批判性思维，敢于评估所有的断言和信念，尤其是对自己我断言和信念加以评估和修正。 可以帮助跨越价值观的差异带来的交流障碍。每个个体会因为成长环境和教育背景不同而形成不同的价值观，这些价值观是我们固有成见的源头。 其次，我们为什么要通过练习才会使用批判性思维？我总结出以下几个方面的理由： 批判性思维可能会让我们显得格格不入。 批判性思维是个社交活动，且是一个费时费力的过程。如果在交流过程中我们不合时宜地使用批判性思维盘问他人，不仅影响交流过程，而且还可能会影响彼此的关系。 快思维替我们做了生活大部分的决策。 快思维是一种基于个人经验对周围世界作出快速反应的思维模式。与快思维相对应的是慢思维，批判性思维就是一种慢思维方式。 刻板印象会取代慢思考。 从出生开始我们就会不知不觉地对一些事物形成刻板印象，不管是被动还是主动都是源于大脑的懒惰机制。一旦我们对某个事物形成了刻板印象，它就会变成快思考所依赖的经验。 基于快思维的一系列思维习惯限制和背叛了我们。 现实生活中存在一系列基于快思维模式和特定的上下文衍生出来的思维习惯，而这些思维习惯会让我们与批判性思维背道而驰。 以自我为中心带来的偏见。 人从出生的那一刻起就是以自我为中心来感知周围的世界，而成长的过程就是围绕这个中心不断扩张认知的过程。 我们坚信公正世界信念 所谓公正世界信念就是个体为了个人长远目标的实现，坚信这个世界的公正且稳定有序的。 最后，如何学习批判性思维？我总结出以下三个部分： 先找出论证中三个组成部分：论题、结论、论据。 1.1. 找出论证的论题。 论题大致可分为两种，分别是描述性论题和规定性论题。描述性论题是对世界描述精确与否提出的问题，反映了我们对世界的好奇。而规定性论题是属于道德和伦理的范畴，讨论的是原则性且非此即彼的问题。 在立论者会没有给出论题时，我们可以先找到结论在来确定论题。因为找到结论后，围绕结论辩论的过程就是论题渐渐清晰的过程。 1.2. 找出论证的结论。 结论是被逐步推断出来的，它们源于论证。在没有被明确告知结论的前提下，我们就得基于立论者给出的理由进行推理来得出结论。此外，我们还可以通过一些技巧来找到结论，包括：利用论题和结论相呼应的关系，在已知论题的前提下来寻找结论；寻找带结论性的引导词；在特定的位置寻找，比如文章的开头或结尾；排除非结论的内容；基于语境和立论者的背景来推导。 1.3. 找出论证的论据 所谓论据就是用来支撑或者证明结论的信念、证据、隐喻、类比和其他陈述，这些都是构建结论可信度的基础。因此，我们只有在找出支撑结论的各种论据之后才能评判结论的价值。 结论和论据之间的对应关系通常是一对多得关系。且论据本身是一个孤立的想法，不能反应逻辑关系，只有在论证和推理中才有可能存在逻辑关系。因此，找出论据的第一步就是从质疑推理过程的合理性开始，尽可能地以公平客观的角度来评价立论者的整个论证过程。 立论者在引述论据时通常会使用一些特定的指示词，比如：由于、鉴于、因为等等。我们可以通过寻找这些指示词来找出立论者引用的论据。 论据有很多种类型，同一个论题使用不同类型的论据效果可能大相径庭。其中最常见的论据类型是：将对某个证据的一些陈述作为理由，而证据来源包括事实、研究成果、生活实例、统计数据、专家或权威观点、当事人证言以及类比等等。 评价论证过程的质量和合理性 2.1. 找出论证中有歧义的地方 由于词语本身具有多义性和易混淆性，同一个词语在不同的上下文的意思可能截然不同。为此，我们需要强迫自己找出那些含义模糊的词语或短语，这些地方通常是存在歧义的地方。 寻找关键性的词语和短语的一条可行性原则是：一个词或短语越是抽象，人们就越有可能对其作出多重解读。 2.2. 找出论证中潜在的假设 所谓假设就是那些立论者没有明说出来的想法，这些想法往往是立论者认为是理所当然的论证依据，并且默认读者也是认同的。找出这些假设是我们能否客观地评价论证过程的前提。 假设主要可以分为两种，分别是价值观假设和描述性假设。 价值观假设又称之为规定性假设，是指一种想当然的看法，认为某些相互对立的价值观的一个比另外一个重要，源于个体间价值观的差异而产生的冲突。寻找价值观假设的出发点包括：一些常见的伦理道德上存在价值观冲突；了解立论者背景；论题可能产生的后果与立论者结论之间的冲突。 描述性假设，是指对这个世界过去、现在或未来是什么样的没有明说信念。寻找描述性假设的几条线索： 线索一：思考结论和论据之间存在的鸿沟，论据推导出结论是否还需要其他东西支持？ 线索二：寻找支撑理由但是没有明说的想法。 线索三：换位思考，是自己站在立论者的立场进行辩护和推理。 线索四：换位思考，是自己站在反对者的立场进行辩护和推理。 线索五：避免自己矫枉过正，找出一些不成立描述性假设。 2.3. 找出论证中存在的谬误 所谓谬误，就是论证中的欺骗手段，立论者有可能利用这个欺骗手段来说服读者接受他的结论。谬误本质上就是没有理由依据就可以被任意捏造，因此论证中的谬误不计其数。 常见的谬误有： 人身攻击型谬误：通过对论证人的品格或兴趣背景进行攻击来否定其所做的论证的质量，将讨论的重点转移出了论证本身。 滑坡谬误：通过类比的方式来偷换概念，忽略了类似是我间的差异，进而产生谬误。 追求完美解决方案谬误：通过以完美或极端的标准来衡量与评估对方解决方案，找出其中的漏洞，进而全盘否定对方的解决方案。 诉诸公众谬误：通过采用流行观点或公众感受作为论据来论证自己的观点，忽视了观点的可靠性和公众情感的盲目性。 诉诸可疑权威谬误：通过采用可疑权威的观点作为论据，试图用权威而非观点本身来说服公众。 诉诸感情谬误：激发和煽动公众情绪来让公众同意自己的观点。 稻草人谬误：选择性攻击对方立场的几个方面，而刻意忽视这个立场的其他方面，以此来全盘否定对方的立场。 虚假的两难选择谬误：过度简化论题，仅仅给出对立的两种选择来干扰公众的判断。 乱扣帽子谬误：随意给某有行为给出一个简单的原因或名称作为自己的解释，并以此为依据论证自己的观点。 转移话题谬误：故意把话题转移到与原来不相干的事情上，来逃避对原来话题的回答。 循环论证谬误：作为证明结论的理由本身是结论的另外一种说法，意思其实是相同的。 2.4. 验证论证中使用的证据的可信度 对于证据来说，要证明它们是绝对的真理或绝对的谬误都极其困难，因此与其证明它们真假，不如确定它们的可信度。 论证过程中使用的证据包括： 个人直觉：直觉最大的问题在于它的私密性。外人根本无法判读它的可靠性，并且放映出强烈的偏见。 个人经历：个人经历存在很大的局限性，不足以作为具有代表性的历史样本，具有强烈的偏见。 典型案例：典型案例通常是基于访谈或观察得出的，其描述的形式各异且深浅不同，同样具有局限性和偏见性。 当事人证言：当事人证言可能会因为个人利益而出现强烈的偏见，可能会被刻意省略信息或者被选择性引用。 专家意见：在某个领域有超于常人认知的人被称之为专家，专家的观点具有一定的可信度。然而专家本身也是人，也有其局限性。 个人观察：个人观察是根据个人认知过滤之后的产物，即使亲眼所见也不一定符合事实。 研究结果：理想情况下，研究结果是获得证据的最好的来源，因为科学研究强度可验证性、可控性和精确性。但是不管研究结果显得多么客观，其中也难免会夹杂主观因素。 类比：任何两件事物之间几乎都能找出一些共同点，因此仅仅因为找到很多共同点不能说明类比论证方法的可靠性。 2.5. 找出论证中存在的替代原因 所谓替代原因：是指一个言之成理的解释，可以用来替代理论者提供的初始原因，同样能够说明为什么特定的结果会发生。立论者很可能刻意隐瞒了替代原因，以免削弱我们对其初始原因的信心。 主要有三种情形： 日常的人际交往：人际交往过程中我们容易根据个人经验作出认为对的猜测，因此我们可能忽略其他的替代原因 生活中发生的重大或极端事件：重大或极端事件容易引发群体性的感情共鸣，个体容易失去理性思考，而忽视或无视事件真相 科学研究的结果：很多科学研究背后都有利益支撑，因此所谓的科学研究很可能是以证明一个既定的假设为导向。 寻找替代原因的几个线索： 线索一：利用组间差异得出的论据，很多组间实验都很难达到变量单一化的要求，因此造成组间差异的原因很可能不止一种。 线索二：相关性不能证明因果关系，我的理解是因果关系是自变量与因变量的逻辑关系，而相关性是一种时空上的关联，并不存在逻辑上的推导。然而，快思维模式的作用下我们很容易用关联性来证明因果关系。 线索三：以事件发生前后作为推导原因，很多时候我们会因为一件事情紧接在另外一件事情后面发生而将二者建立逻辑关系。 线索四：个人偏见，我们在解释他人的行为时普遍高估个人倾向的重要性而低估了环境因素额作用。 评价替代原因： 在逻辑上的合理性：哪些原因对你而言更有说服力。 与已知的一致性：哪些原因与你所学的其他知识之间有一致性。 时效性：哪些原因在解释或预测类似事件上成功率更高。 公众的接受程度：哪些原因更能被已接受的事实所支持。 2.6. 验证论证中使用的数据的可信度 在论证过程中最为常见的证据就是数据，而最常用的数据就是统计数据。然而，很多时候统计数据会因为呈现的方式不同而表达出截然不同的说服力。 具有欺骗性的数据常见的有： 不明来历或带有偏见的数据：这样的数据往往用大量的数据来加深读者的印象和突显数据的权威，进而让人忽视了数据的来历和数据本身的可行度。 令人困惑的平均值：平均值测定方式有三种，分别是平均数、中位数和众数。这三种方式都能测定平均值，但是结果却是截然不同。 不完整的数据：数据的呈现方式多样，因此数据的可信度是基于完整的计算过程，而非数据本身的大小。 2.7. 找出论证中被省略的重要信息 不完整的论证在所难免，原因在于： 时空限制：不论是立论者本人还是其提出论题、证据，以及论证过程都会受到时空的限制。 精力限制：人的精力有限，漫无止境的论证过程会让人觉得厌倦。 知识限制：立论者本身知识的局限性。 利益驱动：论证过程很可能是立论者为了利益而做出的欺骗性行为。 个体差异：立论者与他人直接存在着价值观、信念等多方面的差异。 正因为论证几乎不可能做到完整，因此论证过程中一定会有省略的信息。而我们要做的就是找到其中被省略的重要信息。所谓重要信息就是对结论合理与否具体决定性的信息。 寻找省略的重要信息的线索有： 常见的反驳论证：站在立论者的对立面，反驳其论证来寻找被省略的信息。 遗漏的价值取向或视角：采用不同的价值观（并非对立的价值观）来看待论证过程来寻找被省略的信息。 论证中的事实来源：考证论证中引用的事实的来源和可靠性来寻找被省略的信息。 使用权威或典型：思考论证过程中引用权威或典型是否可信，是否能够推广到一般情况来寻找被省略的信息。 结论是否有负面效果：思考结论可能带来的负面效果，找出立论者刻意隐瞒的信息。 找出基于论证的更多合理的结论 在对立论者的整个论证过程进行批判性思考之后，我们还应该思考立论者给出的结论是否是最合理的结论，我们是否还可以推导出更多合理的结论？ 找出更多合理的结论的线索有： 替换论证中涉及的信息的参照系：同一个问题或者价值观会因为使用的参照系不同而变得截然不同。 以解决论据中存在的问题为出发点：提出更多解决理由涉及的问题的方法就是这个论证可能得出的结论。 不是所有的结论都生来平等：结论之间有权重之分，有主次不分。 最后，批判性思维是一个工具，它既可以让你如虎添翼，也可能让你折戟沉沙。于己，批判性思维可以让我们更好地认清生活的真相而仍然去热爱它；于公，只有公众都能独立思考和判断，民主制度才可能真正地行之有效。","link":"/2020/02/24/%E3%80%8A%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"《曼巴精神：科比自传》读后感","text":"何为曼巴精神？ 曼巴精神是对自己的热爱的事物付诸持之以恒的热情，探索其中的奥秘，注意每一个细节，不厌其烦地重复着那些枯燥无味但又异常重要的基本功。此外在巨大的荣誉和财富面前时刻保持清醒，不忘初心。 曼巴精神是认真研究对手的每个细节，并制定对策，将全力以赴地投入视为对对手最大的尊重，并以此获得对手的尊重。正如勒布朗•詹姆斯对德怀恩•韦德说的那样：Everyone wants to put us against him,but we were just trying to make him proud of us.(所有人都想要我们和科比处于对立面，但是我们只是想要让他为我们感到自豪)。 曼巴精神是不断地自我反省，认识自己，了解自己，倾听自己的内心，顺应身体的反馈，追求身心合一的境界，时刻保持最好的竞技状态。 R.I.P 致敬我心目中最完美最励志的篮球运动员—科比•布莱恩特","link":"/2020/01/30/%E3%80%8A%E6%9B%BC%E5%B7%B4%E7%B2%BE%E7%A5%9E%EF%BC%9A%E7%A7%91%E6%AF%94%E8%87%AA%E4%BC%A0%E3%80%8B%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"《永远的三丁目的夕阳》观后感","text":"我想如果不是朋友的推荐，我不大可能会主动接触这部影片。其中一个比较直接原因在于影片的名称挺不起眼的，再者这类题材的电影已经不再是我的首选了。在第一次听到影名的时候感到有点困惑：三丁目是什么意思？为什么是永远的三丁目的夕阳？这里先回答第一个问题：丁目是日语词汇，类似汉语中胡同的意思，日本的地址通常是：区-丁目-番-号组成。因此，片名翻译过来就是：永远的第三胡同的夕阳。接下来是我对于第二个问题的答案。 故事背景影片故事背景是昭和30年，即公元1956年（昭和元年为公元1926年），日本制定“电力五年计划”，进行以电力工业为中心的建设，并以石油取代煤炭发电。日本经济至此不仅完全从二次大战中复兴，而且进入积极建立独立经济的新阶段。1955至1957年，日本出现了第一次经济发展高潮。日本人把这个神话般的繁荣，称为神武景气(Jinmu boom)。 此时已是战后十多年，百废待兴，全日本上下一副蒸蒸日上的繁荣景象。与此同时，人们也开始慢慢地从战争的阴影中走出来，而东京旧城区夕日町三丁目就是这个时代背景下日本平民生活的缩影。那个时代的日本人不像现在那样拘谨阴郁，有着当今日本人少有的对未来的坚定信念，每个人的努力就如同电影里展现的东京塔的逐渐建成一样，是可以实实在在看到成果的。再加上那时如“夕日町三丁目”一般的平民街巷所充满的人情味，怎能不让如今被沉重且无望的工作以及冷漠的人际关系所压迫的日本人们为之向往呢？ 童年记忆影片里面描述的很多细节和画面勾起了我童年的记忆，是那种温馨且快乐的记忆。我觉得铃木一家与我家有一定的重叠。我的父亲同样的是一个脾气暴躁的人，但是有时候也会有一些暖心的举动。就像铃木会特意为六子准备圣诞节回家的车票一样，我的父亲也曾用家里一个星期的伙食费为我买了一款最新上市的MP4播放器。虽然现在这个播放器已经被时代淘汰，但是我一直都留在身边，铭记这份温情。我的母亲也同一平的母亲一样，是一个温柔贤惠的家庭妇女。记得电影中有一个画面：一平不愿意午睡，张开嘴巴对着电风扇发出哇啊哇啊的声音，脑袋也随着风扇来回摇摆，被母亲发现后立刻假装睡着的场景。记得小时候我也常在午睡的时候对着家里的电风扇说话，因为这样会听到被旋转的扇叶反射回来的回声，有种千里传音的感觉。然后每次发现母亲过来时，立即摆出一副假装睡着打呼噜的样子。现在想想母亲那会应该早就看穿了我的演技，我却每次都为此洋洋得意。另外一个让我印象很深的画面是：铃木一家终于盼来三目丁区第一台电视机时，整个街道的居民都前来道贺围观看新鲜。大家都围坐在电视机旁七嘴八舌地议论着，当电视画面出现时全都目不转睛地盯着屏幕。整个屋子里时而安静、时而欢呼，一片其乐融融的景象。巧的是类似的情景也曾发生在我的家里。在我大概小学三年级的时候，我的父亲挣了一点小钱，于是给家里买了一台牡丹牌的彩色电视，那时候也算是村里的一件大事，以至于那会我在街坊邻居面前走路说话都比较嘚瑟。一般邻居们都会在吃过晚饭后陆陆续续来到我家，然后围坐在电视机旁有说有笑地看着电视，各抒己见地讨论着剧情。后来，随着生活水平地提高，越来越多的家里都配备了电视机，慢慢地晚饭后家里也开始变得清静。 隐形婚戒茶川这位以文学家自居的二流作家，在影片的前半部更多地是充当搞笑的配角，给人一种懦弱无能的感觉。然而，广美和淳之介出现彻底地改变了他的生活，也第一次让他有了家的感觉。看到茶川和广美的爱情，让我又理由相信那个是一个即便物质上贫穷匮乏，只要内心善良与真诚，同样有机会能够打动女孩子芳心的年代。当茶川战战兢兢地从口袋里面拿出用所有积蓄买来的盒子时，我以为盒子里至少会是一颗小的钻戒。然而，接下来的对话成为了整部影片最打动我的莫过于茶川向广美表白的镜头。茶川：“对不起，跟我结婚吧。我的钱虽然只够买个盒子，不过很快…盒子里的东西，我的稿费再多一点的话…”。广美：“给我戴上，那个…总有一天能买来的戒指”。虽然这段感情最终因为广美身不由己地离开而告一段落，但是当广美站在歌舞厅的天台，对着夕阳，伸出自己右手无名指，望着那枚隐形的戒指时，我觉得此生能拥有过这样一段爱情本身就是很幸福知足的事情。我们向往那个年代是因为我们内心都渴望得到一份真挚的爱情，是因为对方爱你这个人才选择和你在一起，合于性格，久于善良，忠于人品，亦或是是始于颜值，陷于才华。那个年代时间过得慢，人们对物质的需求也不高，一生也许真的只够爱一个人而已。现如今结婚的高门槛已经成为很多自由恋爱的年轻人以逾越的障碍，在现实面前而被迫选择结束的感情也已屡见不鲜。我想除了外界的因素之外，现在的爱情也许本身就缺乏一些真诚。我并不反对现在的婚姻价值观，作为女性通过自己的自然属性选择社会属性更优的男性，从物种进化的角度来说是完全符合自然法则的，可以让更好的基因得到更佳的资源配置。正因如此，那个更在意个人情感的年代才更让人怀念。 总体感受最后说说我对这部影片的总体感受。东京铁塔作为日本标志性建筑，象征着日本经济腾飞和民族再次崛起。影片的首尾镜头与东京铁塔修建到竣工的时间节点动态呼应。而与之对应的是一种静态的永恒，即第三胡同的居民的淳朴善良，以及街坊邻居之间的真挚情感。这种美好的记忆就如同夕阳一般，很美，但已是近黄昏。不难想象随着城市化建设的推进，三丁目暖黄色基调的原貌必会成为过去，取而代之的定是冷灰色基调的现代建筑，留下的只有三丁目这个地名。电影的最后一个镜头是远方温暖绚丽的夕阳，夕阳下矗立着已经竣工的东京铁塔。铃木一家面向着夕阳，一平说：“明天，后天，就算50年后，夕阳也会一直这么美”。如今已是50多年后的今天，我想关于夕阳是否依旧那么美，大家心里都有自己的答案。虽然我并不认为这是导演的故意隐喻，这也许只是个巧合。当新的时代以一种高姿态来临，那个“大家诚诚恳恳，说一句，是一句”的社会已如夕阳的余晖般慢慢地消逝，如斯人的背影般渐行渐远。不过，这也正是这部影片触动我的地方，它带给我一种翻阅旧相册时的温暖和感动。","link":"/2018/09/03/%E3%80%8A%E6%B0%B8%E8%BF%9C%E7%9A%84%E4%B8%89%E4%B8%81%E7%9B%AE%E7%9A%84%E5%A4%95%E9%98%B3%E3%80%8B%E8%A7%82%E5%90%8E%E6%84%9F/"},{"title":"Belief in a Just World","text":"前几天微信朋友圈被一篇名为《罗一笑：你给我站住》刷屏，文章讲述了一个身患白血病的女孩子，名为罗一笑，文章的封面就是她，一个脸上挂着天真可爱的笑容的女孩。其父罗某为了给女儿筹集医药费，在网上发布了一篇饱含父爱的文章。文章的内容就不赘述了，毕竟这已经不是我这篇博客论述的重点所在，何况在网上随便搜索这个有点新意的文章名就能轻易找到原文或者转载的文章。 我是在微信朋友圈看到这篇文章的，对于这类带有“乞讨性质”的文章，我一般都是持怀疑态度并习惯性忽略。但是这次我却被这个文章名以及封面上小女孩的笑容所吸引，卸下来了防备，看完全文并转发了朋友圈，以此表达自己的爱心与祝福。 然后，今天在微信朋友圈看到了另外一篇文章，这篇文章戳穿了“罗一笑事件”的骗局，揭露其中的内幕。我这才意识到这可能又是一场网络营销的经典案例，而且估计自己和很多富有同情心的民众一样已经成为炮灰。 讲真，世上最让人感到愤怒的情况可能莫过于三种：一是被利用；二是被欺骗；三是被迫承认自己的愚蠢。当着三种情况同时在一件事情发生，我相信内心的那种怒火的不言而喻的。伤害最深的就是那些满怀善意转发朋友圈的人。 截止目前，这件事的后续报道仍是接二连三，一度占领着各种媒体的头条。报道的内容也是各执一词，标题也是博人眼球，这个很China。只是，我觉得事情是真是假已经不很重要的，重要的是它对社会造成的伤害已经成事实。聊聊群众为什么会一次又一次的被欺骗似乎更有意义点。 不过，我仅从个人的角度来分析。毕竟我没有做广泛的群众调查，也就无法知晓广大群众的真实想法。但是，我自己作为一个普通群众中的一员且同样是炮灰之一，说说自己的想法，也许能找到与我产生共鸣的人？ 言归正传，撇开个人主观方面的差异，我觉得有两个客观的原因是此次我“沦陷”的主要推手。下面具体说说我的个人的理论依据。 ** 公正世界信念 ** 第一个是公正世界信念，我一直相信这个理论是真实存在的。这个理论是在1965年，由美国心理学家Lerner首次提出的“公正世界信念(Belief in a Just World，BJW )”的概念：个体有一种需要：相信他们生活在一个公正的世界里，在这个世界里人们得其所应得，所得即应得。 美国心理学家Lerner及其同事研究了美国五六十年代的种种社会现象，比如说人们在没有细究事情的原委之前，就会贸然地认为高空作业摔伤的工人一定是因为工作马虎不认真、严重车祸的受害者一定是因为不遵守交通规则或飙车、流浪汉流落街头就是因为他们好吃懒做不愿意去工作等等。基于此，Lerner提出了著名的公正世界信念的概念：“个体有这样一种需要：相信他们生活在一个公正的世界里。在这样一个世界里，人们得其所应得。这种世界是公正的信念，可使个体相信他们所处的物理和社会环境是稳定有序的，从而有利于个体适应这些环境。如果这种信念缺失，个体就很难使自己致力于长远目标的追求，难以遵循社会规范行事。由于公正世界信念在个体适应方面具有重要的功能，所以人们极不情愿放弃这种信念，并且一旦遇到例证表明世界是不公正的、无秩序的，他就会陷入忧虑烦恼之中。” 反观“罗一笑事件”，这个事件里面有几个关键因素，分别是小女孩，白血病，父爱。一个天真可爱的小女孩遭遇命运的不公平，承受白血病这种不可控的天灾带来的痛苦。更何况主角是一个小女孩，一个无辜的孩子，还没来得及理解死亡的意义就要面对死亡威胁。这显然不是我们愿意看到的，我们希望自己生活在一个有爱的世界里，同时也希望未来某个时刻如果自己的孩子在遇到困境的时候能得到社会援助。因此，我们会很容易同情心泛滥，献出自己的爱心，为筑建一个心中期望的世界添砖加瓦。也许如果主角不是儿童或未成年人，而是一个成年人，我想也许会有一部分将他/她的不幸遭遇归责于其个人不良的生活习惯，认为一定是他/她不注意个人卫生或是缺乏自控力才染上重病，比如吸烟、酗酒等。因此，我们心里很可能不会去同情他/她，甚至觉得他/她罪有应得。大多数人相信一个自控力强且生活习惯好的人得到的应该更好的生活，不愿意接受病魔不期而至的事实。此外，这个事件还要一个不能忽视的因素：父爱。正所谓父爱如山，母爱似海。这两种世间最伟大也是最无私的爱，它们无疑是这个社会的道德基石。除去有童年阴影的少数人，大多数人都是在父爱和母爱的沐浴下长大的。因此，我们几乎丝毫不会怀疑它们的真实性，内心也期望它们是普遍存在的。这也是为什么我的心理防线会被攻破的原因所在。然而，当事件的内幕被曝光之后，大家发现自己的善意被愚弄了，纷纷开始将矛头指向罗父还有相关的媒体人，网上瞬间谴责声一片，此时已经没多少人再将注意力放在罗一笑的病情上了，而是急于发泄心中的怒火。这也正是公正世界信念的体现，大家都倾向于相信自己所处的物理和社会环境是稳定有序的，因为这样才有助于我们长期目标的发展。 再次声明，我仅仅是结合“罗一笑事件”分析这种心理现象，我个人为罗一笑小盆友的遭遇感到同情，也不怀疑罗父爱女心切的心情。我要批判的不是他们父女，而是怒斥那些利用群众心理软肋进行网络营销，谋求个人利益的媒体人。 ** 心理阈值效应 ** 第二个是心理阈值效应。阈值效应是一个普遍存在于社会各个领域的现象，包括经济、心理、学习等。在经济学中经常提及一个概念，叫做“边际递减效应”。何为“边际递减效应”？我记得一个文革时期的经济学家给出的解释最为恰当和接地气，故事大概内容是：在大跃进之后和文革之前的这段时间，国内经济不景气，生产力低下，粮食产量低。于是，村委会鼓励群众去收割完的稻田里捡稻穗，减少粮食的浪费。刚开始大家都在距离家近的稻田里捡稻穗，并且每天都能满载而归。过了一段时间，附近稻田的稻穗都被捡完了，人们不得不去离家更远的稻田捡稻穗，捡满一箩筐之后再背回家。随着时间的推移，人们离家的距离越来越远，稻穗也越捡越少，渐渐地人们每天在捡稻穗的过程中消耗的能量等于或大于捡到的稻穗的能提供的能量，常常饿着肚子都捡不满一筐，这时候如果继续捡稻穗则得不偿失。这就是边际递减效应，而这个节点就是阈值点。小于这个阈值时则收获大于消耗，超过这个值则收获小于消耗，且二者的比值呈递减趋势。 心理阈值效应也是类似。当某件事情触发了心理的阈值，则会适得其反。当年轰动一时的“郭美美炫富事件”爆出红十字会的腐败内幕，让整个社会的信任基础遭受重创，此后多数人都不再愿意捐钱给红十字会。然而，这个阈值是动态的。经过一段时间的冷却或者其他事件转移注意力，加上期间被一些正能量的事迹所影响，愿意再次相信社会是和谐美好的，因此人们的心理情绪也会慢慢回归阈值以下，但是也许再也回不到之前的水平了，也就意味人们比之前更容易达到阈值点。假设社会上频繁的出现一些破坏社会信任的负面事件，会导致人们越来越冷漠，最终对所处的社会彻底失去信任。 我想“罗一笑事件”背后的策划者毋容置疑地再次挑战了人们的阈值限度，造成了不可逆的伤害。Double Kill! Nice! ** 小结 ** 罗曼·罗兰说过，世界上只有一种真正的英雄主义，就是认清了生活的真相后还依然热爱它。虽然说我所处的社会一次又一次的面临信任危机，但是我还是选择去拥抱它，因为我看到了很多和我一样被欺骗的群众，让我知道身边的大多数人都是心存善意的。不过，我可能需要换一种更为理智的拥抱姿势罢了。","link":"/2016/12/08/%E4%B8%96%E7%95%8C%E5%85%AC%E6%AD%A3%E4%BF%A1%E5%BF%B5/"},{"title":"世界是多元的","text":"世界是多元的，相比之下个人的生活圈显得单一，特别是像我这样在二线省会城市的普通青年。最近有两件事情让我感触挺深的，它们彼此之间没有交集，与我的生活也相差甚远。它们代表着世界在同一时段下的不同呈现方式，陌生却又是那么真实。 第一件事是在朋友圈看到了一篇关于全球变暖导致两极的生态圈剧变，进而威胁了生存于其中的生物的生命。文章图文并茂，措辞严厉，搭配的图片更是让人看得触目惊心。如果仅从周围的生活圈一片“欣欣向荣”的样子，很难联想到离我们很远的地方正在为人类肆无忌惮地地污染环境而深受其害。可悲地是，我并不觉得这种文章会产生多少影响力，很多人包括我很可能只是停留在看完之后的一丝感叹与自责之中，随后又恢复到原有的生活节奏之中。我们常常听到的环保标语是“拯救地球母亲”，然而真相是地球并不需要拯救，真正需要拯救是人类本身，可是我们这个国家举国上下都似乎沉迷于高速的经济发展之中，恐怕想让他们出于环保的目的而放弃既得利益是一件很难做到的事情吧？ 第二件事是下午在YouTube上面看到一段采访视频，采访的主人公是一个在美国纽约追梦的中国女孩。她个人是纽约大学房地产金融专业硕士毕业，毕业之后选择留在纽约拼搏，证明自己的价值。她给我印象最深的除了高学历之外，更多地是一种由内而外的自信。如果仅从大众的审美角度来说算不上美女，属于一个很普通的女生类型。但是她得体的言谈举止、自律的生活节奏和不卑不亢的工作态度在不经意间让人心生敬佩。我认为自信分很多种，最常见也是最肤浅的自信来源于出众外貌或身材，这些先天的优势很容易让人产生优越感，本能也，无可厚非。而最稀缺也是最可贵的自信来源于内心的自律和成熟的心智，也许看似样貌平平无奇，一经接触或交谈便能吸引对方，让人觉得有趣。外貌总会随着时间的流逝慢慢失去了往昔的风采，而一个有趣或者说自信的灵魂却是随着在岁月中酝酿得愈加香醇浓郁。 世界是多元的，且需要从宏观和微观地双重角度去看待。有时候太局限于个人的生活圈，容易变成井底之蛙，进而变得盲目乐观或者自大，导致对事物的判断出现严重的偏差。我一直觉得，贫穷不是一个人最可怕的状态，无知才是。","link":"/2016/08/05/%E4%B8%96%E7%95%8C%E6%98%AF%E5%A4%9A%E5%85%83%E7%9A%84/"},{"title":"两个特殊函数+load和+initialize","text":"记得还在上一家公司任职的时候，在研发部的探讨会会上就“+load的加载过程”这一议题有过激烈的讨论，大家各执一词，争得面红耳赤。最终是部门老大专门做了一期讲解，才平息了这场争执。但是那时候的讲解并未涉及到源代码分析，而是基于测试代码做的分析，故我并没有完全理解。 在苹果开发文档中提及到：+load是在类或者分类被添加到runtime的时候被调用，而+initialize则是在类的用实例方法或者类方法第一次被调用之前调用。 上面的说明只是说明了这两个函数调用时机，但是并没有涉及父类、子类和分类之间的调用顺序和相互影响，于是试着结合apple公司的开源代码objc4-532.2试着分析这两个函数的加载过程，以加深理解。 +load首先在objc-os.mm文件中找到函数_objc_load_image_objc_load_image： 1234567OBJC_EXPORT void _objc_load_image(HMODULE image, header_info *hinfo){ prepare_load_methods(hinfo); call_load_methods();} 根据参数判断，这个函数应该是在加载镜像文件的时候由系统直接调用，且里面就两行代码，分别是对+load函数的预处理与加载 接着在objc-runtime-new.mm文件找查看prepare_load_methods的函数实现： 123456789101112131415161718192021222324252627282930313233343536373839404142void prepare_load_methods(header_info *hi){ size_t count, i; rwlock_assert_writing(&amp;runtimeLock); //获取头文件中所有的类 classref_t *classlist = _getObjc2NonlazyClassList(hi, &amp;count); //先处理类中的+load方法 for (i = 0; i &lt; count; i++) { //处理类与父类中的+load函数 schedule_class_load(remapClass(classlist[i])); } //再处理分类中的+load方法 category_t **categorylist = _getObjc2NonlazyCategoryList(hi, &amp;count); for (i = 0; i &lt; count; i++) { //初始化分类 category_t *cat = categorylist[i]; class_t *cls = remapClass(cat-&gt;cls); if (!cls) continue; // category for ignored weak-linked class realizeClass(cls); assert(isRealized(cls-&gt;isa)); //将可加载的（存在+load函数）分类归类 add_category_to_loadable_list((Category)cat); }}static void schedule_class_load(class_t *cls){ if (!cls) return; assert(isRealized(cls)); // _read_images should realize if (cls-&gt;data()-&gt;flags &amp; RW_LOADED) return; // Ensure superclass-first ordering //递归调用，优先处理父类 schedule_class_load(getSuperclass(cls)); //也就意味着父类中的+load方法先被加入列表 add_class_to_loadable_list((Class)cls); changeInfo(cls, RW_LOADED, 0); } 由上述函数可以推断出：父类的+load方法先于子类被加入待处理列表，分类与类中的+load方法是区分对待的。 接着，在objc-loadmethod.mm文件中查看call_class_loads函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697void call_load_methods(void){ static BOOL loading = NO; BOOL more_categories; recursive_mutex_assert_locked(&amp;loadMethodLock); // Re-entrant calls do nothing; the outermost call will finish the job. if (loading) return; loading = YES; void *pool = objc_autoreleasePoolPush(); do { // 1. Repeatedly call class +loads until there aren't any more //先调用类中的+load方法 while (loadable_classes_used &gt; 0) { //先入先出处理+load函数列表 call_class_loads(); } // 2. Call category +loads ONCE //再调用分类中的+load函数 more_categories = call_category_loads(); // 3. Run more +loads if there are classes OR more untried categories } while (loadable_classes_used &gt; 0 || more_categories); objc_autoreleasePoolPop(pool); loading = NO;}static void call_class_loads(void){ int i; // Detach current loadable list. struct loadable_class *classes = loadable_classes; int used = loadable_classes_used; loadable_classes = NULL; loadable_classes_allocated = 0; loadable_classes_used = 0; // Call all +loads for the detached list. //先入先出的遍历顺序，调用父类函数先于子类 for (i = 0; i &lt; used; i++) { Class cls = classes[i].cls; //获得+load的函数指针 load_method_t load_method = (load_method_t)classes[i].method; if (!cls) continue; if (PrintLoading) { _objc_inform(\"LOAD: +[%s load]\\n\", _class_getName(cls)); } //注意：是通过函数指针直接调用，而非使用objc_msgSend，因此不会走runtime调用过程。 (*load_method)(cls, SEL_load); } // Destroy the detached list. if (classes) _free_internal(classes);}static BOOL call_category_loads(void){ .... // Call all +loads for the detached list. for (i = 0; i &lt; used; i++) { Category cat = cats[i].cat; load_method_t load_method = (load_method_t)cats[i].method; Class cls; if (!cat) continue; cls = _category_getClass(cat); if (cls &amp;&amp; _class_isLoadable(cls)) { if (PrintLoading) { _objc_inform(\"LOAD: +[%s(%s) load]\\n\", _class_getName(cls), _category_getName(cat)); } //直接通过函数指针进行调用，而非通过objc_msgSend调用 (*load_method)(cls, SEL_load); cats[i].cat = NULL; } } ..... return new_categories_added;} 在上述函数中，先调用了类的+load函数列表，再处理分类中的+load函数，且都是直接通过函数指针调用。又因为父类的+load函数先于子类加入列表，因此+load函数的调用顺序是：父类-&gt;子类-&gt;分类 在上一篇博客Objective-C Category 深入浅出系列之实现原理中结合源代码分析了Category的实现原理。其中有一个重要的知识点就是分类Category中函数会覆盖主类中同名的函数。然而这种情况发生的前提是函数必须是通过runtime机制（使用objc_msgSend发送消息）调用，因为这样才会通过遍历类的方法列表去获得方法对应的实现。 +initialize既然+initialize函数是在类的实例方法或者类方法第一次被调用之前触发，而类的实例方法或者类方法正常的调用方式是通过objc_msgSend函数。那么+initialize很有可能是在objc_msgSend函数中进行判断和触发，于是，在objc-msg-x86_64.s文件找到了objc_msgSend的汇编实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/******************************************************************** * * id objc_msgSend(id self, SEL _cmd,...); * ********************************************************************/ .data .align 3 .private_extern __objc_tagged_isa_table__objc_tagged_isa_table: .fill 16, 8, 0 ENTRY _objc_msgSend DW_START _objc_msgSend NilTest NORMAL GetIsaFast NORMAL // r11 = self-&gt;isa CacheLookup NORMAL, _objc_msgSend // r11=method, eq set (nonstret fwd) jmp *method_imp(%r11) // goto *imp NilTestSupport NORMAL GetIsaSupport NORMAL// cache miss: go search the method listsLCacheMiss: DW_MISS _objc_msgSend GetIsa NORMAL // r11 = self-&gt;isa MethodTableLookup %a1, %a2, _objc_msgSend // r11 = IMP cmp %r11, %r11 // set eq (nonstret) for forwarding jmp *%r11 // goto *imp DW_END _objc_msgSend, 1, 1 END_ENTRY _objc_msgSend#if __OBJC2__ ENTRY _objc_msgSend_fixup DW_START _objc_msgSend_fixup NilTest NORMAL SaveRegisters _objc_msgSend_fixup // Dereference obj/isa/cache to crash before _objc_fixupMessageRef movq 8(%a2), %a6 // selector GetIsa NORMAL // r11 = isa = *receiver movq cache(%r11), %a5 // cache = *isa movq mask(%a5), %a4 // *cache // a1 = receiver // a2 = address of message ref movq %a2, %a3 xorl %a2d, %a2d // __objc_fixupMessageRef(receiver, 0, ref) call __objc_fixupMessageRef movq %rax, %r11 RestoreRegisters _objc_msgSend_fixup // imp is in r11 // Load _cmd from the message_ref movq 8(%a2), %a2 cmp %r11, %r11 // set nonstret (eq) for forwarding jmp *%r11 NilTestSupport NORMAL DW_END _objc_msgSend_fixup, 0, 1 END_ENTRY _objc_msgSend_fixup STATIC_ENTRY _objc_msgSend_fixedup // Load _cmd from the message_ref movq 8(%a2), %a2 jmp _objc_msgSend END_ENTRY _objc_msgSend_fixedup#endif 汇编基本就是大一水平，很有限。初略发现在调用指令_objc_msgSend之前，先调用了_objc_fixupMessageRef函数。 接着在objc-runtime-new.mm文件中找到_objc_fixupMessageRef函数： 123456789101112131415161718192021222324252627282930313233343536OBJC_EXTERN IMP _objc_fixupMessageRef(id obj, struct objc_super2 *supr, message_ref_t *msg){ IMP imp; class_t *isa; ..... msg-&gt;sel = sel_registerName((const char *)msg-&gt;sel); if (ignoreSelector(msg-&gt;sel)) { // ignored selector - bypass dispatcher msg-&gt;imp = (IMP)&amp;vtable_ignored; imp = (IMP)&amp;_objc_ignored_method; }#if SUPPORT_VTABLE else if (msg-&gt;imp == (IMP)&amp;objc_msgSend_fixup &amp;&amp; (vtableIndex = vtable_getIndex(msg-&gt;sel)) &gt;= 0) { // vtable dispatch msg-&gt;imp = vtableTrampolines[vtableIndex]; imp = isa-&gt;vtable[vtableIndex]; }#endif else { // ordinary dispatch //常规的消息派发，遍历类的函数列表 imp = lookUpMethod((Class)isa, msg-&gt;sel, YES/*initialize*/, YES/*cache*/, obj); ...... } return imp;} 在上述函数中调用了lookUpMethod函数，其中调用了prepareForMethodLookup函数： 1234567891011121314151617181920212223IMP prepareForMethodLookup(Class cls, SEL sel, BOOL init, id obj){ rwlock_assert_unlocked(&amp;runtimeLock); if (!isRealized(newcls(cls))) { rwlock_write(&amp;runtimeLock); realizeClass(newcls(cls)); rwlock_unlock_write(&amp;runtimeLock); } //调用_class_initialize对类进行初始化 if (init &amp;&amp; !_class_isInitialized(cls)) { _class_initialize (_class_getNonMetaClass(cls, obj)); // If sel == initialize, _class_initialize will send +initialize and // then the messenger will send +initialize again after this // procedure finishes. Of course, if this is not being called // from the messenger then it won't happen. 2778172 } return NULL;} 在objc-initialize.mm函数中，找到_class_initialize函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void _class_initialize(Class cls){ assert(!_class_isMetaClass(cls)); Class supercls; BOOL reallyInitialize = NO; // Make sure super is done initializing BEFORE beginning to initialize cls. // See note about deadlock above. //递归，保证父类先于子类初始化 supercls = _class_getSuperclass(cls); if (supercls &amp;&amp; !_class_isInitialized(supercls)) { _class_initialize(supercls); } ..... if (reallyInitialize) { // We successfully set the CLS_INITIALIZING bit. Initialize the class. // Record that we're initializing this class so we can message it. _setThisThreadIsInitializingClass(cls); // Send the +initialize message. // Note that +initialize is sent to the superclass (again) if // this class doesn't implement +initialize. 2157218 if (PrintInitializing) { _objc_inform(\"INITIALIZE: calling +[%s initialize]\", _class_getName(cls)); } //通过objc_msgSend调用+initialize函数 ((void(*)(Class, SEL))objc_msgSend)(cls, SEL_initialize); if (PrintInitializing) { _objc_inform(\"INITIALIZE: finished +[%s initialize]\", _class_getName(cls)); } // Done initializing. // If the superclass is also done initializing, then update // the info bits and notify waiting threads. // If not, update them later. (This can happen if this +initialize // was itself triggered from inside a superclass +initialize.) ..... return; } ......} 通过上述函数可知两点：一是父类的+initialize函数先于子类调用，二是+initialize不同于+load函数的采用函数指针调用，而是通过objc_msgSend函数调用，如果分类实现了+initialize函数，那么类（包括子类和父类）的+initialize函数就会被覆盖。 因此，+initialize的调用顺序是父类-&gt;子类，且分类的实现覆盖类的实现，因此分类中的+initialize可能会被多次调用。 小结至此，对于+load和+initialize的调用规则和方式有了进一步的认识。在日后的编程过程中也可以根据二者的特点，更好的使用它们的功能。","link":"/2015/04/01/%E4%B8%A4%E4%B8%AA%E7%89%B9%E6%AE%8A%E5%87%BD%E6%95%B0+load%E5%92%8C+initialize/"},{"title":"《中国哲学史》读后感","text":"《中国哲学史》讲述了中国哲学的发展历史，打通了古今中外的相关知识，在有限的篇幅里融入了冯友兰先生对中国哲学的理解，是史与思的结晶，充满了人生的睿智与哲人的洞见。作者认为，哲学的功能在于提高人的心灵，超越现实世界，体验高于道德的价值。在学习哲学的过程中，人们没有智慧与不智慧之分，而哲学家们研究哲学的目的也从来不是为了提高智慧，仅仅是为了哲学本身。哲学既不是生存的工具或手段，也非我们生活的目的与理想，但它能使我们更清楚地认识到人生的意义。 在书中冯友兰先生着重于用浅显易懂的言语对哲学家本人思想的重新整理，梳理了中国哲学史上的几个重要的流派：儒家、墨家、道家、名家、阴阳家、法家，及各派在各个时期的发展、演变、更新。冯友兰自己认为，就《中国哲学史》的内容来讲有两点可以引以自豪的: 一是把先秦名家的辩者区分成两派;另一点是分辨出宋代程颢程颐兄弟思想的差异和各自特点。此二点均发前人所未发，为中国哲学史界普遍接受。 说到哲学，我们一般想到的都是西方的哲学，而并不知道中国也有哲学。其实中国哲学有三类，玄学，道学，义理之学，只是中国哲学并没有冠“哲学”之名。 中国哲学之所以缺少严谨的系统的体系，可能和中国人思想方式有关。每个民族都会在其文明发展的同时对人和世界的各种本体性问题发问，于是则产生了哲人。不同民族的哲人思考的终极问题往往相同，但思考的方法，思想的表述则大相径庭，是以各民族的哲学之面貌多有不同。区别于西方注重逻辑和思维缜密，中国的哲学更注重于现象而轻规律，逻辑的成分自然较少。如各个名家思想，常常是以其日常的“零碎语录”编辑而成的哲学，因而中国的哲学也就具有直观性、随意性及非专业性。 但事实上，在中国，哲学如宗教之于西方世界一样深深渗入社会，为常人所持。原因在于中国很多哲人并不以哲人自居，而是在日常行事中表达自己的思想，不求构筑体系，这是以有别于西方的。正如书中所言：“故哲学家之有所蔽，正因其有所见。惟其如此，所以大哲学家之思想，不但皆为整个的，而且各有其特别精神，特别面目”。而此书的作用，便是系统地讲解了中国哲学史从古至今的发展演变，让人充分了解中国的哲学发展。 一时代有一时代之时代精神，一时代之哲学即其时代精神之结晶也。全书分为两部子学时代和下篇经学时代。冯友兰先生从诸子百家中孔子说起。孔子之前只有鬼神，术数，没有一个鲜明的系统。孔子之后，儒家墨家，道家法家，阴阳家名家，无论是对事物的观察，处世之方，或者政治及社会主张，以及对理想之人格和社会的期望，都各自发展出系统的理论，并且身体力行，自成一派，发扬光大，这就是子学时代。而经学时代，则分为古文及今文。“经”即诸子之文，经学即是以旧瓶装新酒，用前人的经文来阐释自己的理论，生搬硬套自然无可避免。自董仲舒开创独尊儒术之时代始，历数两汉之古今文经学之争，魏晋南北朝之玄学佛学，唐朝之佛学以至宋明理学，最终以康有为等人为中古时代之结束。 冯友兰认为，中国哲学的精神之一，便是哲学背负着平衡入世与出世，现实与理想的矛盾。入世出世之对立，正如现实与理想主义的对立，而哲学的使命正是要在这两极对立中寻求它们的综合或许我们该在世俗中陶冶我们的性情。中国的哲学，以其所称的“直觉的概念” 出发，所以很多都是既入世又出世的道德。如今的我们似乎忘了原本的性情，在大流中随波逐流，每天除了工作挣钱，就是抱怨生活的不公平，很难静下心来读一本好书。在这样浮躁的状态下我们是不可能做到出世，我们应该明白现实与理想之间的差距是永远不可能消除的。人类一直在追求那能看到却不能到达的彼岸，那是人耐以生活的根本。由此而言，人们把生存看成是一种负担，一种难言的痛苦就可想而知了。 在中国哲学体系中，各时代的哲学家亦将此思想融入自己的生存之道之中。 儒家推崇“仁义”之道，也表现出神似欧陆浪漫主义诗哲追求的“暮春而游”之境，便是在其现实与抱负无法统一时，用哲学思想在两者之间寻求平衡，在世俗之中修养身心。对于我们而言，又何尝不是这样的情形。冯友兰说，哲学的功能不是为了增进对客观事物的认知，而是为了让人的心灵得到升华，超越现实世界，体验高于道德的价值。其实哲学并不是高高在上，高不可攀的学问，实际上它就深深的蕴涵在我们的日常生活当中，并且与我们的生活密切相关，密不可分。只不过我们缺少是让它们浮出水面，上升到哲学高度的理论思维而已。因此，我们更应该学习哲学，体验超乎现实的道德修养，吸取其精髓。在入世与出世之间修行品性，在喧闹的生活中创造自己的生活，在残酷的现实中建立自己强大的内心世界。","link":"/2018/10/20/%E4%B8%AD%E5%9B%BD%E5%93%B2%E5%AD%A6%E5%8F%B2-%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"二叉搜索树（BST）","text":"简述二叉查找树（Binary Search Tree），又叫有序二叉树，具有以下3个性质： 左子树如果不为空，那么它所有的节点的值都小于它的根节点 右子树如果不为空，那么它所有的节点的值都大于它的根节点 任意节点的左、右子树都是二叉查找树。 复杂度 时间复杂度 由于二叉搜索树的查询、插入或删除的时间复杂度取决于目标节点到根节点的距离，即深度。 二叉搜索树可分为平衡树和非平衡树两大类，注：此处的平衡是指所有叶子的深度趋于平衡。 平衡度最高的二叉树是AVL树，其时间复杂度同二分查找一样为O(logN) 非平衡树最极端的情况是偏斜二叉树，即所有的节点都在根节点的一边，也就是链表结构。此时树的深度为n，其时间复杂度同顺序查找一样为O(n) 因此，二叉搜索树的时间复杂度介于O(logn)和O(n)之间。 空间复杂度 二叉搜索树的空间大小只与其节点的个数相关，所以其空间复杂度是O(n)。 遍历方式二叉搜索树有三种遍历方式，分别是： 先序遍历：根节点→左节点→右节点。 中序遍历：左节点→根节点→右节点，结果是一个有序序列。 后序遍历：左节点→右节点→根节点。 优缺点 优点 二叉搜索树是介于数组和链表的一种折中方案，数组查找方便但是插入或删除麻烦，而链表则恰好与数组相反。 相较之下，二叉查找树在查找、插入或删除的时间复杂度都较低，适用于处理大批量的动态数据。 缺点 构建二叉搜索树本身或维护其平衡需要额外的时间或空间成本。 参考资料 二元搜尋樹 - 维基百科，自由的百科全书 二叉排序树（二叉搜索树）的时间复杂度&amp;空间复杂度_xuxinrk的博客-CSDN博客_二叉查找树的时间复杂度","link":"/2019/08/16/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%88BST%EF%BC%89/"},{"title":"亚当·斯密的人性观","text":"亚当·斯密作为市场经济之父在经济学界德高望重，他最为人们熟知的两本书分别是《道德情操论》和《国富论》。然而，这两本书阐述的人性观却是截然相反。 《国富论》主张人性是自私的。斯密有句名言：“每一个人，不需要自己关心社会福利，他也不知道自己怎么去推动社会的福利，他只需要关心自己，追求自己的福利就可以了。与此同时，会有一只看不见的手让他的努力转变为对公共事业的推动。这只看不见的手会让个人的自私自利推动社会福利的改进。” 《道德情操论》主张人不仅仅是自私的，同时有道德且具有同情心，也就是有一种设身处地为他人着想的能力。人们把自己认为的别人是否幸福，当做自己是否幸福的一部分。这是一种天生的能力，叫“同情心”。 亚当·斯密的两种观点表面上看来是自相矛盾，然而斯密的第三个观点告诉我们之前的两种人性观是共存的。斯密认为：“人的同情心是随着人与人之间距离的拉远而急速减弱的。” 有一种说法认为经济学是建立在人性自私的基础上的，结合人际互动二分法：小圈子靠爱心，大世界靠市场。这种说法在市场范围内是成立的。小圈子靠爱心、讲同情心，而大世界靠市场、讲规则。斯密的重要建议是：在家庭和朋友圈内不斤斤计较，过分讲究市场规则。但是在市场上则不要强求陌生人表现出不切实际的爱心。 简而言之，人性具有两面性，在不同的情况下用不同的方式对待。","link":"/2016/11/21/%E4%BA%9A%E5%BD%93%C2%B7%E6%96%AF%E5%AF%86%E7%9A%84%E4%BA%BA%E6%80%A7%E8%A7%82/"},{"title":"关于爱的一点想法","text":"前言前不久又翻读了《少有人走得路》这本书，并将其置于枕边，每天晚上睡觉之前或是蹲马桶的时候看上几个章节，那种感觉妙不可言。这本书从来没有让我失望过，每看一次都收获不少，确实是一本值得读一辈子的好书。 爱的定义这次的阅读有一个论点让我深以为然，就是关于爱的定义。作者斯科特·派克是这样定义的：“爱，是为了促进自我和他人心智成熟，而具有的一种自我完善的意愿。“ 爱，是一种神秘的现象，我个人觉得很难言明爱是什么，如何定义。如果有人问我：”你觉得爱是什么？“ 我很可能回答：”它是一个很奇妙的东西。“ 然而，当我在书中看到作者给出的定义时，觉得他完整的表达了我对于爱的理解。 爱是长期的和渐进的过程。爱是自我完善，意味着心智不断成熟。当我在付出爱的努力，不仅能让他人的心智成熟，自己也同样获益。真正意义上的爱，既是爱自己，也是爱他人。我始终坚信一个不爱自己的人是不可能爱别人的。一个缺乏自律的父母，不可能让孩子懂得什么是自我完善；一个自私的伴侣，不可能察觉另一半情绪细微变化和顾忌另一半的心理感受。显然，自私和缺乏自律就是一种心智不成熟的表现，换言之就是不自爱的结果。这也许和大多数人理解的爱不太一样，以为爱就只是给予和付出。殊不知，真正的爱是自我完善，也是帮助他人完善。它意味着持续地努力，超越自我界限。 对于爱最大的误解，莫过于将男女恋爱理解为爱。我以前也是这样理解，其实我错了。 坠入情网提及爱这个字眼，相信很多人都会想到男女恋爱，尤其是把坠入情网当成爱。坠入情网的人，时常会把”我爱你“这样的句子挂在嘴边，以此表达爱意。然而，这只是一种主观愿望罢了。要了解坠入情网的本质，首先理解心理学上的”自我界限“。 何为”自我界限“？在新生婴儿的眼里，一切移动或静止的事物之间，他和周围的人之间，在单个个体和整个世界之间，没有任何界限和区别。随之年龄和认识的增长，他会发现他和世界不是一回事。他感觉饥饿，母亲不见得立刻出现；他想玩耍的时候，母亲未必能及时配合。他渐渐地意识到自己的意愿和母亲的行为完全是截然不同的两回事，这也就是自我意识的形成。通常，婴儿的自我意识能否健康发展，取决于同母亲的关系是否融洽。当婴儿意识到自己是一厢情愿的，不能主宰其他人的意愿，于是开始在自己和周围世界之间做出区分。慢慢地我们能区分出自己和外在世界更多的不同，认识到自己的局限性。这样的认知就是”自我界限“。 永远活在”自我界限“中，只会给人带来孤寂。对他们而已，世界充满险恶，自我界限是保护伞，孤独和寂寞反而能带来安全感。但是大部分人还是渴望摆脱寂寞，冲出自我界限的牢笼。坠入情网，就是表现之一，暂时性地摆脱寂寞。坠入情网意味着”自我界限“的某部分崩溃，使我们的自我与他人的自我合二为一。情感就像决堤的洪流，声势浩大地涌向所爱的人，于是寂寞消失了，取而代之的是难以言喻的狂喜。 显然，坠入情网是情感和心灵退化现象。与心爱的人在一起，跟童年时和父母相伴的记忆彼此呼应，让我们体会到幼年时无所不能的快感，似乎没有什么能够阻止我们实现愿望。然而，残酷的现实会像击溃两岁小孩的幻想一样击溃我们的爱情之梦。日常琐事和难题，容易让双方产生矛盾和冲突，对这种”爱“造成威胁甚至击溃。我们必须面对现实，学会真正的相知和相爱，以此来避免上述这种虚幻的爱。 坠入情网是自我界限暂时性崩溃的现象，只要客观条件允许，就会发生。而真正的爱是需要彼此付出努力的，是一种主观意愿。坠入情网的经历终结，自我界限会恢复原样。而真正的爱是对自我界限的扩充，而不是使其恢复原状。 小结真正的爱不是过度依赖，也不是自我牺牲，更不是一种感觉，而是实际行动，是心智上地成长。在爱一个人之前，首先成为一个自爱的人，一个有趣的人，再和另外一半一起有趣下去。 如何成为一个有趣的人？还在努力中…","link":"/2017/01/08/%E4%BB%80%E4%B9%88%E6%98%AF%E7%88%B1/"},{"title":"使用PlistBuddy命令动态修改APP名称","text":"当一个工程里面包含多个target且每个target都有本地化的名称，一般做法是为每个target配备一个InfoList.strings文件。随着target数量和支持的语种增多，InfoList.strings文件数量也增加，更改和管理target名称也会变得复杂。 我们可以在工程里面只保留一个InfoList.strings文件用于显示当前编译的target本地化名称，并且将所有target的本地化名称用一个plist文件统一管理，然后使用shell脚本和PlistBuddy命令在编译阶段动态修改target名称。以下是具体实现： 假设工程中有4个target，本地化需求为英语（en）和西班牙语言（es）。 1、在Xcode中创建一个名为ProductName.plist文件，并保存至工程根目录。注意：这个文件不需要和任何target关联。 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;&lt;plist version=\"1.0\"&gt;&lt;dict&gt; &lt;key&gt;ProductId_1&lt;/key&gt; &lt;dict&gt; &lt;key&gt;en&lt;/key&gt; &lt;string&gt;ProductId_1_EnglistName&lt;/string&gt; &lt;key&gt;es&lt;/key&gt; &lt;string&gt;ProductId_1_SpanishName&lt;/string&gt; &lt;/dict&gt; &lt;key&gt;ProductId_2&lt;/key&gt; &lt;dict&gt; &lt;key&gt;en&lt;/key&gt; &lt;string&gt;ProductId_2_EnglistName&lt;/string&gt; &lt;key&gt;es&lt;/key&gt; &lt;string&gt;ProductId_2_SpanishName&lt;/string&gt; &lt;/dict&gt; &lt;key&gt;ProductId_3&lt;/key&gt; &lt;dict&gt; &lt;key&gt;en&lt;/key&gt; &lt;string&gt;ProductId_3_EnglistName&lt;/string&gt; &lt;key&gt;es&lt;/key&gt; &lt;string&gt;ProductId_3_SpanishName&lt;/string&gt; &lt;/dict&gt; &lt;key&gt;ProductId_4&lt;/key&gt; &lt;dict&gt; &lt;key&gt;en&lt;/key&gt; &lt;string&gt;ProductId_4_EnglistName&lt;/string&gt; &lt;key&gt;es&lt;/key&gt; &lt;string&gt;ProductId_4_SpanishName&lt;/string&gt; &lt;/dict&gt;&lt;/dict&gt;&lt;/plist&gt; 2、Info.plist中有个叫CFBundleDisplayName的key决定APP的名称，创建一个InfoList.string文件并关联所有的target。在InfoList.string文件修改CFBundleDisplayName即可更改APP名称,格式如下所示： CFBundleDisplayName=”xxxxxxxxxx”; 3、在project的“Build Settings”中新建一个“Use_Defined Setting”命名为MY_PRODUCTID，然后为每一个target设置对应的ID。此处分别为四个target命名为：ProductId_1、ProductId_2、ProductId_3、ProductId_4。 4、在工程的“build Phases”界面中新建一个脚本块，脚本内容如下： 12345678910111213141516#PRODUCT_NAEMS_FILE_PATH的路径PRODUCT_NAEMS_FILE_PATH=\"${SRCROOT}/PRODUCT_NAEMS_FILE_PATH\"#获取对应ProductId的plist/usr/libexec/PlistBuddy -c \"print ${MY_PRODUCTID}\" -x \"${PRODUCT_NAEMS_FILE_PATH}\" &gt; \"/var/tmp/${MY_PRODUCTID}.plist\"#获取ProductId.plist对应的本地化名称EN_NAME=$(/usr/libexec/PlistBuddy -c \"print en\" \"/var/tmp/${MY_PRODUCTID}.plist\" )ES_NAME=$(/usr/libexec/PlistBuddy -c \"print es\" \"/var/tmp/${MY_PRODUCTID}.plist\" )#设置InfoPlist.strings对应的本地化文件中的CFBundleDisplayName字段值echo \"CFBundleDisplayName=\\\"${EN_NAME}\\\";\" &gt; \"${SRCROOT}/en.lproj/InfoPlist.strings\"echo \"CFBundleDisplayName=\\\"${ES_NAME}\\\";\" &gt; \"${SRCROOT}/es.lproj/InfoPlist.strings\" 5、编译target，即可在InfoPlist.strings看到对应的本地化名称。","link":"/2016/10/15/%E4%BD%BF%E7%94%A8PlistBuddy%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9APP%E5%90%8D%E7%A7%B0/"},{"title":"关于中国的户籍改革的一点想法","text":"今天这篇文章是看《意见中国–经济学家访谈录》第112期，秦晖教授谈论“户籍制度背后的三大不平等”的观后感。 观点一：户籍制度改革落后于人们的期望 有人说这种户籍制度只有中国和北朝鲜才有，其实把人分成不同等级和身份，享有不同权利的制度很大程度上在前现代很多民族都有。 但是这种身份性等级制度是以国家法律的方式强制推行，并且普及到社会几乎所有人，且有具有很明显的原始记录功能的个例很少。另外一个类似的例子出现在南非种族隔离时代。 这种制度的产生的主要原因是为了实现国家的原始积累。一方面，大量的农民工进城打工带来拥有廉价劳动力，又因为城市户籍人口远小于农村人口因此城市有大量的廉价土地，这是所谓的良好投资环境的基础要素。另一方面，一旦城市不需要这些农民工，可以通过户籍制度驱使其中的大部分人回到农村，避免了一些国家由于自由居住造成的城市贫民窟问题。 户籍制度背后是人权、财产权和公共服务的不平等。普通的外来农民工对户籍改革的期望很低，只有不被赶出贫民窟，不需要任何补偿。很多发展中国家的飞速发展都是建立在低人权的基础之上。 在户籍改革之前，即取消现存户籍类别之前，农村人口是不能随便进城，如果一定进城需要有相关的证明，否则就可能被抓，到后面逐渐改为罚款，再到现在的默认迁移。从这个趋势来看，都是朝着废除户籍和不合理的身份等级的方向发展。只不过离人们的预期还有相当大的距离。而造成户籍制度落后的原因是：政府权力不受限制和政府的责任不可追问。 观点二：户籍制度考验人的忍耐力 户籍制度需要改革其背后的三大平等：一是人权不平等，尤其是居住权；二是财产权不平等，即农民的土地不是他们真正的财产；三是公共服务福利的不平等。 在一个宪政国家，比如欧美国家，一个国家政府能够承担多大的公共服务责任，公民就为让出相应的权利，这是由契约决定的。 然而，现在的中国拥有一个无限权利的政府，但是百姓又不能对其进行问责。这就是造成这三个不平等的根本原因。 对于受户籍制度管制的百姓来说，现在的户籍制度对他们没有什么积极的意义可言，只是一个忍耐力的问题罢了。 观点三：减少大城市的吸引力 很多人担心农村人口大量涌入城市，造成大城市规模的过度膨胀，因此需要“排挤”很大一部分外来人口。然而，从另外一个角度来看，之所以造成这种现象是因为这些大城市享有的特权远远大于其他地方。比如北京，即是集政治、经济、文化三个中心唯一体，享受最后的社会福利和资源。 如果能够通过减少大城市的吸引力，平衡不同城市直接的吸引力和特权，才是解决问题的根本。 小记 早上与好友聊天，我们以前在一个镇上读小学。他对我感叹到现在我们镇上的孩子只能在镇上完成九年义务教育，除非你在县城买房子。记得我们读书那会还可以通过考试进入县城的高中读书。 教育资源的稀缺的，县城的资源绝对不是镇上能比拟的。有稀缺就要区别对待，区别对待就意味着歧视。另外一个原因是，现在城市人口比例已经超过农村人口，不同与我们那个时候农村人口占多数。因此，现在对农村人口进行这样赤裸裸的歧视，其实是对于弱势群体的歧视。","link":"/2019/07/28/%E5%85%B3%E4%BA%8E%E4%B8%AD%E5%9B%BD%E7%9A%84%E6%88%B7%E7%B1%8D%E6%94%B9%E9%9D%A9%E7%9A%84%E4%B8%80%E7%82%B9%E6%83%B3%E6%B3%95/"},{"title":"关于时间管理的一点理解","text":"最近时间管理方面又出现问题，感觉做事的效率明显下降很多。在知乎上看到李开复先生关于时间管理的文章，觉得很有感触，遂做一些笔记以自省。 人的一生两个最大的财富：你的才华和你的时间。才华越来越多，但是时间越来越少，我们的一生可以说是用时间来换取才华。如果一天天过去了，我们的时间少了，而才华没有增加，那就是虚度了时光。所以，我们必须节省时间，有效率的使用时间。 做你真正感兴趣、与自己人生目标一致的事情。生产力和兴趣有着直接的关系。而且这种关系不是单纯的线性关系。如果面对没有兴趣的事情，可能会花掉40%的时间，但是只能产生20%的效果；反之，如果是感兴趣的事情，可能会花100%的时间而得到200%的效果。要在工作上奋发图强，身体健康固然重要，但是真正能改变你的状态的关键是心理而非生理的问题。 知道你的时间是如何花掉的。挑一个星期，每天记录下每30分钟做的事情，然后做一个分类和统计，看看自己什么方面花了太多的时间。凡是想要进步，必须先理解现状。每天结束后，把一整天做的事记录下来，每15分钟一个单位。在一周结束后，分析一下这周你的时间如何可以更有效率的安排？有没有方法可以增加效率？ 使用时间碎片和“死时间”。如果你做上面的时间统计，你一定发现每天有很多时间流失掉了。无论自己忙还是不忙，你要把那些可以利用的时间碎片做的事情先准备好，到你又空闲的时候有计划的拿出来做。 要事为先。每天一大早挑出最重要的三件事，当天一定要能够做完。在工作和生活中每天都有干不完的事，唯一能够做的就是分轻重缓急。要理解急事不等于重要的事情。每天除了办又急又重要的事情外，一定要注意不要成为急事的奴隶。有些事急但是不重要，你要学会放掉，学会说NO！而且，每天这三件事情最好有一件重要但是不急的，这样才能确保你没有成为急事的奴隶。 要有纪律。有的年轻人会说自己“没有时间学习”，其实，换个说法就是“学习没有被排上优先级次序”。时间管理就是要找到自己的优先级，若颠倒顺序，一堆琐事占满了时间，重要的事情就没有空位了。 运用80%-20%原则。人如果利用最高效的时间，只要20%的投入就能产生80%的效率。相对来说，如果使用最低效的时间，80%的时间投入只能产生20%的效率。一天头脑最清楚的时候，应该放在最需要专心的工作上。与朋友、家人在一起的时间相对来说，不需要头脑那么清楚。此外，我们要把握一天做最高效的20%d的时间，专门用于最困难的科目和最需要思考的学习上。 平衡工作和家庭。 划清界限、言出必行：对家人做出承诺后，一定要做到。制度较低的期望值以免造成失望。 忙中偷闲：不要一投入工作就忽视加入，有时10分钟的体贴比10小时的陪伴更受用 闲中偷忙：学会怎么利用碎片时间。例如：家人没起床的时候，你就可以利用这段空闲时间做自己的工作 注重有质量的时间：时间不是每一分钟都是一样的，有时需要全神贯注，有时只需要放空大脑。要记得家人平时为你牺牲很多，周末是你补偿的机会。","link":"/2018/11/30/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/"},{"title":"关于熵的一点理解","text":"最近看了台湾医学教授柯文哲在TED演讲《生死的智慧》，里面提及了熵的概念，这也是我第一次接触熵这个概念。出于兴趣做了一些粗浅的了解，才发现这其实就是宇宙的终极规则。 他对熵和死亡的理解让我印象深刻：“从科学上讲，一切物理化学反应都应该趋向最低能量、最大乱度，也就是熵。人的存在其实是违反这种趋向的。任何组织的团体都是不稳定的，必须通过破坏环境才能使得总的趋向是最低能量、最大乱度的。有一天，我再不能破坏环境，就只好破坏自己，这就叫死亡。 那什么是死亡？追求这个问题的答案就是这个问题的答案。因为人一定会死，所以死亡不是人生的目的，人生就是一个过程。我们在这个过程中不断去锥形一个问题，这就是是人生。置于死地而后生，我们唯有面对死亡，才能看清人生到底是什么？人终究会死，人生只是一个追求人生意义的过程。 人生应该像a的n次方。如果a大于1，a的n次方就无限大；如果a小于1，a的n次方很快就趋近于零。你知道这是什么意思？我对社会的付出多于索取，就代表a大于1，每个人都如此，社会就会越来越好，如果每个人对社会都是索取大于付出，就代表a小于1，社会很快就会崩溃。” 根据热力学第一定律，即能量守恒定律，能量在理论上是可以在不同能量形态之间完成百分百地转换的。然而，现实生活中缺并非如此。比如，蒸汽机在将热能转换为机械能的过程中，总是有一些热能损耗掉。 物理学家将这些在能量转换过程中浪费掉的、无法再利用的能力称为熵。根据热力学第二定律：能量转换总是会产生熵，如果是在封闭的系统中，所有能量最终都会变成熵。能量转换过程中会创造新的状态，熵就是进入这些状态的能量。 状态多就是可能性多，表示比较混乱；状态少，就可能性少，相对来说比较有秩序。能量转换会让系统的混乱度增加，而熵就是系统混乱度。在没有外力注入的情况下，所有封闭系统最终都会趋向于混乱度最大的状态。从宏观层面来说，如果不施加外力影响，事物永远向着更加混乱的状态发展。比如，房间如果没人打扫，会变得越来越乱。 如果从熵的角度来理解人类的发展进程，那么人类社会并非一定会变得更进步、更文明。过去五千年，人类文明的进步只是因为人类学会利用外部力量，包括驯化牲畜、运用火种、利用水力等，使得人类社会向着文明有序的方向发展。 随着工业革命的到来，人类社会进步的步伐加快，使用的能量也呈指数级增长，能量消耗越大，就会产生越多的熵。因此，人类社会始终处于一种矛盾的状态：整个社会变得更加有秩序和严密的同时，无序和混乱也在暗处不断地滋长。 物理学告诉我们，没有办法消除熵和混乱，我们只能不断依靠更大的外力输入，维持现有的秩序，于此同时产生了更大的熵和混乱，如此反复。 迄今为止，人类一直能够找到足够的能量和替代资源来解决熵带来的混乱。假如未来的某一天，人类无法弥补日渐增大的能量缺口，地球的能量不足以解决熵，那是一切就会发生逆转，人类秩序开始崩塌，世界走向混乱。","link":"/2019/08/10/%E5%85%B3%E4%BA%8E%E7%86%B5%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/"},{"title":"关于真相的一点想法","text":"都说现在的人越来越浮躁，愿意思考的人越来越少，导致整个社会都显得浮躁不安。我觉得其实我们一直以来都是这样的，与这个时代的关系不大。之所以当代人会这么认为，是因为大多数人相较于不熟悉的历史更了解自己当下生活的年代。一旦自己所处的社会没有达到自己的预期，往往更愿意相信以前的年代比现在更好，人也更单纯。现在网络上很多人都在追捧民国时代，认为那个年代更加自由与开明。这是因为他们看到的都是民国精英贵族的事迹，认为自己如果生活在那个年代会同样的潇洒与自由，但是如果你深入了解了民国普通老百姓的生活你就不会这么认为了，毕竟你我都是属于普通阶层。 我觉得造成这种现象的原因至少包含了两个原因：一是大多数人缺乏辩证思想，往往会选择自己那些与自己意愿相符的事物来构成对某一件事情的认知，从而容易忽略其他的客观事实；其次是信息的不对称，如果对一件事情没有足够的深入了解是不可能接近真相的，我一直相信真相永远是掌握在少数人手里。 记得心理学上有一个著名的“棉花糖实验”：研究者给幼儿园小朋友一颗棉花糖，并且说你可以现在就吃掉它，但如果你等上15分钟都不吃，就会得到第二颗棉花糖。根据后续跟踪，得到第二颗棉花糖的孩子在未来更加成功。这项研究发表在1990年，当时学者认为，忍耐不吃糖的小孩具备更强的意志力，能为了长远利益放弃暂时的欢愉，这种“延迟满足能力”正是他们成为人生赢家的原因。然而，研究者忽略了一个很重要的因素：小孩子的家庭背景。事情的真相是那些推迟吃掉棉花糖的小孩子几乎都是来自富裕家庭，棉花糖对于他们来说压根没有什么的诱惑力，日常生活中随时可以获得。而那些没有经受住诱惑的小孩子基本上是来自于经济条件较差的家庭，棉花糖对于他们来说是稀缺资源，因此也就很具有诱惑力。 即便网络再发达，信息不对称还是会一直存在的。网络的出现只是帮助我们减缓信息不对称带来认知偏差。更何况人的言论都是带有倾向性的，说话的人的目的就是让听者认同自己的观点。因此，面对网络上海量的信息时，一定要学会思考，并尽量用辩证的态度去质疑和思考问题。 最后想起一句话，历史是任人打扮的姑娘。因此，有些历史的真相也许是我们永远都不会知道的。","link":"/2019/06/26/%E5%85%B3%E4%BA%8E%E7%9C%9F%E7%9B%B8%E7%9A%84%E4%B8%80%E7%82%B9%E6%83%B3%E6%B3%95/"},{"title":"关于英语学习的困惑","text":"最近的英语学习计划执行的很糟糕，脑海里似乎对目前自己使用的学习方法没有足够的信心或者理论支撑。于是今天又看了一遍《把你的英语用起来》书中Dr.Krashen教授提出的最适合中国人学英文的理论，以下是相关笔记： input输入假说。Dr.Krashen认为英文学习的根本在于input输入，缺乏输入就不可能学好任何一门外语。 i+1理论，也叫可理解性输入假说。在一条是在上一条的基础上作进一步补充说明。进行输入练习时，一定要遵循i+1的原则。i代表目前的水平，1代表稍微高一点点的难度。随着自己水平的提高，需要主动的调整输入材料的难度，使之符合i+1。 narrow input假说。输入的材料类型和难度级别在一定时间内相对要狭窄。这样做有极大的好处，只输入自己感兴趣的材料，可以把熟悉的语言知识以不同的模式快速熟悉起来。 情绪机制。学习材料和环境应该是有趣的、轻松自如的，才能实现效果的最大化。 系统化量化。英文学习必须建立一个系统化、量化的流程，规定好整个学习周期的时间，彻底突破。 自勉 笛卡尔曾经有一个比喻：在森林里迷路，如果不停地换方法，最后的结果很可能是走不下去。然而如果你认准一个方向坚定地走下去，最后一定能走出森林，哪怕你绕了一段远路，但胜利最终是属于你的。所以，如果只有方法没有坚持下去的勇气，一切都是空谈。","link":"/2018/07/19/%E5%85%B3%E4%BA%8E%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%B0%E6%83%91/"},{"title":"关于读书无用论的一些想法","text":"关于最近流行的“读书无用论”观点的一些个人看法 通过反复揣摩这句话，觉得大概可以总结为以下五点： 一、在需要的时候，读技能书学习相应的技能即可二、选择什么样的生活，取决于性格，而非读书能够左右三、读书不能弥补先天的差距 我觉得，所谓的读书无用，其中“读书”是指阅读，而非指代“寒窗苦读十余载，金榜题名望今朝”这样功利性的读书，另外“无用”是指阅读不会对一个人的生活带来太大的改变。所以，后面用“阅读”来取代“读书”。 首先，我的观点是：“阅读很有用，不仅完善人格，还能深化思想，甚至可以改变一个人的命运。”书有好书和差书之分，一本好书是作者耗费了大量精力，基于自身知识底蕴，结合个人思想，经过岁月打磨出来的。从某个角度来说，读者只需要几十块钱就能获得作者几十年甚至一生的心血，实在是再廉价不过了。当然，读者能否完全理解作者的思想那就另当别论。阅读一本好书，读过就会留下印象，并且受其影响，只是深浅之分罢了。至于差书，确实没有阅读的必要，不仅无用，浪费时间不说，可能还会造成负面影响。 以下是我的具体想法。 一、在需要的时候，读技能书学习相应的技能即可。 作为一个理科生，读技能类的书差不多是每天的日常。书分很多种，技能书则属于自然科学类。特点就是其内容是依据人类目前已经公认或者证实的客观事实提炼或者推导出来的。同一个主题，不同的作者可能表述方式不一样，但是阐述的观点或者得出结论总是一样的。这样的书，讲究实用性，尊重客观事实，不会随着个人意志改变，主要功能在于传授一种技能，对人的三观（人生观，价值观，世界观）不会有太大的影响。 我想你认可读技能书就是因为它的实用性，能解决实际问题。这也是你认为阅读还算有价值的地方。这一点我同意你的观点。对于不是专业的技能，需要的时候，能解决问题就行。 二、选择什么样的生活，取决于性格，而非读书能够左右 首先，现实生活中，大多数人都没有选择自己想要的生活的资本，而是迫于生计和负担，过着不如意的生活。所以，选择什么样的生活与物质条件也有关系。所以，应该是选择什么样的生活态度更为准确。 都说“内心是怎样的，你看到的世界就是怎样的。”我们看到的或者听到的，都不一定是真实客观的，而是经过大脑过滤，在主观思想的作用下，变成我们愿意相信的“事实”。至少，我们大多数时候都会信以为真。 那么你的思考问题的角度是否足够全面，思维方式是否是辩证的，以及你大脑的知识储量是否足够充实，就确定了过滤后的结果与真相偏离度的大小。能够影响上述三个方面的因素大致两个，一是外界环境影响，包括家庭环境，成长环境，教育环境。在我们还没有独立学习能力之前，我们对世界的认知都是被动地接受外界影响，最终构成了性格的一部分，这属于先天条件差异造成的个体差异，即所谓的天赋。另外一个因素就是主动学习，这也是人类特有的能力。而最有效也是最廉价的途径莫非就是阅读。一个人成年之后并非不可以改变自己的性格，只是会比较难，这一点已经有科学依据。阅读，既然能改变你的主观思想，也就会影响你对于这个世界的认知，对人生的理解，对自身价值的认可。阅读也许不能改变一个人的物质生活，但是改变一个人看待生活的方式。因此，阅读至少可以改善我们的精神生活。 因为性格是先天性的，所以会在最开始影响我们的生活方式。但是阅读可以改变一个人看待生活的态度，进而去追求自己想要的生活。 三、阅读不能弥补先天的差距 你说有人毕生的追求也许就是别人与生俱来的。没错，确实普遍存在这样的情况。就拿阅读这个习惯来说吧，有些“书香门第”出身的孩子，从小就养成了阅读的习惯，而且从小就阅读很多的书籍，从而比一般的同龄人有更渊博的知识和更出色的思维方式。这些天赋在他们看来都是自然而然的事情，先天的优势不言而喻。对比出身贫穷的孩子，很多人都没有阅读的习惯，思考问题也很浅显和片面。而且，一旦成年，即便有条件和时间来重新塑造自己，也需要付出很大代价，需要将推翻原有的思维方式和改正不良的习惯。 从这个角度来说，阅读确实很难弥补先天的差距。人生本就是不公平的，坦然接受这个事实是树立正确地人生观的前提。另外，即便如此也不能因为这个原因就否定阅读的作用。 每个人都有自己的局限性。而人生的意义就在于突破自己的局限性，给自己的生活带来更多可能性，这是每一个精彩人生的主旋律。而阅读无非就是这样的一把利刃。 最后，我上面叽里呱啦说这些并不是想改变你对阅读的看法。而是，我想和你交流一下我对阅读的看法。我从小在农村长大，身边的人几乎没有看书的习惯，除了干活就是看电视聊家常，童年的记忆根本没有书的影子。我们村很多同龄人都是初中毕业就去广东打工。我是整个村子为数不多的大学生。即便如此，我直到上大学都没有真正明白为什么要读书，意义是什么？难道就是为了找一份谋生的工作？阅读的习惯是我大二之后开始培养的，因为我意识到了自己的局限性以及和别人的先天性差距。从那时候起，我就开始培养自己的阅读习惯，一开始确实很难，因为应试教育的原因很排斥读书。后面反反复复折腾，慢慢对阅读有了一点感觉，也尝到了阅读带来的一点甜头。就我个人经历来说，阅读给我生活带来的改变还是挺大的，不管是精神上还是物质上都有改变，让我更好地把握机遇，更好的去对待生活中的困境。","link":"/2017/04/14/%E5%85%B3%E4%BA%8E%E9%98%85%E8%AF%BB%E7%9A%84%E4%B8%80%E7%82%B9%E6%83%B3%E6%B3%95/"},{"title":"初识汇编-知识点摘记","text":"汇编语言的由来 汇编语言是基于机器语言（由0或1组成）而产生的一种助记符 汇编语言介于机器语言和高级语言之间 汇编语言与机器语言是一一对应关系，每条机器指令都有对应的汇编指令 汇编语言通过编译得到机器语言，反之机器语言也可通过反汇编得到汇编语言 高级语言通过编译得到汇编语言，但是汇编语言不能反汇编成高级语言，因为高级语言与汇编之间是多对一的关系。 汇编语言的特点优点 汇编语言可直接访问或控制硬件：存储器、CPU，能最大限度的发挥硬件功能 目标代码少，占位内存少，执行速度快 不同厂商的CPU都有对应的机器指令集和汇编指令集合 大小写不敏感 缺点 不易于编写、维护、调试 寄存器 CPU由寄存器、运算器和控制器组成，其中最主要部件是寄存器，通过改变寄存器的内容来实现对CPU的控制 不同的CPU，寄存器个数和结构存在差异 通用寄存器 arm64寄存器有31个64位的通用寄存器x0-x30，这些寄存器通常用来存放一般数据 w0-w28是32位寄存器，是x0-x28寄存器的低32位，即64位的CPU是兼容32位的 CPU会先将内存中的数据存储到通用寄存器中，然后在对通用寄存器中的数据进行运算，原因在于寄存器的执行速度比内存快 arm64架构下，函数参数都是保存在x0-x7（32位下即w0-w7）这8个寄存器，超过8个参数入栈 函数返回值是存放在x0寄存器中 函数的局部变量都是保存在栈中 PC寄存器：program counter register 指令指针寄存器，指向CPU当前要执行的指令地址 内存中指令和数据无区别，都是二进制数据。CPU将PC寄存器指向的内存单元的内容看作指令 sp与fp寄存器 sp寄存器会在任意时刻保存栈顶地址 fp寄存器即为x29寄存器，有时也用于保存栈低的地址 lr寄存器 lr寄存器就是0x30通用寄存器 0x30寄存器存放函数返回地址，执行ret指令时会读取这个寄存器的值，实现函数返回 汇编指令内存读写指令 arm64架构中取消了32位的LDM、STM、PUSH、POP指令，取而代之的是ldr/ldp、str/stp；ldp/stp是ldr/str的衍生，可同时读写两个寄存器，而ldr/str只能读写一个 str指令：store register指令，将数据从寄存器中读出，写入内存 ldr指令：load register指令，将数据从内存读出，存入寄存器 eg：利用栈将x0和x1寄存器中的值互换 arm64架构中，栈是16字节内存对齐的，即一次读写至少是16（0x10）个字节 1234sub sp,sp,#0x10 ;栈顶指针下移0x10个字节，两个64位的寄存器共16个字节stp x0,x1,[sp,0x10] ;寄存器x0,x1先后的值入栈ldp x1,x0,[sp,0x10] ;出栈，先后写入x0,x1寄存器add sp,sp,0x10 ;栈还原，stp、ldp指令不会改变sp指针位置，且都是由高地址向低地址读写 bl指令 CPU执行的指令是由PC寄存器决定的，因此可以通过修改PC寄存器的内容来控制CPU的指令执行 传送指令用于操作通用寄存器，比如mov指令；此外是转移指令，用于修改PC的值，最简单的就是bl指令 bl指令跳转前将当前指令的下一条指令存放到lr(0x30)寄存器：链接寄存器","link":"/2019/06/27/%E5%88%9D%E8%AF%86%E6%B1%87%E7%BC%96/"},{"title":"几个典型的幸存者偏差现象","text":"幸存者偏差，就是忽略了筛选条件，认为经过筛选的结果是随机产生的。 幸存者偏差的现象的普遍的存在于我们现实生活中的，我们往往容易以自己的生活环境和经历为出发点去看待一件事情，把看到的结果当成是普遍存在的结果。 最近网上有一个《假中国系列》恰好说明了幸存者偏差现象普遍存在且容易被我们忽视。下面一一列举其中的个例。 中国本科生以上的学历占比不到4% 实话说，刚开始看到这个观点，我有点难以接受。因为就我个人而言，朋友圈的好友有将近一半都是本科毕业，也就是50%。然而，我们很容易忽视一个客观事实，就是中国人口基数很大，有近14亿之多。国家统计局数据显示1998-2016年本科以上毕业生总数是4756万，2016年中国人口为13.83亿，算下来本科以上的毕业生占比3.44%。加上去年和今年的最新数据，以及1998年以前少的可怜的数据和中间计算的问题，可以肯定不会超过4%。 中国只有不到0.4%的存款人全部存款超过50万。 关于这一点，我的质疑不是很大，但是也刚开始也会产生质疑。毕竟时常看到知乎和虎扑上面很多人都年薪百万。不过，中国现在的贫富差距之大，以及高房价掏空了大部分中产阶级家庭的储蓄，真正有50以上的存款的人很少。而且，其中这0.4%中很大一部分都是巨富家庭。 中国缴纳个税的人数只有2800万 关于这一点，我还是倾向于相信的。除了公务员和事业单位，不缴纳个税的人往往是特别贫穷（不缴纳社保和五险一金的工作，或者没有到达起征点），或者是特别富裕（不拿工资所以不用缴纳个税）。 全国居民人均可支配收入全年25974元 2017年国家统计局数据，全国居民人均可支配收入25974元。目前中国20%低收入人群每月只有430多块钱，还有20%的中低收入平均不到一千块钱，这两个群体的总人数是5.5亿元。 前不久看一个纪录片，在西北的一个村庄，一对夫妇为了送孩子去县城高考，把家里的羊买了凑了500块钱，作为一个生活在城市的人很难想象或者容易忽略这些贫困家庭的存在。 A股持有100万以上市值的自然人账户占自然人账户比例的2.53% 中登公司2016年6月数据，1/4账户市值不超过1万块，10万以下的占比3/4，100万以上的比例2.53%。 中国目前有约8200万人，占总比人口比例6%领取低保 这个是民政局今年5月公布的数据，此外，16岁以下和60以上不参加劳动的人口占总数人口35%比例（2-17年国家统计局数据） 总体上中国1.8人养1个人。 以上这些触目惊心的现象是客观存在的，但是因为幸存者偏差，造成了我一种对于中国现状过于乐观的假象，进而导致看待一些社会现象存在偏差和误解。","link":"/2017/07/30/%E5%87%A0%E4%B8%AA%E5%85%B8%E5%9E%8B%E7%9A%84%E5%B9%B8%E5%AD%98%E8%80%85%E5%81%8F%E5%B7%AE%E7%8E%B0%E8%B1%A1/"},{"title":"副词能否修辞名词？","text":"之前知乎上看到一提问，大意是：The Lamb Astray中的Astray是形容词还是副词？副词是否能修辞名词？最近恰好在旋元佑先生的《文法俱乐部》一书中找到了合理的解释，借此机会梳理一下这个知识点。 结合上述问题：The Lamb Astray中的Astray是形容词还是副词？副词是否能修辞名词？，可以从两个方面进行解答： The Lamb Astray中的Astray是形容词词性，属于形容词后置的情况 副词可以修辞名词 形容词后置形容词常见的所处位置包括名词片语、表语、主【宾】语补语，此外还有一个位置：名词后面，属于形容词后置的情况。 在以下三种情况，形容词需要后置： 复合名词后面： 类似someone这样的符合名词，因为限定词 some 和 名词 one 组合成一个词，原本名词片语中在限定词和名词之间存放形容的位置被挤压掉了，因此只能把形容词置于名词之后。 比如： someone else //其他人 someone important //某些重要的人 一部分a-开头的形容词： 有一部分a-开头的形容词通常放在补语或者表语的位置，也可以放在名词片语后面。 比如： Jane and her mother alike are teather. //珍和她妈妈一样是老师 Tom alone is coming. //只有汤姆要来 wood adrift //漂流的木头 外来词或者惯用法： 英语中习惯把形容词放在名词前面，但是有些语言中例如法文，形容词是放在名词后面的。因此一些外来语或者惯用语，都要把形容词放在名词后面。 比如： Secretary General //秘书长 Poet Laureate //桂冠诗人 Aisa Minor //小亚细亚 heir apparent //合法继承人 副词修辞名词正如一般文法书上所说，一般情况下形容词修辞名词而副词则用于修辞除了名词以外的其他词类，包括形容词、动词和副词。这种说法基本上成立，但是也有特殊情况。 存在一类表示强调功能的副词，可以修辞名词、动词、形容词和副词，修辞范围很广。也正因为如此，所以这类副词只能放在修饰词前面，确保修辞对象在其后面，以免出现歧义。 这一类副词又可以细分为三种： 强调范围的副词 典型代表：only, merely, also, especially, particularly, even等 以Only举例： I heard about the accident yesterday. //我昨天听说了这件意外 Only I heard about the accident yesterday. //只有我听说了… I only herad about the accident yesterday. //只是听说，并没有看到 I heard about only the accident yesterday. //昨天全在听人在谈论这件意外 I heard about the accident only yesterday. //直到昨天才听说 这几个句子里only分别修饰了代名词I、动词heard、名词the accident和时间副词yesterday，都是当副词使用。 强调语气的副词 这是最典型的副词，同样也可以修饰名词在内的四种主要词类。 举例如下： He is very much his father’s son. //他和他爸爸一个调调 You’re utterly insane! //你是完完全全疯了 I badly need a drink. //我急需来一杯 程度副词 这一类副词和加强语气的副词很像，但是程度副词是用来做有几成的表示，而非加强语气。所以，如果把加强语气的副词，只是语气变弱，意思不会变。但是如果拿掉程度副词，意思就可能发生改变。 举例： The project is almost finished. //项目已经完成的差不多了。 ps:上面的句子如果去掉almost，这句话的意思完全变了 小结旋元佑先生的《文法俱乐部》是一本不可多得的文法书，它区别于传统文法书的教条式+填鸭式的讲解方式，而是追本溯源，从理解本质和语言使用的角度为读者拨开文法的迷雾。","link":"/2016/09/24/%E5%89%AF%E8%AF%8D%E8%83%BD%E5%90%A6%E4%BF%AE%E8%BE%9E%E5%90%8D%E8%AF%8D/"},{"title":"在MacOS系统中使用OpenCV库（sandbox supported）","text":"最近因工作需要研究图片格式转换相关的知识点，其中使用到OpenCV库（一个基于BSD许可（开源）发行的跨平台计算机视觉库，很强大）中的ssim（结构相似性）算法实现来计算两张图片的相似度，用以做图片转换前后的对比。因此需要在Xcode中配置OpenCV库并且能在沙盒下使用，这一过程花费了将近一天的工作时间才配置成功，由于网上大多数资料基本上都是在非沙盒条件下的配置教程，对我没有太多实质性的帮助，这也是写这篇博客的意义所在。 安装OpenCV库在Mac下，安装OpenCV库的方式一般有两种：使用brew命令或者使用make编译源代码。笔者用的是第一种：在终端执行命令：brew insall opencv，即可安装opencv库及其所依赖的动态库。安装成功之后，会在命令行终端的最后一行显示当前OpenCV库的安装路径和版本号，笔者电脑上的安装路径为：/usr/local/Cellar/opencv/3.4.0_1，版本号为3.4.0_1。 在/usr/local/Cellar/opencv/3.4.0_1/include目录下有两个文件夹：opencv和opencv2，里面是OpenCV相关的头文件。/usr/local/Cellar/opencv/3.4.0_1/lib/下有许多前缀为libopencv_的dylib文件，这些都是OpenCV的链接库文件。 在MacOS下配置并使用OpenCV库笔者项目中用到OpenCV库中的libopencv_imgproc.3.4.0.dylib库。因此下文以这个库为例进行展开，其他的库类似操作即可。 使用otool查看库依赖关系首先使用otool命令查看libopencv_imgproc.3.4.0.dylib的依赖关系，必须确保其这些依赖的库在系统中能够找到。 12345678$ otool -L /usr/local/Cellar/opencv/3.4.0_1/lib/libopencv_imgproc.3.4.0.dylib /usr/local/Cellar/opencv/3.4.0_1/lib/libopencv_imgproc.3.4.0.dylib: /usr/local/opt/opencv/lib/libopencv_imgproc.3.4.dylib (compatibility version 3.4.0, current version 3.4.0) @rpath/libopencv_core.3.4.dylib (compatibility version 3.4.0, current version 3.4.0) /usr/local/opt/tbb/lib/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0) /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1) 可以看到libopencv_imgproc.3.4.0.dylib一共依赖了4个库，忽略系统自带的libc++.1.dylib和libSystem.B.dylib，因为这两个库任何Mac电脑上都可以找到。另外两个库分别是@rpath/libopencv_core.3.4.dylib和/usr/local/opt/tbb/lib/libtbb.dylib，分别查看这两个库所依赖的库。 查看libopencv_core.3.4.dylib库的依赖关系。这个库是以libopencv_开头的，与libopencv_imgproc.3.4.0.dylib在同一个目录下。 123456789$ otool -L /usr/local/Cellar/opencv/3.4.0_1/lib/libopencv_core.3.4.0.dylib /usr/local/Cellar/opencv/3.4.0_1/lib/libopencv_core.3.4.0.dylib: /usr/local/opt/opencv/lib/libopencv_core.3.4.dylib (compatibility version 3.4.0, current version 3.4.0) /usr/local/opt/tbb/lib/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0) /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5) /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL (compatibility version 1.0.0, current version 1.0.0) /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate (compatibility version 1.0.0, current version 4.0.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1) /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0) 可以看到，忽略系统自带的库之后其所依赖的库只有一个：/usr/local/opt/tbb/lib/libtbb.dylib。说明libtbb.dylib这个库同时被libopencv_core.3.4.dylib和libopencv_imgproc.3.4.0.dylib引用到。 查看libtbb.dylib库的依赖关系，在目录/usr/local/opt/tbb/lib/目录下可找到这个库。 12345$ otool -L /usr/local/opt/tbb/lib/libtbb.dylib/usr/local/opt/tbb/lib/libtbb.dylib: /usr/local/opt/tbb/lib/libtbb.dylib (compatibility version 0.0.0, current version 0.0.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1) /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0) 可以看到libtbb.dylib库所依赖的都是系统自带的库，所以库依赖关系遍历到此结束。如果当前库还依赖于其他非系统自带库，则需要继续查找下去。 弄清楚库之间的依赖关系之后，接下来将库配置到Xcode中。 无沙盒如果是无沙盒条件下使用OpenCV还是很简单的，因为使用brew命令安装OpenCV过程中所有依赖的库都已帮你配置好了，只需要配置好头文件和库文件即可，不需要关心库之间的依赖关系。 首先配置OpenCV库头文件的查找路径，在Xcode-&gt;Target-&gt;Build Settings中找到“Header Search Paths”选项，新添加一项：/usr/local/Cellar/opencv/3.4.0_1/include。 配置OpenCV库文件的查找路径：在Xcode-&gt;Target-&gt;Build Settings中找到“Lib Search Paths”，新添加一项：/usr/local/Cellar/opencv/3.4.0_1/lib。 接着切换到Xcode-&gt;Target-&gt;Build Phases的tab下，在“Link Binary With Libraries”中，将软件依赖的OpenCV链接库拖拽其中。笔者只用到了libopencv_imgproc.3.4.0.dylib库，因此只需要拖拽这一个库即可。 对于 Lion 操作系统，需要在Xcode-&gt;Target-&gt;Build Settings中，将“C++ Language Dialect”设置成 C++11，将“C++ Standard Library”设置成libstdc++ ，如下图所示。个人感觉是由于Xcode默认设置的GNU++11、libc++与OpenCV库有一些兼容性问题，我在更改该设置前老是出现编译错误。后续版本在Montain Lion系统中解决了这个问题，因此不需要此操作。 注意，如果使用OpenCV库函数的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道该文件混合使用C++语言和Objective-C语言。 以上，无沙盒条件下配置完成。这种配置存在一个严重的缺陷，即如果想要编译后的软件在其他电脑上正常运行则必须确保其他电脑在同样系统目录下安装了OpenCV库，即OpenCV库头文件与链接库文件目录与编译电脑一致，显然这是不能接受的。常规的解决方法是将软件所依赖的库一并打包到软件中，具体配置过程可见于下文的有沙盒配置过程。 有沙盒有沙盒与无沙盒的区别出来签名之外，还有一个重要的区别就是访问权限。无沙盒条件下，软件和Xcode一样拥有当前用户下的最高权限，可以访问当前用户下的任何目录，这也是为什么在Xcode的配置项中可以直接使用当前用户的系统路径的原因。 一旦为添加沙盒条件后，软件所能访问的目录局限于自己的沙盒下，不再有访问当前用户系统目录的权限。此时，只有将软件所依赖的库一并打包到软件中，才能使软件正常运行。具体步骤如下所示。 首先，将软件所依赖的库文件和头文件拷贝到项目工程下的OpenCV目录中，分别存放于lib目录和include目录中： 然后，配置OpenCV库头文件的查找路径，在Xcode-&gt;Target-&gt;Build Settings中找到“Header Search Paths”选项，新添加一项：$(PROJECT_DIR)/OpenCV/include。 接着，配置OpenCV库文件的查找路径：在Xcode-&gt;Target-&gt;Build Settings中找到“Lib Search Paths”，新添加一项：$(PROJECT_DIR)/OpenCV/lib。 其中PROJECT_DIR宏是Xcode自带的，表示xxx.xcodeproj文件所在的目录路径。 然后，切换到Xcode-&gt;Target-&gt;Build Phases的tab下，在“Link Binary With Libraries”中，将软件用到依赖的OpenCV链接库拖拽其中。笔者只用到了libopencv_imgproc.3.4.0.dylib库，因此只需要拖拽这一个库即可。 接着，切换到Xcode-&gt;Target-&gt;Build Phases的tab下，在“Copy Files”中，将libopencv_imgproc.3.4.0.dylib库及其所依赖的库拷贝到软件目录下的Frameworks中。 最后一步，使用install_name_tool命令修改依赖库之间、软件与依赖库的依赖关系。因为使用brew安装，库之间的依赖关系以及库本身的加载路径都是系统路径，在沙盒条件下是无效的。 切换到Xcode-&gt;Target-&gt;Build Phases的tab下，点击左上角的“+”，选择“New Run Script Phase”，新建一个“Run Script”项目，里面是一个shell脚本文件，在Xcode编译运行前执行。 修改依赖关系的顺序很重要，如果依赖关系是：软件-&gt;dylibA-&gt;dylibB-&gt;dylibC，则修改依赖关系的顺序是：dylibC-&gt;dylibB-&gt;dylibA-&gt;软件。 笔者当前软件中的依赖关系是：软件-&gt;libopencv_imgproc.3.4.0.dylib-&gt;libopencv_core.3.4.0.dylib-&gt;libtbb.dylib。 由于libtbb.dylib库所依赖的都是系统自带库，因此不需要修改。 修改命令与参数简单介绍，详细使用方式可通过终端执行命令：man install_name_tool查看：install_name_tool -change oldPath newPath lib(or executable file) 1. 修改libopencv_core.3.4.0.dylib对libtbb.dylib的依赖关系 1install_name_tool -change \"/usr/local/opt/tbb/lib/libtbb.dylib\" \"@loader_path/libtbb.dylib\" \"$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/Frameworks/libopencv_core.3.4.0.dylib\" 其中@loader_path是Xcode自带的宏，表示库加载路径，即libopencv_core.3.4.0.dylib的加载路径，因为libtbb.dylib与libopencv_core.3.4.0.dylib是在同一目录，因此@loader_path/libtbb.dylib表示告诉libopencv_core.3.4.0.dylib在自身所在目录中加载libtbb.dylib。 $TARGET_BUILD_DIR是Xcode自带的宏，表示Xcode编译目录，即编译后的软件存放的目录。PRODUCT_NAME宏也是Xcode自带的，表示软件名称。因为笔者项目中是先拷贝库文件到软件目录中，再修改依赖关系。因此libopencv_core.3.4.0.dylib库所在路径为：$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/Frameworks/libopencv_core.3.4.0.dylib。 以下修改命令类似，不再赘述。 2. 修改libopencv_imgproc.3.4.0.dylib对libtbb.dylib和libopencv_core.3.4.0.dylib的依赖关系 123install_name_tool -change \"/usr/local/opt/tbb/lib/libtbb.dylib\" \"@loader_path/libtbb.dylib\" \"$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/Frameworks/libopencv_imgproc.3.4.0.dylib\"install_name_tool -change \"@rpath/libopencv_core.3.4.dylib\" \"@loader_path/libopencv_core.3.4.0.dylib\" \"$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/Frameworks/libopencv_imgproc.3.4.0.dylib\" 3.软件对libopencv_imgproc.3.4.0.dylib库的依赖关系 1install_name_tool -change \"/usr/local/opt/opencv/lib/libopencv_imgproc.3.4.dylib\" \"@executable_path/../Frameworks/libopencv_imgproc.3.4.0.dylib\" \"$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/MacOS/$PRODUCT_NAME\" 值得注意的是，软件路径必须可执行文件的路径$TARGET_BUILD_DIR/$PRODUCT_NAME.app/Contents/MacOS/$PRODUCT_NAME，而不能是$TARGET_BUILD_DIR/$PRODUCT_NAME.app，因为xxx.app文件本质上的一个目录。 注意：如果在软件编译后运行时crash，并提示类似ImageLoaderMachO的错误则很可能是因为从系统目录下拷贝过来的库文件没有写的权限。因为OpenCV使用的是brew命令安装，brew使用的是root权限，而Xcode只有当前目录下的最高权限，所以必须确保库文件在当前用户下有读写权限，可以使用chmod +rw /path/to/dylib添加读写权限 以上，在有沙盒条件下的配置完成。 小结笔者在刚开始配置过程中，由于自身知识储备不足的原因被折腾得够呛。现在看来整个配置过程其实不难，通过博客记录一遍思路和流程显得更为清晰，理解也更为深刻。","link":"/2017/12/24/%E5%9C%A8MacOS%E7%B3%BB%E7%BB%9F%E4%B8%AD%E4%BD%BF%E7%94%A8OpenCV%E5%BA%93%EF%BC%88sandbox%20supported%EF%BC%89/"},{"title":"在一台电脑搭建多个不同的hexo+github博客","text":"hexo+github是目前比较受欢迎的搭建个人博客的组合，hexo最终的发布依赖于github的。因此解决在同一台电脑搭建多个不同的hexo+github博客的根本在于：解决如何在一台电脑上绑定多个github账号。 本地电脑对github服务器访问是基于ssh的，一般情况下git命令会默认在~/.ssh/config文件中写入对github远程host的映射与配置，类似于： 12345# defaultHost default.github.com //本地使用的host名，可以自定义HostName github.com //远程的host名，必须是目标服务的域名User git //本地ssh登录使用的用户名，登录github服务器只能是gitIdentityFile ~/.ssh/id_rsa //ssh访问使用的秘钥 这个文件所表达的意思是：将本地host名：github.com映射到远程的host名：github.com，并且使用路径：~/.ssh/id_rsa下的秘钥进行ssh访问。 在此之前，我们需要将与私钥/.ssh/id_rsa成对出现的公钥/.ssh/id_rsa.pub配置到自己的github账号中。具体步骤很简单，参考github官方文档：adding-a-new-ssh-key-to-your-github-account。 在配置好github账号中的公钥之后，可通过以下命令检测是否配置成功： 12$ ssh -T git@default.github.com #ssh -T 用户名@本地host名Hi “你绑定的github账号名”! You've successfully authenticated, but GitHub does not provide shell access. 在理解远程登录github背后的原理之后，在一台电脑上绑定多个github账户的思路也变得清晰，即将多个本地host映射到同一个github的host上。 又因为每一个新的映射需要一对新的密钥对（公钥和私钥）用于ssh访问，在配置新的host映射之前需要先创建一对新的密钥。具体步骤如下： 打开终端，并输入如下命令ssh-keygen： 1$ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" 其中-t表示密钥类型为rsa，-b指定密钥的长度，-C为密钥添加的注释，这个注释你可以输入任何内容，很多网站和软件用这个注释作为密钥的名字。 密钥创建完成后会提示你指定密钥存储路径： 1Enter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] 这一步需要注意的是，如果是直接回车则默认存储在/.ssh/id_rsa中。因为我们已经有一对名id_rsa的密钥。我们需要将新创建的秘钥存储在新的文件中以作区分。比如存储在文件/.ssh/test_id_rsa中。 接下来为秘钥提供访问密码，如果直接回车表示空密码。如果输入了密码，这个密码在后续在hexo中绑定github时使用到。 12Enter passphrase (empty for no passphrase): [Type a passphrase]Enter same passphrase again: [Type passphrase again] 创建完密钥之后，在文件~/.ssh/config中加入新的host映射： 1234567891011# defaultHost default.github.com //本地使用的host名，可以自定义HostName github.com //远程的host名，必须是目标服务的域名User git //本地ssh登录使用的用户名，登录github服务器只能是gitIdentityFile ~/.ssh/id_rsa //ssh访问使用的秘钥# testHost test.github.com HostName github.com User git IdentityFile ~/.ssh/test_id_rsa //使用新创建的私钥 将新的映射对应的公钥配置到新的github账号中后，就可以使用以下命令检测是否绑定成功： 12$ ssh -T git@test.github.com #ssh -T 用户名@本地host名Hi test! You've successfully authenticated, but GitHub does not provide shell access. 现在，我们解决了一台电脑绑定多个账户的问题。接下来弄清楚hexo对github依赖的实现方式，便可实现在一台电脑搭建多个hexo博客。 此处省略了hexo博客搭建的过程，网上有很多教程，可自行查阅 在完成hexo的安装和初始化后，通过终端进入在对应的目录下，并执行命令ls -la 1cd ./Hexo所在的根目录 &amp;&amp; ls -la 找到名为.deploy_git的目录，这是一个隐藏目录，用于存储与同步hexo生成好的博客文件到github账号中。本质上这是一个github的本地仓库，类似于用git init命令创建的本地仓库一样。因此对git的配置都需要在这个目录下完成。以下是配置过程： 进入.deploy_git目录中，执行如下命令： 123456\\# 取消全局 git用户名/git注册邮箱git config –global –unset user.namegit config –global –unset user.email\\# 单独设置每个repo git用户名/git注册邮箱git config user.email “xxxx@xx.com”git config user.name “xxxx” 重新关联git项目，比如讲hexo部署到本地host:test对应的github账号上： 12git remote rm origingit remote add origin git@test.github.com:GitHub账户名/hexo对应的仓库名 至此，我们实现了在一台电脑上搭建多个hexo博客的想法。","link":"/2018/02/03/%E5%9C%A8%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E6%90%AD%E5%BB%BA%E4%B8%A4%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%9A%84hexo+github%E5%8D%9A%E5%AE%A2/"},{"title":"失传的艺术-计算机科学","text":"Don’t learn to build doghouses and call yourself an architect. 不要明明是在搭建狗屋，却自称为建筑师。 今天在阮一峰博客看到一篇名为Computer science as a lost art的英文博客，文章不长，内容也朴实随意，正如作者所言属于即兴发挥。文章阐述的观点让我自感惭愧，也让我意识到自己与真正的计算机从业者之间的差距，遂翻译以自勉。 译文如下： 昨晚我的一位老友问我：“计算机科学是否已经成为了一门失传的艺术？”今早，我给出了即兴想到的答案： 嗯，这就是我的观点。我拥有计算机本硕学位即六年计算机科学求学历程，与此同时有着30年工作经验。换言之，我有些过时了，且与当下有点格格不入。 即使我不大愿意相信，但是确实有些事情实实在在的发生了。首先，如今电脑已经相当普及，你还能找到一个80岁以下却没有电脑或手机的人吗？其次，万维网（作为互联网最初的模样诞生于1989年）在1995左右便已经开始遍布于公众。随着电脑的使用领域变得越来越广，它也变得越来越重要。第三，那些我们用于创建软件应用的工具在功能上变得更复杂从而更便于使用，就像驾驶汽车这件事来说现在相对于1905年来说要简单的多。 我想要表达的是现在的电脑使用者比过去任何时候都要多。现在也有很多所谓的程序员没有上过一堂编程课。不过任何事情都要利弊。 这意味着一个人只需要很少的计算机知识便可以完成一个小项目，但也意味着这样的人很可能不会为了完成大项目而去学习更多的知识。 老实说，私底下我对于现在存在这样一大群不思进取的伪程序员这个事实感到很沮丧，我也很少对他人提及我的感受。在我看来，他们决定学习他们领域5%的知识是为了完成某个任务，或找点乐子，或谋生而已。 这些人使用编程工具创建一些日常所用的应用程序，殊不知编程工具本身也是软件。但是编程软件远非一般水平的人所能创建的。即便这些人每天都在使用编程语言，编辑器，编译器和操作系统，但是他们对于如何编写用于编程的软件，以及这些软件的运行原理没有丝毫的头绪。 20年后，一个赛车手可以把小孩放他的腿上，然后小孩会说：“哈，我也能驾驶这辆车，任何人都可以驾驶它。你只需要按下绿色按钮然后说‘送我去沃尔玛’即可。”这与我对如今学习编程这件事的看法有些类似。 回到计算机科学的话题。我的朋友有一个七岁的儿子自学了一款很棒的编程工具，然后编写了一款iPhone游戏。尽管，那是一款很简单的游戏。但是他完成了这件事情放在三十年多前差不多需要拥有计算机博士学位的人才能完成，而且还不是移动设备上的软件。 有时候我与一些人交流计算机知识时，他们的抱怨和疑惑说明他们已经到了自己的知识边界。有时候这让我很震惊，我认为：这些知识点应该是在你第一个学期的第一堂计算机科学课程里面就能学到的。随后我意识到，这些并没有真正意义上学习过计算机科学的课程。 当然，在我之前的上一代计算机前辈们也是以同样的眼光看待我们这一代人的。在1940年代，你几乎必须有一个电子工程学位才有可能接触到计算机。在上个世纪70年代末到80年代初，你只需主修一门计算机科学或工程就能接触到计算机，在90年代以后，你仅仅需要一张信用卡，或者你父母有一张信用卡。 我对于硬件很痴迷，顺便说一下，我离不开键盘。每当我拆开一台电脑试图捣腾点某个零件时，我总会把其他零件搞砸。严格意义上说我是一个软件男。因此，我曾经被他人嘲笑过，甚至一些年长的人也会因为我不会使用电焊笔而嘲笑我。 任何事情都基于你真正想做什么。如何你只是想开一家网店、制作购物车、网页表格、漂亮的图片以及社交媒体软件，那么你根本不需要计算机科学学位，甚至是与之相关联的学位。 如果你想创造一些尚未存在且很有趣的东西，或是你想在这个产业里面做出一点成绩，或是你仅仅想稍许改变一点这个世界，那么你必须有一个计算机学位。如果你想编写那些给低层次的程序员使用的软件和库，你也必须有一个计算机学位。 或者你从另外一个角度看待：如果你想搭建一个狗屋，只需要知道使用锤子和钉子，然后动手做即可。如果你想成为一名设计和建造摩天大厦的建筑师时，你首先需要一个建筑业的学位。再次恳请大家要有自知之明，不要明明是在搭建狗屋，却自称为建筑师。","link":"/2018/11/03/%E5%A4%B1%E4%BC%A0%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"},{"title":"Where do we come from?","text":"你的身体里的每一个原子都来自一颗爆炸了的恒星，形成你的左手的原子可能和形成你右手的原子来自不同的恒星。这是我所知的关于物理的最有诗意的事情：你们都是星尘。 —劳伦斯·克劳斯 《一颗原子的时空之旅》 上面这段文字是今天一个朋友给我的，很浪漫也很有诗意。同时，这段文字也引发了我的思考：我们从何而来？ 这个问题之深奥远非我目前的知识水平能够回答，BBC纪录片《宇宙的奇迹》给了我们一个答案： 每个人，你所热爱的一切，你所憎恨的一切，你所拥有的最宝贵的东西，在宇宙生命最为伊始的几分钟内由自然的力量合成，在恒星的中心转化或者在它们燃烧的消亡中诞生。而当你去世的时候，这些碎片将回到宇宙中，进入无限的死亡又重生的轮回之中。 太阳的命运也是所有恒星的命运，终有一天，它们都会消亡。宇宙将会陷入永无止境的黑暗之中，这便是时间箭头最深远的影响。 我们现在看到的夜空中某个光点，可能是在几百万年前踏上了旅程。那时候地球上还没有人类，远古的祖先能人正在非洲广袤的平原上漫步。就是在这些光线穿行于无垠宇宙的同时，人类不断地进化，一代又一代的生老病死，周而复始。旅途开始的几百万年后，这些远道而来的信使，穿越漫长的时间映入我们现在的眼帘。 我们与那些遥远星系息息相关，无论它们是如何与我们天各一方，那些经过数十亿年旅行到达地球的光线终究会把我们联系在一起。在我们注意太空的时候，我们也是在寻找自己的起源。我们的故事就是宇宙的故事，因为我们是恒星真正的孩子，注入进我们身体的每一个原子和分子就是宇宙从大爆炸到现在全部的历史。 “生星时代”-恒星漫天的时代，我们的太阳只是银河系两千亿颗恒星的其中一颗。我们的星系也只是可观察的宇宙范围内的一百亿个星系中的一个，数不尽的星球上有数不尽的岛屿。 从宇宙起源到最后一个黑洞消失的过程中，生命正如我们所知只有百分之千亿分千亿分之千分之一的可能性。所以，对于我来说，宇宙中最惊人的奇迹不是恒星，不是行星，也不是星系，甚至根本就不是一个物质，而是时间里的一瞬间，那个瞬间就是现在。 当我们仰望天空，望向遥远的恒星和星系时，我们其实是在仰望过去。因为光从那些遥远天体到达地球需要时间，而光从那个红点传播到我们这里差不多经历了整个宇宙史。我们看到的是一百三十亿年前发生的事件，我们看到的是宇宙初期的一颗恒星爆炸灭亡的景象。","link":"/2017/06/29/%E6%88%91%E4%BB%AC%E4%BB%8E%E4%BD%95%E8%80%8C%E6%9D%A5/"},{"title":"揭开ARC的神秘面纱系列-第1话","text":"这个系列一共有四篇博客，是Matt Galloway大神关于ARC的内部实现的一些探索，看完之后觉得收获不少。因此尝试着翻译出来和大家分享，一定会翻译不当之处，希望大家及时指正。原文地址 以下是正文： 在Twitter上和@jacobrelkin进行了一次交流之后，我决定写几篇博客关于ARC在神秘的面纱之下是如何运转和如何窥视其内部机制的方法。这篇博客我将解释ARC如何处理retain、release和autorelease这三个关键字对应的内部实现。 我们通过定义一个类作为开始，如下： 1234567891011121314151617181920212223242526272829#import &lt;Foundation/Foundation.h&gt;@interface ClassA : NSObject@property (nonatomic, retain) NSNumber *foo;@end@implementation ClassA@synthesize foo;- (void)changeFooDirect:(NSNumber*)inFoo { foo = inFoo;}- (void)changeFooSetter:(NSNumber*)inFoo { self.foo = inFoo;}- (NSNumber*)newNumber { return [[NSNumber alloc] initWithInt:10];}- (NSNumber*)getNumber { return [[NSNumber alloc] initWithInt:10];}@end 123456789101112131415161718192021222324252627282930313233343536373839上述代码覆盖了ARC的几个重要的方面，包括直接访问成员变量与通过setter访问这两种方式的比较，以及当不同的函数名的函数返回某个对象时ARC将会如何添加autorelease属性。让我们首先关注直接访问成员变量与通过setter访问这两种方式的比较。如果我们编译上述代码并查看其汇编代码将会洞悉其中的奥秘。我决定使用ARMv7指令集而非x86指令集是因为前者更容易理解（纯属个人见解！）。我们可以使用编译参数-fobjc-arc和-fno-objc-arc来开启或关闭ARC。在这些实例中我使用的是优化等级是第3级，也就意味着编译器将会移除多余的代码，这些代码我们既不感兴趣同时还会阻碍我们理解核心代码（读者做一个练习，在不设置优化等级的前提下编译上述代码，看看结果是怎样的）。在非ARC的模式下采用如下指令进行编译上述代码： $ /Developer/Platforms/iPhoneOS.platform/Developer/usr/bin/clang -isysroot /Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS5.0.sdk -arch armv7 -fno-objc-arc -O3 -S -o - test-arc.m然后，查看changeFooDirect:和changeFooDirect:这个两个函数的汇编码：``` arm .align 2 .code 16 .thumb_func \"-[ClassA changeFooDirect:]\" \"-[ClassA changeFooDirect:]\": movw r1, :lower16:(_OBJC_IVAR_$_ClassA.foo-(LPC0_0+4)) movt r1, :upper16:(_OBJC_IVAR_$_ClassA.foo-(LPC0_0+4)) LPC0_0: add r1, pc ldr r1, [r1] str r2, [r0, r1] bx lr .align 2 .code 16 .thumb_func \"-[ClassA changeFooSetter:]\" \"-[ClassA changeFooSetter:]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) LPC1_0: add r1, pc ldr r1, [r1] blx _objc_msgSend pop {r7, pc} 继续向前，看看在ARC模式下又是怎样的一副景象。采用如下所示的指令进行编译： $ /Developer/Platforms/iPhoneOS.platform/Developer/usr/bin/clang -isysroot /Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS5.0.sdk -arch armv7 -fobjc-arc -O3 -S -o - test-arc.m 同样，此刻我们只关注changeFooDirect:和changeFooDirect:这两个函数： 12345678910111213141516171819202122232425262728293031.align 2 .code 16 .thumb_func \"-[ClassA changeFooDirect:]\"\"-[ClassA changeFooDirect:]\": push {r7, lr} movw r1, :lower16:(_OBJC_IVAR_$_ClassA.foo-(LPC0_0+4)) mov r7, sp movt r1, :upper16:(_OBJC_IVAR_$_ClassA.foo-(LPC0_0+4))LPC0_0: add r1, pc ldr r1, [r1] add r0, r1 mov r1, r2 blx _objc_storeStrong pop {r7, pc} .align 2 .code 16 .thumb_func \"-[ClassA changeFooSetter:]\"\"-[ClassA changeFooSetter:]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4))LPC1_0: add r1, pc ldr r1, [r1] blx _objc_msgSend pop {r7, pc} 我们可以一目了然地看到两段汇编代码的不同之处。函数changeFooSetter:完全一样，而函数changeFooDirect:已经发生了变化：调用了一次objc_storeStrong函数。有意思的地方就是这里。如果我们查阅LLVM文档中objc_storeStrong函数的说明将会看到objc_storeStrong函数里完成一个典型的变量交换，释放旧变量然后持有新变量。然而在非ARC模式下，这个变量仅仅是赋值，并没有任何释放或者持有操作。这就是我们期望的结果，感谢ARC！ 接下来是更有趣的地方，newNumber函数对比getNumber函数。这两个函数在非ARC模式下都返回一个引用计数为1的NSNumber对象，也就是说函数调用者持有返回对象。根据Cocoa的命名约定，这个结果似乎符合函数newNumber而不符合函数getNumber。我们期望看到函数getNumber中有调用autorelease。因此，让我们查看非ARC模式下的代码是怎样的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253.align 2 .code 16 .thumb_func \"-[ClassA newNumber]\"\"-[ClassA newNumber]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC2_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC2_0+4)) movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC2_1+4)) movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC2_1+4))LPC2_0: add r1, pcLPC2_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC2_2+4)) movs r2, #10 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC2_2+4))LPC2_2: add r1, pc ldr r1, [r1] blx _objc_msgSend pop {r7, pc} .align 2 .code 16 .thumb_func \"-[ClassA getNumber]\"\"-[ClassA getNumber]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC3_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC3_0+4)) movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC3_1+4)) movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC3_1+4))LPC3_0: add r1, pcLPC3_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC3_2+4)) movs r2, #10 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC3_2+4))LPC3_2: add r1, pc ldr r1, [r1] blx _objc_msgSend pop {r7, pc} 然后是ARC模式下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354.align 2 .code 16 .thumb_func \"-[ClassA newNumber]\"\"-[ClassA newNumber]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC2_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC2_0+4)) movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC2_1+4)) movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC2_1+4))LPC2_0: add r1, pcLPC2_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC2_2+4)) movs r2, #10 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC2_2+4))LPC2_2: add r1, pc ldr r1, [r1] blx _objc_msgSend pop {r7, pc} .align 2 .code 16 .thumb_func \"-[ClassA getNumber]\"\"-[ClassA getNumber]\": push {r7, lr} movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC3_0+4)) mov r7, sp movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC3_0+4)) movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC3_1+4)) movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC3_1+4))LPC3_0: add r1, pcLPC3_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC3_2+4)) movs r2, #10 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_4-(LPC3_2+4))LPC3_2: add r1, pc ldr r1, [r1] blx _objc_msgSend blx _objc_autorelease pop {r7, pc} 查看上述两段代码唯一不同点：ARC模式下getNumber:函数中调用了objc_autorelease。这也是我们所期望的，因为ARC模式能自动觉察到函数名是以关键字new还是关键字copy开头的，并为不属于这两种的情况的Get类函数的返回对象自动添加一次autorelease调用。棒极了！ 这里仅仅只展示了关于ARC在两种模式下如何工作的一小部分奥秘，与此同时，我希望这能激励读者能自己去探索ARC的内部实现而不是理所当然的接受现有的知识点。作为一个程序员，理解自己使用的工具的内部实现是很重要的。","link":"/2015/02/05/%E6%8F%AD%E5%BC%80ARC%E7%9A%84%E7%A5%9E%E7%A7%98%E9%9D%A2%E7%BA%B1%E7%B3%BB%E5%88%97-%E7%AC%AC1%E8%AF%9D/"},{"title":"揭开ARC的神秘面纱系列-第2话","text":"原文地址 以下是正文： 写完第一篇关于揭开ARC神秘面纱的博客，我想和大家分享另外一些有趣的片段。这一次我好奇当你通过函数返回一个存在数组中的对象时会发生什么。非ARC模式，你可能会对这个对象retain一次再返回一个自动释放的对象。ARC模式下，我们虽然可以免去这些内存管理的操作，但还是不放心，觉得别扭。因此，我决定检测一下ARC是否做到位了。 考虑一下这个类： 123456789101112131415161718192021#import &lt;Foundation/Foundation.h&gt;@interface ClassA : NSObject@property (nonatomic, strong) NSMutableArray *array;@end@implementation ClassA@synthesize array;- (id)popObject { id lastObject = [array lastObject]; if (lastObject) { [array removeLastObject]; } return lastObject;}@end 在非ARC模式下，调用函数removeLastObject将会释放数组对对象的持有，如果这是对象的最后一个引用则对象的内存将会被释放，意味着返回的对象是一个已经被回收的对象。所以，我们应当retain一次lastObject并在返回前添加autorelease属性（加入自动释放池）。 尽管我完全明白ARC应该会完成这些工作，但是我还是担忧没有自己添加这些操作。我天真地以为ARC会一行行地解析函数中的代码。如果是这样，我觉得ARC也许没必要在我们引用lastObject对象的时候为它添加一次引用计数，此时ARC并不知道lastObject需要进行retain，所以ARC没必要非得做这些操作。 这就是我错误所在。显然，ARC在我们引用lastObject对象的时候为其添加一次引用计数，并在对象立刻作用域的时候进行了一次release操作，在我们这个例子中，由于我们是通过函数返回这个对象且函数名不是已关键字new或者copy开头，因此需要将对象加入自动释放池。 让我们看看上述代码编译之后的样子： 12345678910111213141516171819202122232425262728293031323334353637.thumb_func \"-[ClassA popObject]\"\"-[ClassA popObject]\": push {r4, r5, r6, r7, lr} movw r6, :lower16:(_OBJC_IVAR_$_ClassA.array-(LPC0_0+4)) mov r4, r0 movt r6, :upper16:(_OBJC_IVAR_$_ClassA.array-(LPC0_0+4)) movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_1+4))LPC0_0: add r6, pc movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_1+4))LPC0_1: add r1, pc add r7, sp, #12 ldr r0, [r6] ldr r1, [r1] ldr r0, [r4, r0] blx _objc_msgSend @ InlineAsm Start mov r7, r7 @ marker for objc_retainAutoreleaseReturnValue @ InlineAsm End blx _objc_retainAutoreleasedReturnValue mov r5, r0 cbz r5, LBB0_2 movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC0_2+4)) movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_2-(LPC0_2+4)) ldr r0, [r6]LPC0_2: add r1, pc ldr r1, [r1] ldr r0, [r4, r0] blx _objc_msgSendLBB0_2: mov r0, r5 blx _objc_autoreleaseReturnValue pop {r4, r5, r6, r7, pc} 好吧，事实如此。ARC已经为我们考虑周全了。ARC在代码中插入了objc_retainAutoreleaseReturnValue调用，这意味着ARC已经觉察到需要给一个已经加入自动释放池的返回值增加引用计数，这个操作属于ARC的一种优化处理，它仅仅是把对象从自动释放池中移除而并非真的添加一次引用计数。接下来在函数结尾处，ARC调用了objc_autoreleaseReturnValue，这个函数将即将返回的对象加入自动释放池。 这仅仅是关于揭开ARC神秘面纱系列的另外一个例子。随着使用ARC的次数增多，我愈发意识它的实用性。ARC减少代码中内存管理相关的错误，并将上述的代码片段进行最佳优化处理。","link":"/2015/02/20/%E6%8F%AD%E5%BC%80ARC%E7%9A%84%E7%A5%9E%E7%A7%98%E9%9D%A2%E7%BA%B1%E7%B3%BB%E5%88%97-%E7%AC%AC2%E8%AF%9D/"},{"title":"揭开ARC的神秘面纱系列-第3话","text":"原文地址 “揭开ARC的神秘面纱系列”的这篇续集全都是关于@autoreleasepool这一新指令的。LLVM提及到autorelease pools（自动释放池）的语义已经在LLVM3.0版本中发生变化，尤其是，我觉得探究ARC模式更新之后是如何实现的会很有意思。 因此，思考一下下面的函数： 12345678void foo() { @autoreleasepool { NSNumber *number = [NSNumber numberWithInt:0]; NSLog(@\"number = %p\", number); }} 显然，这完全是不和谐的代码段，但是它能让我看到发生什么。在非ARC模式下，我们可能会假设：number将会在numberWithInt:函数中被分配内存，并返回的是一个自动释放的对象。因此当自动释放池随后被销毁时，number对象将会被释放。所以让我们看看是否如上所述（一如往常，使用的是ARMv7指令集）： 1234567891011121314151617181920212223242526272829303132.globl _foo .align 2 .code 16 .thumb_func _foo_foo: push {r4, r7, lr} add r7, sp, #4 blx _objc_autoreleasePoolPush movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_0+4)) movs r2, #0 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_0+4)) mov r4, r0 movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC0_1+4))LPC0_0: add r1, pc movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC0_1+4))LPC0_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend mov r1, r0 movw r0, :lower16:(L__unnamed_cfstring_-(LPC0_2+4)) movt r0, :upper16:(L__unnamed_cfstring_-(LPC0_2+4))LPC0_2: add r0, pc blx _NSLog mov r0, r4 blx _objc_autoreleasePoolPop pop {r4, r7, pc} 不错，答案是肯定的。正是这样的。我们可以看到函数先将自动释放池入栈，然后调用numberWithInt:函数，然后将自动释放池出栈。正如我们所预料的。现在我们看看完全相同的代码在ARC模式编译出来是怎么样的： 123456789101112131415161718192021222324252627282930313233343536373839.globl _foo .align 2 .code 16 .thumb_func _foo_foo: push {r4, r5, r7, lr} add r7, sp, #8 blx _objc_autoreleasePoolPush movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_0+4)) movs r2, #0 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC0_0+4)) mov r4, r0 movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC0_1+4))LPC0_0: add r1, pc movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC0_1+4))LPC0_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend @ InlineAsm Start mov r7, r7 @ marker for objc_retainAutoreleaseReturnValue @ InlineAsm End blx _objc_retainAutoreleasedReturnValue mov r5, r0 movw r0, :lower16:(L__unnamed_cfstring_-(LPC0_2+4)) movt r0, :upper16:(L__unnamed_cfstring_-(LPC0_2+4)) mov r1, r5LPC0_2: add r0, pc blx _NSLog mov r0, r5 blx _objc_release mov r0, r4 blx _objc_autoreleasePoolPop pop {r4, r5, r7, pc} 留意上述代码中objc_retainAutoreleasedReturnValue函数和objc_release的调用。ARC已经为我们做了决定，完全不必担心自动释放池，因为ARC可以直接不然自动释放池生效，通过调用objc_retainAutoreleasedReturnValue函数对number对象进行retain一次，然后在后面在调用objc_release函数释放它。这意味着自动释放池的逻辑不一定执行，让人满意的结果。 注意到自动释放池一直需要入栈和出栈，是因为ARC无法知晓numberWithInt函数和NSLog函数中会发生什么，不知道在函数中是否有对象会被加入释放池。如果说ARC知道这两个函数不会自动释放任何东西则实际上可以移除自动释放池的入栈和出栈操作。也许这种逻辑在ARC未来的版本中出现，尽管我不是很确定那时候ARC的语义会如何实现。 现在让我思考另外一个例子，在这个例子中我们想要在自动释放池的作用域之外使用number对象。这应该告诉我们为什么ARC是一个神奇的工具。思考下面的代码： 12345678910void bar() { NSNumber *number; @autoreleasepool { number = [NSNumber numberWithInt:0]; NSLog(@\"number = %p\", number); } NSLog(@\"number = %p\", number);} 你可能会认为上述这段看似很和谐的代码会出问题。问题在于number对象将在自动释放池中创建，在自动释放池初衷时被释放，但是却在释放之后继续使用。噢！让我们通过在非ARC模式下编译上述代码来看看我们的猜想是否是正确的： 12345678910111213141516171819202122232425262728293031323334353637.globl _bar .align 2 .code 16 .thumb_func _bar_bar: push {r4, r5, r6, r7, lr} add r7, sp, #12 blx _objc_autoreleasePoolPush movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) movs r2, #0 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) mov r4, r0 movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC1_1+4))LPC1_0: add r1, pc movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC1_1+4))LPC1_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend movw r6, :lower16:(L__unnamed_cfstring_-(LPC1_2+4)) movt r6, :upper16:(L__unnamed_cfstring_-(LPC1_2+4))LPC1_2: add r6, pc mov r5, r0 mov r1, r5 mov r0, r6 blx _NSLog mov r0, r4 blx _objc_autoreleasePoolPop mov r0, r6 mov r1, r5 blx _NSLog pop {r4, r5, r6, r7, pc} 很明显，正如我们所期望的那样没有调用retain,release或者autorelease，因为我们没有显式调用这些函数以及使用ARC。编译的结果也正如我们之前推理的那样。接下来让我们在ARC的帮助下会是什么样： 12345678910111213141516171819202122232425262728293031323334353637383940414243.globl _bar .align 2 .code 16 .thumb_func _bar_bar: push {r4, r5, r6, r7, lr} add r7, sp, #12 blx _objc_autoreleasePoolPush movw r1, :lower16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) movs r2, #0 movt r1, :upper16:(L_OBJC_SELECTOR_REFERENCES_-(LPC1_0+4)) mov r4, r0 movw r0, :lower16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC1_1+4))LPC1_0: add r1, pc movt r0, :upper16:(L_OBJC_CLASSLIST_REFERENCES_$_-(LPC1_1+4))LPC1_1: add r0, pc ldr r1, [r1] ldr r0, [r0] blx _objc_msgSend @ InlineAsm Start mov r7, r7 @ marker for objc_retainAutoreleaseReturnValue @ InlineAsm End blx _objc_retainAutoreleasedReturnValue movw r6, :lower16:(L__unnamed_cfstring_-(LPC1_2+4)) movt r6, :upper16:(L__unnamed_cfstring_-(LPC1_2+4))LPC1_2: add r6, pc mov r5, r0 mov r1, r5 mov r0, r6 blx _NSLog mov r0, r4 blx _objc_autoreleasePoolPop mov r0, r6 mov r1, r5 blx _NSLog mov r0, r5 blx _objc_release pop {r4, r5, r6, r7, pc} 此处应该有掌声！ARC识别出我们在自动释放池作用域之外使用了number对象，因此它如上一段代码一样对numberWithInt:函数的返回值进行了retain，但是这一次它将release操作放在了bar函数末尾而不是自动释放池出栈的时候。这一举措避免在一些代码中出现崩溃，我们可能会认为这些代码是正确的，但实际上却潜在着内存管理的bug。","link":"/2015/02/25/%E6%8F%AD%E5%BC%80ARC%E7%9A%84%E7%A5%9E%E7%A7%98%E9%9D%A2%E7%BA%B1%E7%B3%BB%E5%88%97-%E7%AC%AC3%E8%AF%9D/"},{"title":"整数求均值的几种方法","text":"问题描述： 求均值最常用的方法是将两数相加再除以2，但是当两个数都大于其最大值的一半时， 相加的结果会发生内存移除。比如： 12345unsigned average(unsigned a, unsigned b){ return (a + b) / 2;}average(0x8000'0000 + 0x8000'0000) = 0; // 内存溢出 解决方法： 使用减法代替加法 12345unsigned average(unsigned a, unsigned b){ // assume a &gt; b return b + (a - b) / 2;} 分别求两个数的均值再相加，最后修正地位，以确保两个数都是奇数时结果仍然正确： 1234unsigned average(unsigned a, unsigned b){ return (a / 2) + (b / 2) + (a &amp; b &amp; 1);} SWAR (SMID with a register) 123456unsigned average(unsigned a, unsigned b) { // 交集 + 合集 / 2 // &amp;运算不会发生进位 return (a &amp; b) + (a ^ b) / 2;}","link":"/2019/04/02/%E6%95%B4%E6%95%B0%E6%B1%82%E5%9D%87%E5%80%BC%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"title":"时序模型初探之-：概述","text":"时间序列是一组数据序列，且序列中的单一变量是按时间的先后次序产生的。 简述时间序列根据研究依据可分为不同的类型，主要包括以下几种： 按研究的对象的个数，可分为一元时间序列、二元时间序列和多元时间序列 按时间采样的连续性，可分为连续时间序列和离散时间序列 按时间序列的分布规律，可分为高斯型时间序列和非高斯型时间序列 按序列的统计特性，可分为平稳时间序列和非平稳时间序列 时序平稳性所谓时间序列的平稳性，形象地描述就是样本时间序列所得到的拟合曲线在未来的一段时间仍能顺着现有的形态”惯性“地延续下去。 反之，如果样本时间序列所得到的拟合曲线不具有”惯性“延续的特点，那这类时间序列是非平稳的。 平稳时间序列 平稳时间序列又有广义和狭义之分： 狭义平稳时间序列 狭义平稳又称为严平稳，是一种条件比较苛刻的平稳性定义，即当序列所有的统计性质都不会随着时间的推移而发生变化。 Jonathan.D.Cryer和Kung-Sik Chan的Time Series Analysis with Applications in R 中关于严平稳的定义： 如果对一切时间间隔k和时间点，都有和的联合分布相同，则称时间序列是严平稳过程。 广义平稳时间序列 广义平稳又称为弱平稳，其定义为： 如果时间序列的一阶和二阶矩存在，且对任意时刻t都满足以下三个条件： 均值恒为常数，与时间无关 方差恒为常数，与时间无关 协议差为时间间隔的函数，与时间无关 比如，弱白噪音就是一种典型的弱平稳时间序列。 b. 非平稳时间序列 非平稳时间序列的均值、方差和协防差都是一个与时间相关的函数，即非常数。 时间序列建模时间序列一个重要的应用领域就是基于观测样本预测未来趋势，但前提是所研究的时间序列必须是一个广义平稳时间序列。 根据时间序列的根据变化趋势可分为多种形式，且一个时间序列往往是多种变化形式的叠加或耦合，主要的变化形式有以下几种： 长期趋势变动：指时间序列朝着一定的方向持续上升或下降，亦或有保持在某一个水平的倾向，通常用表示。 按季节变动：指时间序列由季节因素出现类似涨落起伏的波动，通常用表示。 周期性变动：指时间序列的变动存在周期性，通常用表示。 不规则变动：指时间序列的变动无规则可言，通常分为突发变动和随机变动，通常用表示。 时间序列建模的前提假设是：时间序列是一个确定性过程产生的，是一个时间的函数，即时间序列中的每一个观测值都是由同一个确定性过程和随机因素决定的。常见的确定性时间序列模型有以下几种类型： 加法模型： 乘法模型： 混合模型： 和 其中，表示观测目标的观测记录， 。 分析方法 平稳时间序列有多种分析方法，主要包括以下几种： 移动平均法 时序模型初探之二：移动平均法 指数平滑法 时序模型初探之三：指数平滑法 差分指数平滑法 TODO: 时序模型初探之四：差分指数平滑法 自适应滤波法 TODO：时序模型初探之三：自适应滤波法 趋势外推预测法 TODO：时序模型初探之三：趋势外推预测法 参考资料平稳过程 - 维基百科，自由的百科全书 如何理解时间序列的平稳性？ 时间序列笔记-白噪声 如何判断时间序列是否是白噪声？ LaTeX转义特殊符号 LaTex常用公式语法备忘录","link":"/2020/08/05/%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2%E4%B9%8B%E4%B8%80%EF%BC%9A%E6%A6%82%E8%BF%B0/"},{"title":"时序模型初探之三：指数平均法","text":"简述一般而言，历史数据对未来值的影响是随着时间地推移而递减的。所以，不同于移动平均法只关注时间序列中近期数据对预测值的影响，指数平滑法对时间序列中所有的观测值依时间顺序进行加权平均作为预测值的作法，显得更切合实际。 三种常用预测模型指数平滑法（Exponential Smoothing，ES），本质上是一种加权平均法，由于其加权系数符合指数规律，又具有平滑数据的功能，故称之为指数平滑法。 指数平滑法根据平滑次数的不同，可分为三种常用的预测模型，分别是： 一次指数平滑法 预测模型 设时间序列为，加权系数为，，一次指数平滑公式为： 为进一步理解指数平滑的实质，将上式依次展开，可得： 由上式可知，是对全部历史数据的加权平均值，加权系数分别是，其预测模型为： 加权系数的选择 在指数平滑预测模型中，加权系数的选择决定了最终的预测结果。的值决定了在做新预测时新数据和原预测值所占的权重。值越大，新数据所占的权重越大，原始预测值所占的权重就越小，反之亦然。 由式(3)可知，新预测值本质上是使用预测误差对原预测值进行修正后得到的，其中的值与修正的幅度成正比： 如果，则，新预测值等于原预测值，即忽略新观测值，完全相信过去信息。 如果，则，新预测值等于新观察值，即忽略过去信息，完全相信新观测值。 因此，的值应根据时间序列的具体性质在0~1之间选择。一般原则是： 如果时间序列波动不大，则的值应取小一点，e.g. 0.1~0.5之间 如果时间序列具有迅速且明显的变动倾向，则的值应取大一点，e.g. 0.6~0.8之间。这样预测模型更为灵敏，以便迅速响应变化。 实际应用上，类似移动平均法，多取几个值，选其中预测误测最小的那个。 初始值的选择 在指数平滑预测模型中，除了选择合适的值，还要确定初始值。初始值是由预测根据经验指定的。一般原则是： 如果时间序列的观测数据较多，初始值对以后的预测值影响很小，可选用第一期的观测值作为初始值。 如果时间序列的观测数据较少，初始值对以后的预测值影响较大，可选用最初几期观测值的平均值作为初始值。 二次指数平滑法 一次指数平滑法适用于时间序列没有明显变动趋势的场景。但是当时间序列的变动出现线性变动趋势时，用一次指数平滑法进行预测的未来值会存在明显的滞后偏差，而线性趋势恰好体现在滞后偏差上。因此，二次指数平滑的思想是：一次指数平滑法得到的滞后偏差建立线性趋势模型。对一次指数平滑模型的预测结果进行修正，即进行二次移动平均，最终得到修正后预测值更接近实际情况。 预测模型 根据一次指数平滑法的计算公式: 可得二次指数平滑法的计算公式为： 其中，为一次指数的平滑值，为二次指数的平滑值。 设时间序列从某个时期开始呈现线性趋势，且线性趋势会延续到未来，其线性趋势预测模型为： 其中，表示当前时期，为由至预测期的间隔期数，，为平滑系数，分表示斜率和截距。 类似二次移动平均法的线性趋势模型推导过程，可得二次指数平滑的线性趋势模型： 总结，二次指数平滑法一种既能反映趋势变化，又可以有效的分离出周期变动的预测方法。因此，适用于同时存在线性趋势和周期波动的时间序列 三次指数平滑法 当时间序列的变动表现为二次曲线趋势时，则需要使用三次指数平滑法 当时间序列的变动表现为二次曲线趋势时，则需要用三次指数平滑法。三次指数平滑法是在二次指数平滑的基础上，在进行一次平滑。其计算公式为： 其中，分别为一次指数平滑值，二次指数平滑值和三次指数平滑值。 设时间序列从某个时期开始呈现二次曲线趋势，且变动趋势会延续到未来，其二次曲线趋势预测模型为： 其中，表示当前时期，为由至预测期的间隔期数，，，为平滑系数。 三次指数平滑法的预测模型为： 总结指数平滑预测模型是以时刻为起点，综合历史序列的信息对未来进行预测。选择合适的加权系数是提高预测精度的关键。一般的原则是： 如果序列的基本趋势比较平稳，预测偏差由随机因素造成的，则的值应取小一点，以减少修正幅度，是预测模型能包含更多的历史数据。 如果预测模板的基本趋势已经发生系统地变化，则 的值应取大一点，这样可以偏重新观测值对原预测模型进行大幅度修正，使预测模型适应预测目标的新变化。","link":"/2020/08/11/%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2%E4%B9%8B%E4%B8%89%EF%BC%9A%E6%8C%87%E6%95%B0%E5%B9%B3%E6%BB%91%E6%B3%95/"},{"title":"时序模型初探之二：移动平均法","text":"简述移动平均法（Moving average，MA）是根据时间的推移，依次计算某个时间窗口内的时序平均数，以此预测长期趋势的方法。 使用场景：当时间序列受周期变动和不规则变动的影响，起伏较大，不易观测发展趋势时，可用移动平均法消除这些因素的影响。 三种常用预测模型移动平均法根据次数和权重的不同，可分为三种常用预测模型，分别是： 简单移动平均法 设观测序列为 ，取移动平均的窗口，简单移动平均的公式为： 当观测目的的基本趋势在某一水平上下波动时，可用简单移动平均方法建立预测模型： 其预测标准差为： 总结，简单移动平均只适合做近期预测，且预测目标的发展趋势变化不大的情况。预测模型使用最近期序列值的平均值作为未来各期的预测结果。一般的取值范围：。当历史序列的基本趋势变化不大，且序列中随机变动成分较多时，的取值应该较大一些，否则的取值宜小一点。选择值的一个有效方法是，选取多个值，选预测标准差最小的那个值。 加权移动平均法 在简单移动平均法中，每个序列值在预测过程中的权重都是等同的。但实际上，越靠近当前的序列值应该包含着更多关于未来的的信息量。因此，加权移动平均法的基本思想就是：在预测过程中给予近期数据更高的权重。 设观测序列为，取移动平均的窗口，加权移动平均的公式为： 使用加权移动平均法建立预测模型： 可用总的平均相对误差，对预测值进行修正： 修正后的预测值: 假设，则表示总预测值的平均值比实际值低0.06。 总结，在加权移动平均的预测模型中，权重的选择具有一定的经验性，一般原则是近期数据的权重偏大，而远期数据的权重偏小。 二次移动平均法 二次移动平均法，又称为趋势移动平均法。由上可知，简单移动平均法和加权移动平均法，适用于时间序列没有明显变动趋势的情况。当时间序列出现线性增加或减少的变动趋势时，使用移动平均或加权移动平均的预测模型得到的结果会出现滞后偏差，而变化的趋势恰好体现在滞后偏差上。因此，移动平均或加权移动平均法的思想就是：基于移动平均或加权移动平均预测得到滞后偏差建立线性趋势的预测模型，对一次移动平均的预测结果进行修正，即进行二次移动平均，最终得到一个修正后的预测值更接近实际情况。 设观测序列为，取移动平均的窗口，简单移动平均的公式为： 所谓二次移动平均，就是在一次移动平均的基础上再进行一次移动平均，其计算公式为： 以下是利用移动平均的滞后偏差建立线性趋势预测模型的过程： 设时间序列从某个时期开始呈现线性趋势，且线性趋势会延续到未来，其线性趋势预测模型为： 其中，表示当前时期，为由至预测期的间隔期数，，为平滑系数，分表示斜率和截距。 推导平滑系数，由上面的线性函数可知： 所以 因此，结合，可得 由于与的关系等同于与的关系，同理可得： 于是，平滑系数的计算公式为： 至此，线性趋势预测模型建立完成。 总结，二次移动平均法是一种既能反映趋势变化，又可以有效的分离出周期变动的预测方法。因此，适用于同时存在线性趋势和周期波动的时间序列。 总结一次移动平均的假设前提是最近期数据对预测值的影响相同，即权重都为。换言之，期之前的历史数据对预测值的影响被忽略，即权重为0。 二次及更高次移动平均的权重不再是，而是随着次数的叠加而呈现对称结构，即两端项的权重小，中间项的权重大。","link":"/2020/08/07/%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%8E%A2%E4%B9%8B%E4%BA%8C%EF%BC%9A%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%B3%95/"},{"title":"《Effective Modern C++》条款8：表示空指针优先选用nullptr，而非0或NULL","text":"简述 字面常量0的型别是int，而非指针。C++会在只能使用指针的语境中才勉强将其解释为空指针。 NULL是一个宏定义，而非指针。同样，C++会在只能使用指针的语境中才勉强将其解释为空指针。 12345678/* Define NULL pointer value */#ifndef NULL #ifdef __cplusplus #define NULL 0 #else /* __cplusplus */ #define NULL ((void *)0) #endif /* __cplusplus */#endif /* NULL */ nullptr是C++关键字，不具备整型型别。实际上，它也不具备指针型别，但是它可以隐式转换成任意指针型别，这也就是为什么nullptr可以用于初始化所有指针型别的原因。 使用nullptr可避免多义性由于字面量0和NULL本质上是一个整型，因此用它们表示空指针时会出现多义性，而使用nullptr可避免多义性。 避免重载决议中的意外 1234567891011121314class Widget {public: .... void Func(int); // Func的三个重载版本 void Func(bool); void Func(void*);};Widget w;w.Func(0); // 调用的是Func(int)，而非F(void*)w.Func(NULL); // 可能编译错误，但一般会调用的Func(int)， // 而非F(void*)w.Func(nullptr); // 调用的是Func(void*) 提升代码清晰度 比如涉及auto型别推导时： 123456789auto ret = FindRecord(/* 实参 */);if (result == 0) { // 很难判断result的型别是整型还是指针...}auto ret = FindRecord(/* 实参 */);if (result == nullptr) { // 一目了然...} 总结 相对于0NULL，优先选用nullptr 使用nullptr可避免在整型和指针型别之间出现重载意外","link":"/2019/04/24/%E6%9D%A1%E6%AC%BE8%EF%BC%9A%E8%A1%A8%E7%A4%BA%E7%A9%BA%E6%8C%87%E9%92%88%E4%BC%98%E5%85%88%E9%80%89%E7%94%A8nullptr%EF%BC%8C%E8%80%8C%E9%9D%9E0%E6%88%96NULL/"},{"title":"用复利思维来思考人生","text":"今天看了一篇文章，名为《比勤奋更能决定人生的是复利思维》，里面谈及了复利思维带来的边际递增效应，并列举了诸如吴晓波和巴菲特等典型的成功案例。我并不完全认同文章中的观点和论据，但是文章所要表达的核心思想还是值得学习的，就是用复利思维来思考人生。 文章中提及了一个用于表达复利效应的表达式：(1+r)n，即1+r的n次方。其中，r表示当前你正在做的一件事，n代表时间。显然，当r为正时，表示做一些类似健身、跑步、阅读等长周期低回报的事情。在最开始的阶段这些事情并不会对你产生的影响是微小且难以被察觉的，但是随着n的增大会慢慢呈现出指数级的变化。只要r为正，即你在做正确的事情，时间就会为你带来奇迹。 财富复利。当下很多人都渴望着一夜暴富，想用最短的时间追求最快速的财富积累，追求高回报率。实话说，这种心态也时常困扰着我。然而，高回报率意味着高风险，很多理财产品也正是利用这种心理，通过短期高回报率来吸引顾客，最后往往是顾客被骗、亏空、债台高垒。典型的例子比如前不久杭州一系列的p2p理财产品爆雷，很多人为此倾家荡产。然而，如果把目光放长远一点，用复利的思维看待财富积累，耐心地等待机遇，即便是当下的回报率很低。 知识复利。利用碎片时间长期的坚持阅读看书，新知识不断成为下一次思考素材的积累，从而让知识能够不断以复利的速度快速迭代。对于这一点我深有体会，我一直都有睡前阅读的习惯，从最开始的强迫自己阅读到现在主动喜欢阅读。在坚持五年之后，我明显能感觉到这个习惯带给我成长，更重要的时这个它让我真实的体会到“复利效应”。可惜当下愿意花半个小时用来看书的人已经很少了，身边的朋友大多都把时间“浪费”在玩游戏和综艺娱乐节目上。 健康复利。不同于阅读，作为一个从小喜好运动的我对于健身这件事情的主观意愿比阅读会强一些。记得15年第一次走进健身房，我给自己定下的目标是：每天5公里坚持100天。随后16年，我给自己的目标是：每天10公里，坚持跑一年。那时候并不懂得复利思维，而是想着坚持下去就一定会有收获。现在想来也有点佩服那时候的自己，也很感谢那时候的自己。 看了这篇文章之后觉得自己很庆幸，误打误撞走上了一条似乎是正确的道路。不过，站在整个人生的维度来说这只是刚刚开始而已，很多时候我还是会因为急功近利的心理而变得鼠目寸光。未来的路还很长，还有很多更具挑战的事情等着我去克服。路漫漫其修远兮，吾将上下而求索。","link":"/2017/05/27/%E7%94%A8%E5%A4%8D%E5%88%A9%E6%80%9D%E7%BB%B4%E6%9D%A5%E6%80%9D%E8%80%83%E4%BA%BA%E7%94%9F/"},{"title":"《1984》读后感之楚门的世界","text":"我是国庆假期的最后一天，睡了一会懒觉，九点起床。没有像昨天的那样惯性地选择去公司加班，而是约了二三好友去健身房完成了今日的训练，这应该是我多年来第一次选择上午去健身。这种感觉让我想起温斯顿在某一天下班后没有径直回家，而是在一种自己也弄不明白的驱动力下走向了无产者居住的街道。现在看来，温斯顿这个看似不经意的选择加速了他生命结束的进程，但与此同时也是遇见爱情的开始，也许他当时认为只是生命中普通的一天。 下午没有午睡而是在某巴克点了一杯无糖拿铁，选了一个安静的角落，拿出kindle并尝试着在把《1984》看完。这是一个美妙的下午，感觉自己很久没有像今天这样心无旁骛地阅读一本书，或许这是第一次。不负“众”望，我如愿以偿地的看完了这本书。期间甚至没有去一趟洗手间，也许是我太过认真，也许是因为洗手间的温度比大厅低5°的原因。看完后，我伸了一个懒腰，环视着周围的这个世界，脑海中闪过一丝疑虑：我当下所处的世界是否是客观真实的，亦或是它只是一个“楚门的世界”。 王小波杂文中常提到罗素先生的一句话：“须知参差多态，乃是幸福的本源”，这也是我对生活和这个世界的期许与认知。但也会有人觉得单一机械乃是幸福的本源。于我，定是前者。在接触《1984》之前，我坚信周围的世界是客观存在的，而非存在于我的主观意识中，更不愿意相信它是被有意创造出来的假象，并通过教育等多种的方式让我信以为真。但是，现在我会怀疑至少存在部分以前看似合理的真相其实是一种假象，我们也许就像电影《楚门的世界》中的男主角那样，从一出生便生活在已经设计好的剧本里面，而不自知。也许“过去”并不客观的存在，它只存在于记录和人的记忆中。但凡是记录和记忆一致的东西，即是“过去”。我们从小接受的教育大多数都源于课本，视课本中的知识为金科玉律，认同课本中的价值观，认为课本中描述的历史就是历史本身的模样。那是否存在一种可能性，课本中的知识是出于某种政治或其他的目的而被有意编排的，为的是让我们变成被期望的样子，以达到统一思想的目的。书中说谁掌控了过去就掌控了未来，谁掌控了现在就掌控了过去，而教育应该是达成这个目的成本最低也是效果的手段之一，也许没有之一。目前来看，这种教育的非常成功的，我们周围已经培养出相对数量的无产者。这些人崇拜着老大哥，如今老大哥已然是党的化身。大多数时候他们会沉浸于各种综艺娱乐节目或是精心制作的爱国纪录片中安然度日，这就是所谓的奶头乐策略。但倘若出现对民族或国家的批评或诋毁，他们便会发出如同仇恨日那般的怒吼和反击，而非自省，但他们这些过激行为又似乎被上层默许的。在他们眼里非黑即白，似乎没有可用于商榷的中间地带。温斯顿一直将希望寄托于无产者，殊不知无产者本身已经没有了主观思想，他们安逸于目前的生活现状，他们认同资本主义是万恶之源，他们看到的国外局势永远是动荡不安的。即便日子过得艰苦也不会有所察觉或不满，因为没有对比，在他们目光所及之处皆如此，便也心安理得。纵观人类历史，任何一次革命的成功都必须有一只思想先进的先锋队，只有在他们的带领和引导之下群众才有可能觉悟，才有可能拿起武器反抗统治阶级。单纯依赖于愚蠢的无产者是不可能自我觉悟的，可惜温斯顿并没有意识到这一点。而温斯顿作为外围党成员中的觉悟者，本应属于先锋队中一员，但是他已丧失了人身和思想的自由。这也是为什么核心党只对外围党成员进行密切的监视，而放任无产者自生自灭。一直以来我不明白当年毛为什么要发动群众进行一场由下而上的文化大革命，而不是至上而下的整顿。现在我知道了答案，因为当年的先锋队已经变质了，而他们现在就是被革命的对象。文革的初衷是利于无产者的，其最终失败源于毛对权力和人性的过度自信，权利的泛滥和人性的扭曲导致局势失控，酿成了一出人间惨剧。当他意识到这一点的时候，已经油尽灯枯，无能为力。历朝历代得罪过既得利益集团的统治者都会背负骂名，不论是雍正还是毛，都是如此。因为他们得罪的就是书写和掌控历史的人，这也是为什么《毛选》最后一卷成为了禁书。想起书中有一个有意思的细节，通过奥勃良的家是可以知道核心党是享有特权的，他甚至可以关闭电幕。同样，在文革那个“闭关锁国”的时代，特权阶层也从未与外部世界隔绝。 温斯顿是孤独的，具体来说是思想孤独患者。他不得不小心翼翼地隐藏着自己内心反动的思想，但又极度渴望找到志同道合的同志。当他第一次见到奥勃良便坚信对方是他苦苦找寻的那个人，那个可以带给他希望的人，我当时也深以为然。然而，最后他才知道这一切都是幻想，不过是一场游戏一场梦而已。从最开始他就走进了奥勃良为他精心设计的圈套里，包括却林顿的店铺，与奥勃良的密会，以及那本精神领袖果尔德施坦因的书都是有意的安排。可怜的温斯顿一直认为自己隐藏的很好，没有留下蛛丝马迹，却不知道思想警察其实早已翻阅过他的日记，只是又被原封不动地放回原处，即便是日记本上那颗白色的灰尘都被小心地还原。以奥勃良为代表的思想警察耐心地用来七年时间自导自演这出戏，看着温斯顿做困兽之斗，不断地引诱着他表露自己内心的真实想法。如果非要说有一丝欣慰，那就是温斯顿比《楚门的世界》中的男主角幸运一点，因为至少他与裘莉亚之间的感情是真实存在的，且裘莉亚也是他唯一的战友，他们有过一段快乐的时光。不过温斯顿在这场斗争中注定是要失败的，因为他面对的不是某一个个体，而是一个经验丰富的集团，里面都是身经百战的老戏骨。毋容置疑，类似的戏码他们已经经历过一次又一次，也将一代又一代永远一而再再而三地演下去。人作为个体终究是要死去的，而集团是可以以思想和意志的形式永远存在的。一个统治集团只要能够指定它的接班人就是同一个统治集团。党所操心的不是维系血统相传而是维系党本身的永存。由谁掌握权力并不重要，只要等级结构保持不变。想到这一点，不由得心生寒颤，似乎确实是如此的。 《V字仇杀队》中的有一句台词：“面具下面不只是血肉之躯，而是一种思想，思想是不怕子弹”。此前我一直认为肉体消灭是对一个人最极端的处决，其实不然，思想改造才是。一个人失去了独立思考的能力，已于行尸走肉无异。温斯顿最开始也不明白为什么自己因为思想罪被捕之后没有立即被处以极刑，而是遭受不断地拷问和折磨。原因正如奥勃良所说，党是不会满足于消极的服从，甚至是最卑躬屈膝的服从都不要。他们不会对异端分子进行简单地肉体毁灭，而是进行改造思想和争取内心，使异端分子在内心真心诚意的屈服。让异端分子带着脱离正轨的思想死去，只会激发更多的异端分子，这是不能被容忍的。在强大的国家机器面前，温斯顿最终被改造成功，他出卖了裘莉亚，背叛了爱，也背叛了原来的自己。他尝试做过抵抗，但最终让他屈服的不是无尽地拷打带来的肉体上的痛楚，而是人的一种无法不服从的本能：对每一个人来说，都各有不能忍受的事情，连想都不能想的事情，这并不牵涉到勇敢与怯懦的问题。对温斯顿来说，老鼠是无法忍受的，对他会产生一种无法抗拒的压力。这也足以说明思想警察对于人性已经有很深刻的研究，从而有了让人闻风丧胆的101号房。想必裘莉亚也是在同样的情况下出卖了他，至少我相信是这样的。所以说，他们没有并出卖彼此，他们只是屈服于人的本能罢了。 最后，也是我个人觉得是最让感到绝望的一点：人类历史似乎始终都处于不断轮回的过程，那个人人自由平等的天堂永远不会到来，但却一直被作为革命最初的愿景。革命的目的其实是为了建立专政，夺取权利的目的就是为了权利，而所谓“取消私有制”实际上意味着把财产集中到比以前更少得多的一批人手中，不同的是，新主人是一个集团，而不是一批个人。而历史的不断重演，从某种意义上来说是在不断地帮助统治者丰富和优化巩固政权的手段，而无产者则永远是无产者。","link":"/2018/10/05/%E6%A5%9A%E9%97%A8%E7%9A%84%E4%B8%96%E7%95%8C/"},{"title":"科斯定律-从社会成本看问题","text":"最近了解到一个很棒的经济学概念：社会成本问题。这是之前从未接触到的概念，给了我一个全新的思考问题的角度，心中多少有点欣喜。奈何这个概念有点深奥难懂，所以试着写出自己的理解以加深理解。 社会成本问题在经济学中有着非常重要的政策含义。只有理解了社会成本问题，才能顺应社会和市场的基本运行规律，制定出因势利导的经济政策。 最早把社会问题成本讲清楚的是罗纳德·斯科。人们一直信奉的用来解决纷争的金科玉律是：“权利的刑事应以不伤害别人的权利为界”。而斯科认为所有的伤害都是相互的，对于纷争的双方，谁避免意外的成本最低，谁的责任就最大。在面对具体的案例时，人们容易不自觉地掺入个人的情感和主观判断，而只有斯科看到了纠纷背后与资源争夺相关的、客观的经济本质。 斯科把产权或侵权的案件都看作是人们对稀缺资源的平等争用。为了解决这些纷争，进而形成了科斯定律：在交易费用为零或足够低的情况下，不管资源最初的主人是谁，资源都同样会流到价值最高的用途上。 然而现实生活中交易费用很高，很多资源是没有办法落到使用价值更高的人手里。因此，我么有时要鼓励第三方-例如政府-在知道资源怎样使用最合理、在非常有把握的情况下，使用手中的权利对资源进行重新分配。而这就是所有的制度、风俗、习惯以及政府、法院存在的根源理由-对资源、责任、权利进行初始界定。我们可以把社会上通行的制度、习俗和道德规范，都看成为了减少重复商议的成本而逐渐固定下来的解决纠纷的办法。 经济学本质就是研究这个世界客观地运行规律，这恰恰是经济学最具有魅力的地方。","link":"/2018/08/16/%E7%A7%91%E6%96%AF%E5%AE%9A%E5%BE%8B-%E4%BB%8E%E7%A4%BE%E4%BC%9A%E6%88%90%E6%9C%AC%E7%9C%8B%E9%97%AE%E9%A2%98/"},{"title":"红黑树（Red-black tree）","text":"简述红黑树同AVL树一样也是一种自平衡二叉搜索树，不同于AVL树是高度平衡树，红黑树属于近似平衡树。 所谓近似平衡就是对平衡的要求相对宽松，不像AVL树那么严格。红黑数的平衡标准是：任一节点的左右子树的高度差小于两倍。 判断一颗二叉搜索树是否是红黑树的条件如下: 每个节点非黑即红 根节点必须是黑色 每个叶子节点必须是黑色，即NIL节点或空节点必须是黑色 不能出现连续的红色节点，即不能有两个相邻的红色节点 任一节点到其每个叶子节点的所有路径都包含相关数目的黑色节点 其中，最后两点可确保红黑树的平衡标准始终得以满足，证明过程略。 复杂度 时间复杂度 由于红黑树也是近似平衡树，所以其查找、插入和删除在平均和最坏情况下的时间复杂度都是O(logn)。 空间复杂度 红黑树的空间复杂度只与节点个数相关，因此为O(n)。 对比AVL数红黑树与AVL树的比较： AVL树的查找速度更快，因为AVL有更为严格的平衡标准 红黑树提供了更快的插入和删除的操作，因为红黑树的平衡标准更为宽松，所以旋转操作更少。 红黑树对额外空间的消耗更小。AVL树的每一个节点需要存储一个平衡因子或高度值，只是需要一个整型，而红黑树只需要一个bit位用于标识节点的颜色属性，非红即黑。 综上， 红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入或删除操作更少的旋转操作，整体来说性能优于AVL树。 注：红黑树和AVL树在数据量较小时的性能相近，但是在百万或千万级的数据量时，二者的性能差异会比较明显。 使用场景鉴于红黑树在插入和删除的性能更佳，因此广泛用于实现插入或删除操作较为频繁的数据结构，如C++的STL中map和set等。 参考资料红黑树 - 维基百科，自由的百科全书 Red-Black BSTs - Balanced Search Trees | Coursera","link":"/2019/08/25/%E7%BA%A2%E9%BB%91%E6%A0%91%EF%BC%88Red-black%20tree%EF%BC%89/"},{"title":"经济学中的成本","text":"最近在《薛兆丰经济学讲义》一书中看了“成本”这一概念在经济学中的定义，这与我过去的理解截然不同。 书中专门有一章是讲成本的概念，可见成长在经济学中占有非常重要的地位。书中说如果我们对成本的概念有了深刻的理解，就可以说对经济学了解了一半。 我以前对于成本的理解是做某件事情需要付出的代价，包括物质、金钱和劳动力等。然而，书中对成本的定义是：成本是放弃了的最大代价。换言之，如果做一件事情没什么可放弃的，也就不存在成本。比如，如果你选择做事情A的，那么就不能做事情B、C、D、E…。那么你做事情A的成本就是你所放弃的其他选项中价值最高的那个。 与成本容易混淆的一个概念是沉没成本。沉没成本是指那些已经发生但是不可收回的支出。比如你买票去看一场电影，但是看了10分钟之后你觉得这个电影不好看，最合适和做法就是马上离开电影院。此时，买电影票的钱已经沉没了，不可再放弃，也就不再是成本了。但是很少有人会在这种情况下果断地离开电影院。 既然成本的定义是“所有放弃了的选项中价值最高的那个”，但问题是所有放弃的选项并没有实现，我们又如何知道自己放弃东西的价值呢？答案是，这个价值只能靠想象。这正是成本深奥的原因所在。这个想象空间吸引了众多经济学家在成本的概念上下大功夫。他们充分挖掘了想象空间，分析公共品使用的成本、制度变迁的成本、社会成本、竞争本身带来的成本，将我们对世界的理解拓宽到前所未有的领域。","link":"/2018/08/02/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%B8%AD%E7%9A%84%E6%88%90%E6%9C%AC/"},{"title":"经济学概念-租","text":"最近在《姚兆丰经济学讲义》看到一个“租”的概念。从经济学的角度进行了重新定义，看完之后云里雾里、似懂非懂，于是做点笔记以加深理解。 有一种资产，不以收费的变化而变化，这种资产带来的收入就是租。租就是相对资产的付费，这里说的资产是广义上的，包括土地、矿产、才能以及特权，只要能够带来收入的就是资产，而对资产付费就是租。 每个人都享受一定程度的租。比如我们在平时上班时抽出半个小时刷朋友圈，老板并不会因此开除你或少付工资，这样你就赚了半小时的租。而且这一部分的租是属于旱涝保收的。然而现实生活中，随着时间和竞争条件的变化，真正让你旱涝保收的租是绝对不存在而是相对的存在的。 基于成本是放弃的最大代价这一前提，如果你对目前的工作感到满意，觉得下一份工作的收入会比现在低很多，那你就是在享受当前工作带来的租；相反，如果你觉得你另外一份工作收入会高很多，那你选择留在当前岗位的成本就非常高。此外，即使你不换工作留在当前的岗位上，如果你每天不管努力工作还是得过且过，结果收入都一样，那你选择懒散度日的态度，就是在享受租；但如果努力或懈怠带来的收入会有明显差异，那么你选择懈怠就要付出很大的成本。 不妨记住一句话：人人都是资本家，因为当你认识到自己是资本家之后，会把注意力放到提升自己的租值上，而不是所谓的被剥削。","link":"/2018/08/11/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E6%A6%82%E5%BF%B5-%E7%A7%9F/"},{"title":"经济学的基础：稀缺","text":"稀缺与歧视 稀缺是人类一直面对的问题，也是客观存在的事实。稀缺的含义非常之广，不仅指矿产、森林和能源等有形资产的匮乏，还有空气、美貌、天资、意志力和时空等无形资产稀少。 此外还有很多不易觉察到的稀缺资源，比如说地理位置的稀缺，如北上广这些一线城市的地理位置是稀缺的。另外信任也是稀缺的，不是可以随便建立起来的。同学之所以重要，是因为同学决定了你将来社交的圈子、工作层次。许多人读书的首要目的就是为了与同学建立信任这一项长期投资。 稀缺之所以一直客观存在，主要由两个原因：一是我们想要的东西别人也想要；二是人的需求在不断变化和升级，人的欲望是无止境的。 因为资源的稀缺，人们就不得不对资源的用途进行选择，而一旦做出选择就意味着存在区别对待，而区别对待就是歧视。（我觉得歧视在此处应该是中性词） 稀缺、选择、区别对待和歧视这四个概念，其实是一体的，只要有一个就意味着同时有其他三个。因为稀缺是客观存在的，因此歧视也是客观存在的。 既然不能逃避歧视，那么久只能直面歧视。有时候我们抱着平等主义的思想，试着消除歧视，结果却是产生了新的歧视，这也被称之为逆向歧视。 所以说，歧视不是问题，如何歧视才是问题。 中年人的魅力 今天听了梁实秋先生的文章《中年人的魅力就在如此》，里面的观点我个人比较赞同。虽然尚未进入中年，但是中年的困境的没办法逃避的，遂记录自勉： 某个时期，某个社会，即使所有的青年人和老年人都中魔了，只要中年人不荒唐，事情就怀不到哪里去。 到了该自立的年岁还不知道精神上的自立，这是中国很多中年人的共同悲剧。 中年人最容易犯的毛病，是把一切希望寄托于自己的老年。 如今天天节衣缩食、不苟言笑、忍气吞声，都是在争取一个有尊严、有资材、有自由的老年。 我们无数次看到，一个窝囊的中年抵达不到一个欢乐的老年。这正像江河，一个浑浊的上游不可能带来一个清澈的下游。 习惯了郁闷的，只能延续郁闷；习惯了卑琐的，只能保持卑琐。而且，由于暮色苍茫间的体力不支，有朋散失，郁闷只能更加郁闷，卑琐只能更加卑琐。 中年人失去方寸的主要特征是忘记了自己的年龄，一会儿要别人像对待青年那样关爱自己，一会儿又要别人对待老人那样尊重自己。","link":"/2018/07/25/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E7%9A%84%E5%9F%BA%E7%A1%80%EF%BC%9A%E7%A8%80%E7%BC%BA/"},{"title":"自平衡二叉搜索树（AVL）","text":"简述AVL树是计算机科学中最早被发明的自平衡二叉搜索树，顾名思义，AVL首先是一颗平衡树，其次它能够实现自平衡。 平衡因子AVL树引入了平衡因子（Balance Factor）的概念，即任意一个节点的左右子树的最大高度差为1，因此平衡因子的取值范围是：{-1, 0, 1}。因此，AVL树也被称为高度平衡树。 复杂度 时间复杂度 由于AVL树一直都处于高度平衡的状态，所以其查找、插入和删除在平均和最坏情况下的时间复杂度都是O(logn)。 空间复杂度 AVL树的空间复杂度只与节点个数相关，因此为O(n)。 四种旋转由于AVL树需要时刻保持平衡状态，因此在每一次插入或删除后都可能需要进行旋转操作，以确保插入或删除后的AVL树仍然处于平衡状态。 AVL旋转主要包括四种基础旋转，分别是： 左旋转 右旋转 左右旋转：先进行一次左旋转，再进行一次右旋转 右左旋转：先进行一次右旋转，再进行一次左旋转 优缺点 优点 AVL树的优势源于它的高度平衡，不管是查找、插入和删除在平均和最坏情况下的时间复杂度都是O(logn)。 不足 AVL树不足是为了维持高度平衡，节点需要存储额外的信息，比如每个节点需要存储一个平衡因子（至少是一个整数类型）。 此外，由于AVL树每次插入或删除操作后都可能需要进行旋转操作，所以调整次数会比较频繁，导致维护成本偏高。 适用场景鉴于AVL树的优缺点，AVL树适用于查询操作远大于插入或删除的场景，比如数据库。 参考资料平衡树 - 维基百科，自由的百科全书 AVL树 - 维基百科，自由的百科全书 第15课丨AVL树和红黑树的实现和特性","link":"/2019/08/21/%E8%87%AA%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%88AVL%EF%BC%89/"},{"title":"《船》：一首让我热泪盈眶的诗","text":"记一首让我热泪盈眶的诗… 《船》--白桦 我有过多次这样的奇遇， 从天堂到地狱旨在瞬息之间； 每一朵可爱、温暖的浪花， 都成了突然崛起、随即倾倒的高山。 每一滴海水都变脸变色， 刚刚还是那样美丽、蔚蓝； 旋涡纠缠着旋涡， 我被抛向高空又投进深渊。。。 当时我甚至想到过轻生， 眼前一片苦海无边； 放弃了希望就像放弃了舵柄， 在暴力之下只能沉默和哀叹。 今天的我才有资格嘲笑昨天的自己， 为昨天落叶似的惶恐感到羞惭； 虚度了多少年华，船身多次被礁石撞穿。。。 千万次在大洋里撒网， 才捕获到一点点生活的经验， 才恍然大悟， 啊！道理原是如此浅显: 你要航行吗？ 必然会有千妖百怪出来阻拦； 暴虐的欺凌是它们的游戏， 制造灭亡是它们唯一的才干。 命中注定我要常常和它们相逢， 因为我的名字叫做船； 面对强大于自身千万倍的对手， 能援救自己的只有清醒和勇敢。 恐惧只能使自己盲目， 盲目只能夸大魔鬼的狰狞嘴脸； 也许我的样子比它们更可怕， 当我以生命相拼，一往无前！ 只要我还有一根完整的龙骨， 绝不驶进避风的港湾； 把生命放在征途上， 让勇敢来决定道路的宽窄、长短。 我完完全全的自由了， 船头成为了埋葬它们的铁铲； 我在波浪中有节奏地跳跃， 就像荡着一个巨大的秋千。 即使它们终于把我撕碎， 变成一些残破的木片； 我不会沉沦，决不！ 我还会在浪尖上飞旋。 后来者还会在残片上认出我， 未来的诗人会喟然长叹： “这里有一个幸福的灵魂， 它曾经是一艘前进着的航船。。。”","link":"/2018/11/12/%E8%88%B9/"},{"title":"英语发音规则总结","text":"语句最常用的功能就是口语表达，一切的规则都是为了轻松且简单的表达！ 最近在学习ESLPod的“Introducation to the United States”系列，在跟读的时候感觉挺吃力，一方面是因为对音标熟练程度不够，另一方面就是对英语发音规则缺乏认知。秉着主动学习的态度，通过在网路上查阅资料，对英语发音规则有如下总结。 英语发音规则的建立在对音标熟练且准确掌握的基础之上！ 英语发音规则除了连读还包括浊化、爆破、同化、异化、缩读和略读等。大致包括七大技巧，它们分别是： 注：音标用-连接的地方表示要连读 第一大技巧 连读的两大规律 词尾辅音+词首元音 eg: Time is up =&gt; [taim-iz-ʌp] 词尾元音+词首元音 (1). 在遇到前一个词是以[ei][ai][ɔi][i:][i][e]这几个元音结尾的情况，加[j]连读 eg: Hurry up =&gt; [hʌri-j-ʌp] (2). 在遇到前一个词是以[aʊ][u:][ʊ]这个几个元音结尾时，加[w]连读 eg: How often do you swim =&gt; [haʊ-w-ɔfən] 第二大技巧 浊化的两大规律 所谓浊化就是把清辅音读成浊辅音 清辅音：[p][t][k][f][s][θ] 浊辅音：[b][d][g][v][z][ð] 元音+清辅音+元音 eg: letter =&gt; [‘lɛdɚ] water =&gt; [ˈwɔdɚ] , stay out of this matter =&gt; [stei-y-aʊ-dv-ðis mædɚ] 元音+T+L eg: battle =&gt; [bædl] cattle =&gt; [kædl] Flat T的浊化 3.1 在元音[ɚ]的前后 eg: artist =&gt; [ardst] thirty =&gt; [θɚdi] 3.2 两个tt并存时 eg: batter =&gt; [bædɚ] 3.3 t在[əl]之前 eg: hospital =&gt; [hɑspɪdl] 3.4 一般情况下，t在n和e之间，则t通常不发音。 eg: printer =&gt; [prɪn’ɚ] center =&gt; [cen’er] winter =&gt; [win’er] presented =&gt; [presen’ed] 第三大技巧 爆破的四大规律 爆破音略读：当前一个单词的词尾是爆破音（[p][t][k][b][d][g]）且后一个单词的词首也是爆破音，则省略前一个单词的词尾。 eg: take care =&gt; [tei-kɛr] 不完全爆破：所谓不完全爆破就是对于需要爆破的音，我们仅仅摆出对于的口型而不发出声音。 (1). 词尾爆破音+摩擦音（[f][s][θ][v][z][ð][r][j][w][ʃ][ɛ]） eg: I’m almost there =&gt; [im ɔlmos(t) ðɛr] (2). 词尾爆破音+破擦音[tʃ][dʒ][ts][dz][tr][dr] eg: That joke =&gt; [ðæ(t) dʒok] 鼻音爆破省略：同一意群内，爆破音在鼻音[m][n][ŋ]前，爆破音省略以停顿代替 eg: Good night =&gt; [gʊ(d) nait] 舌边音爆破省略：爆破音+舌边音[l] eg: It’s deadly =&gt; [it z dɛ(d)li] , Old lady =&gt; [ol(d) ledi] 第四大技巧 同化的二大规律 相互同化 (1). /t/+/j/-&gt;/tʃ/ eg: I got you =&gt; [i gɑ tʃ u] (2): /d/+/j/-&gt;/dʒ/ eg: Did you =&gt; [Di dʒ u] (3) /s/+/j/-&gt;/ʃ/ eg: God bless you =&gt; [Gɑ blɛ ʃ u] (4) /z/+/j/-&gt;/ʒ/ eg: How is your boyfriend =&gt; [Haʊ iz ʒ ʊr] 顺向同化：主要同于词尾加s和ed的情况，这两个音都存在清辅音和浊辅音两种发音，具体发音与该音的前一个音标的清|浊一致。 (1). 名词的复数 eg: friends =&gt; [frɛndz] , books =&gt; [bʊks] (2). 第三人称单数 eg: works =&gt; [wɜːks] (3). 过去式或过去分词 eg: looked -&gt; [lʊkt] 第五大技巧 异化：所谓异化就是当清辅音夹在/s/和元音之间时，清辅音发生浊化 sp+元音 eg: speak =&gt; [sbi:k] sk+元音 eg: school =&gt; [sgʊl] st+元音 eg: start =&gt; [sdɑrt] str+元音 eg: strange =&gt; [sdrendʒ] 第六大技巧 缩读：缩读规律性不强，不能一一列举 常见缩读 (1). want to =&gt; [wanna] (2). be going to =&gt; [be gonna] (3). got to =&gt; [gotta] (4). because =&gt; [‘cause] (5). out of =&gt; [outta] (6). you =&gt; [ya] (7). what is the =&gt; [what’sa] (8). sure =&gt; [sher] (9). what are you =&gt; [wachya/wacha] (10). ing =&gt; [in’] 情态动词完成时和过去将来时的不规则缩读 (1). could have =&gt; could’a (2). must have =&gt; must’a (3). should have =&gt; should’a (4). would have =&gt; would’a of的不规则缩读 (本质上是由于语速+f的弱读+上下文导致) (1). kind of =&gt; kinda (2). a lot of =&gt; a lotta (3). lots of =&gt; lotsa (4). sort of =&gt; sorta (5). bunch of =&gt; buncha (6). because of =&gt; becausa 第七大技巧 略读 词尾爆破音略读 eg: very goo(d) , nerver give u(p) 意群结尾的爆破音 eg: I thin(k) you shouldn(t) punish him too har(d) 注：I + think是一个意群，经过think后面紧接you，但是you属于宾语从句，不是一个意群。 同类音：[s]/[θ] , [s]/[ʃ], [z]/[ð]，谁在前面谁先死 eg: Thi(s) shop i(s) so romantic t音的消失： 当[t]在[n]和元音之间（原因可能是[t]的音弱读像边音l因此可以直接略读） eg: Internet =&gt; [In(t)ɚnɛt]","link":"/2018/07/24/%E8%8B%B1%E8%AF%AD%E5%8F%91%E9%9F%B3%E8%A7%84%E5%88%99%E6%80%BB%E7%BB%93/"},{"title":"表达式：x &amp; (-x)的含义","text":"表达式：x &amp; (-x)的含义： 返回x在二进制下的最右边的1表示的值： 如果x是偶数，返回值能整除x且该值一定是2的n次幂，即能整除x的最大的2的n次幂 如果x是奇数，返回值一定是1. 解析： 根源在于计算机中表示负数的机制，即补码。 补码 = 原码取反 + 1 原码：x = b0000’0100 反码：~x = b1111’1011 补码：-x = ~x + 1 = b1111’1100 如果x是偶数，取反末位为1，+1会发生进位，最终最右边的1及后面的0与原码一致。 如果x是奇数，取反后末位为0，+1不会发生进位，最终只有最末位于原码一致，","link":"/2019/03/11/%E8%A1%A8%E8%BE%BE%E5%BC%8Fx%20&%20(-x)%E7%9A%84%E5%90%AB%E4%B9%89/"},{"title":"表达式：x&#x3D;x&amp;(x-1)的含义","text":"表达式x = x &amp; (x - 1)的含义是： 每执行一次，就会把x二进制格式下最右边的1变为0，换言之就是该表达式有效的执行次数等于x二进制格式下1的个数。 以下是常见的几个应用： 统计x在二进制格式下1的个数 12345678int Func(int x) { int countX = 0; while (x) { x = x &amp; (x - 1); countX++; } return countX;} 判断一个整数是否是2的n次幂 12345678int Func(int x) { // 如果x是2的n次幂，那么x的二进制表达式只有一个1，其余都是0 if (x &amp; (x - 1) == 0) { return true; } else { return false; }}","link":"/2019/03/15/%E8%A1%A8%E8%BE%BE%E5%BC%8Fx=x&(x-1)%E7%9A%84%E5%90%AB%E4%B9%89/"},{"title":"解除NSTimer潜在的“保留环”问题","text":"NSTimer是Foundation框架中的一个使用频率很高的类，然而其调用过程中很容易引入潜在的“保留环“问题。可能是因为NSTimer的提供的API足够便利与顺手，以至于这个问题不容易被察觉到。这篇博客旨在阐述这个问题并提供解决方法。 以下的NSTimer提供的三个常用的创建或者初始化的API： 123456+ (NSTimer *)timerWithTimeInterval:(NSTimeInterval)ti target:(id)aTarget selector:(SEL)aSelector userInfo:(nullable id)userInfo repeats:(BOOL)yesOrNo;+ (NSTimer *)scheduledTimerWithTimeInterval:(NSTimeInterval)ti target:(id)aTarget selector:(SEL)aSelector userInfo:(nullable id)userInfo repeats:(BOOL)yesOrNo;- (instancetype)initWithFireDate:(NSDate *)date interval:(NSTimeInterval)ti target:(id)t selector:(SEL)s userInfo:(nullable id)ui repeats:(BOOL)rep NS_DESIGNATED_INITIALIZER; 这三个API有一个共同的点，即都需要提供一个target参数。这个target参数会被创建的NSTimer实例对象强引用一次，直到NSTimer实例对象调用invalidate方法后失效才释放。API文档原文如下： target: The object to which to send the message specified by aSelector when the timer fires. The timer maintains a strong reference to target until it (the timer) is invalidated. 多数情况，我们都会将创建后NSTimer实例对象保存为当前类的实例变量，然后NSTimer的target参数设置为self指针。我写代码的习惯就是这样的。实例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142#import &lt;Foundation/Foundation.h&gt;@interface MyObject : NSObject { NSTimer *mTimer;}@end@implementation MyObject- (id)init { if ((self = [super init])) { //此处参数repeats = YES; mTimer = [NSTimer scheduledTimerWithTimeInterval:1.0 target:self selector:@selector(timerFiredFun) userInfo:nil repeats:YES]; [mTimer setFireDate:[NSDate distantPast]]; } return self;}- (void)dealloc { [mTimer invalidate]; mTimer = nil;}- (void)timerFiredFun{ NSLog(@\"%s\" , __func__);}@endint main (int argc , const char * argv[]) { MyObject *myObjcet = [MyObject new]; //self只是一个空消息，避免编译器发出myObjcet未使用的警告 [myObjcet self]; //NSTimer依赖于RunLoop而存活，手动激活RunLoop while (1) { [[NSRunLoop currentRunLoop] runMode:NSDefaultRunLoopMode beforeDate:[NSDate distantFuture]]; } return 0;} 上述代码就是典型的计时器使用情景之一。如果计时器只是一次执行而非反复触发，那么计时器会在执行后自动失效，也就不会有“保留环”的问题。但是如果是设置反复触发的计时器类型，那么NSTimer对象会强引用MyObject对象，而当前类也一直持有NSTimer对象，因此，如果NSTimer不调用invalidate设置无效，MyObject对象不会背释放，其dealloc函数也一直被调用，然而NSTimer的invalidate恰好是MyObject对象的dealloc函数中调用。这样两个对象都不会释放。 出现“保留环”的根本原因在于NSTimer对象在创建的API隐性地强引用一次target，因此，解除“保留环”的关键在于避开NSTimer对象对self指针的强引用。以下是提供的一种解决方案： NSTimer+BlockSupported分类 123456789101112131415161718192021222324252627282930313233#import &lt;Foundation/Foundation.h&gt;typedef void(^ICETimerScheduleBlock)(void);@interface NSTimer (BlockSupported)+ (NSTimer *)ice_scheduledTimerWithTimeInterval:(NSTimeInterval)ti block:(ICETimerScheduleBlock)block repeats:(BOOL)yesOrNo;@end#import \"NSTimer+BlockSupported.h\"@implementation NSTimer (BlockSupported)+ (NSTimer *)ice_scheduledTimerWithTimeInterval:(NSTimeInterval)ti block:(ICETimerScheduleBlock)block repeats:(BOOL)yesOrNo { //Timer会对target强引用，但是此处target变成Timer类对象。因为类对象生命周期与应用程序一置的，不受引用计数限制，所以没关系。 return [NSTimer scheduledTimerWithTimeInterval:ti target:self selector:@selector(ice_timerFiredFun:) userInfo:block repeats:yesOrNo]; }+ (void)ice_timerFiredFun:(NSTimer *)timer { ICETimerScheduleBlock block = timer.userInfo; if (block) { block(); }}@end 使用方式 1234567__weak typeof(self) weakSelf = self;mTimer = [NSTimer zd_scheduledTimerWithTimeInterval:1.0f block:^{ //添加一次局部强引用，确保即使在block执行过程中外部的self被释放了也能顺利完成。局部变量strongSelf的生命周期只限于当前block，不会一直持有self，所以不影响外部self对象的引用计数平衡。 //如果局部强引用，weakSelf可能会在block执行过程中因为外部self释放而被设置为nil。 __strong typeof(weakSelf) strongSelf = weakSelf; [strongSelf timerFiredFun];} repeats:YES]; 上述解决方案使用了NSTimer+BlockSupported分类对NSTimer原生函数进行了二次封装，将调用方需要的执行的函数转移到block中执行，再结合__weak指针解除NSTimer对self的强引用。NSTimer原生API调用照样会对target强引用，但是此时的target变成Timer类对象。因为类对象生命周期与应用程序一置的，不受引用计数限制，所以没关系。 这种类型的“保留环”问题很隐蔽，因此很有分析与记录价值，与君共享。 GitHub Demo 注：这个解决方案参考了Effective Objective-C 2.0一书中第52条，有兴趣的同学可以自行查阅。","link":"/2017/02/12/%E8%A7%A3%E9%99%A4NSTimer%E6%BD%9C%E5%9C%A8%E7%9A%84%E2%80%9C%E4%BF%9D%E7%95%99%E7%8E%AF%E2%80%9D%E9%97%AE%E9%A2%98/"},{"title":"计算机中几个与时间相关的概念","text":"世界标准时时间与人类的生活息息相关，可时间本身是连续的且不存在刻度，因此，人类引入了世界标准时的概念用以统一时间计量。度量时间意味着需要将时间转换成离散的，即使用计量单位表示时间。不同的标准时使用的度量标准不同：即对计量单位的定义标准不同。 以下是关于计量单位秒的两种定义标准，分别是： 根据地球自转和公转 地球自转，且围绕太阳公转。根据相对运动的原理，以地球为参照物时，太阳是围绕地球运动的。因此，把太阳连续两次穿过地球表面某一个定点的经线（子午线）所需的时间定为一天，即24个小时，换算可得到秒的时长。 比如格林尼治时间（Greenwich Mean Time，GMT）将太阳两次横穿格林尼治子午线所需的时长定为一天。 这种定义标准显然更符合人类习惯，但是由于地球公转轨迹是一个椭圆，意味着地球公转速度是不均匀的，且地球自转的速度正在缓慢减速，换言之，GMT时间在缓慢地变长。因此，GMT时间不再作为标准时间，取而代之的是UTC时间。 采用原子时秒 原子时秒，由原子钟导出，简言之，是以铯-133的振荡频率来定义秒。由于GMT时间存在不均匀性和低精度性，自1867年起，世界标准时改用原子时作为基本的时间计量系统。 协调世界时（Universal Time Coordinated，UTC），就是采用的这种定义标准。 定义秒这一计量单位后，向下可以进一步细分为毫秒、微妙和纳秒等，向上则可以组合成分钟、小时、日、月和年等概念。 几个与时间相关的概念由于时间就像是一条没有起点和终点的直线，除了给出计量单位，比如秒，还需要一个基准点（epoch）作为度量的起始参考点。 以下是计算机系统中的几个与时间相关的概念，它们采用的基准点也不尽相同。 系统时钟 计算机系统中一般都存在两种系统时钟，二者的区别在于采用的基准点不同，分别是： 以系统启动时刻为基准点 我们常说的系统时钟就是指以系统启动时刻为基准点的计时系统。顾名思义，这种系统时钟的从系统启动的那一刻从零开始计时。 这种系统时钟的好处在于它是独立的，即不需要与其他系统进行时间同步。因为在通信的过程中，我们大多数时候关注的是相对时间的概念，因此使用这种系统时间即可。 以下的Mac系统中获取系统时间的两种方式： Mac系统独有的函数 1234567891011121314151617int64_t GetMacSystemTimeInNanos { static mach_timebase_info_data_t timebase; if (timebase.denom == 0) { // Get the timebase if this is the first we run. // Recommond by Apple's QA1398 assert(mach_timebase_info(&amp;timebase) == KERN_SUCCESS &amp;&amp; \"Not Reached.\"); } // Use timebase to convert absolute time tick uints into nanoseconds const auto mul = [](uint64_t a, uint32_t b) -&gt; int64_t { assert(b != 0); assert(a &lt;= std::numeric_limits&lt;int64_t&gt;::max() / b); return utils::numeric::checked_static_cast&lt;int64_t&gt;(a * b); }; // mach_absolute_time is a CPU/Bus dependent function that // returns a value based on the number of 'ticks' since the system started up. return mul(mach_absolute_time(), timebase.numer) / timebase.denom;} 兼容POSIX系统 123456789constexpr int64_t kNumNanosecsPerSec = 1'000'000'000;int64_t GetPosixSystemTimeInNanos { int64_t ticks = -1; struct timespec ts; // CLOCK_MONOTONIC: returns a value based on the number of 'ticks' since the system started up, independently. clock_gettime(CLOCK_MONOTONIC, &amp;ts); return static_cast&lt;int64_t&gt;(ts.tv_sec) * kNumNanosecsPerSec + static_cast&lt;int64_t&gt;(ts.tv_nsec);} Linux/Unix epoch 在中Linux/Unix系统使用的系统时间称之为POSIX time，其采用的时间基准点是1970年1月1日0点0分0秒（UTC）。即POSIX time表示的是自UTC 1970年1月1日0点0分0秒以来经过的秒数，包括小数秒，但忽略润秒。 以下是两种获取POSIX time的方式： 调用gettimeofday函数 123456int64_t GetUTCTimeInMicros() { struct timeval time; gettimeofday(&amp;time, nullptr); // Convert from second (1.0) and microsecond (1e-6). return static_cast&lt;int64_t&gt;(time.tv_sec) * kNumMicrosecsPerSec + time.tv_usec;} 调用clock_gettime函数 12345678constexpr int64_t kNumNanosecsPerSec = 1'000'000'000; GetUTCTimeInNanos() { struct timespec ts; // Use CLOCK_REALTIME_COARSE is faster. clock_gettime(CLOCK_REALTIME, &amp;ts); return static_cast&lt;int64_t&gt;(ts.tv_sec) * kNumNanosecsPerSec + static_cast&lt;int64_t&gt;(ts.tv_nsec);} 建议使用第一种方式，原因在于gettimeofday调用使用的是vsyscall，即不需要经过内核进程切换即可直接读取已预设好的系统时间，没有线程切换的开销，效率更高，其实现原理是： 系统内核在每次调用时间中断时会把当前的系统时间写在某个固定的位置，然后通过mmap机制映射到用户空间，调用该函数时只需在用户空间读取对应位置的数值即可，不涉及线程切换。 NOTE：关于vsyscall的实现原理： 传统的系统调用方式是通过INT 0x80中断/SYSTEMCALL，这种方式会造成内核空间和用户空间的上下文切换，因此效率较低。为此，Intel和AMD两家芯片巨头分别实现了sysenter/sysexit 和 syscall/ sysret，即快速系统调用指令。为了解决硬件层面的兼容问题，Linux实现了vsyscall机制，软件层面统一调用vsyscall来加速系统调用。 vsyscall是一种用于加速特定系统调用的一种机制，以减少系统调用的开销，适用于一些触发频繁且进行只读操作的系统调用。比如获取系统时间，这个系统调用并不会向内核提供参数，而仅是从内核中读取数据。 相较之下，clock_gettime的本身的执行就很耗时，其实现原理是： 直接进入内核空间读时钟设备的内存映射，加之用户空间和内存空间切换等操作，效率很低。但如果clock_gettime第一个参数使用CLOCK_REALTIME_COARSE，即获取一个粗略的系统时间，则比较高效。 NTP 网络时间协议（Network Time Protocol ，NTP），是一种用于同步同一网络下不同计算机系统的时钟的网络协议，采用分组交换的方式实现。NTP采用Marzullo算法来选择准确的时间服务器，旨在将同一网络下所有的计算机的UTC时间同步到几毫米的误差内。比如，NTP可以将互联网内的时间误差维持下几十毫秒以下，局域网内的时间误差维持下1毫秒左右。但是，不对称路由和拥塞控制可能导致超过100毫秒的误差。 NTP的时间基准点是：1900年1月1日0点0分0秒（UTC）。 NTP的格式如下所示，共64 bits，包括两个秒和小数秒两个部分，各32 bits： 1234567// NTPTimestruct NTPTime { uint32_t seconds; // 秒，32 bits uint32_t fractions; // 小数秒，32 bits}// NTP中秒和小数秒的转换关系：1秒 = 2^32小数秒constexpr uint64_t kFractionsPerSecond = 0x100000000; // 2^32 时间转换 系统时间转UTC时间 此处的系统时间是指以系统启动时间为基准点的计时系统，下同。把时间比喻成一条直线，UTC时间的起点的1970年1月1日0点0分0秒，而系统时间则是系统启动时间。因此，任一时刻的UTC时间减去同一时刻的系统时间即为二者的差值，且这个差值在当前系统关闭之前都是相同的，即为定值。以下是二者转换的伪代码： 1234// 计算一次即可，因此可设为常量const int64_t utc_and_system_time_diff = curr_utc_time - curr_system_time;// 任一时刻系统时间转换成UTC时间int64_t utc_time_x = system_time_x + utc_and_system_time_diff; UTC时间转NTP时间 UTC时间和NTP时间除了基准点不同之外，二者表示时间的格式也不同。以下是转换代码： 12345678910111213// 从UTC时间基准点（1970年1月1日0点0分0秒）到NTP时间基准点（1900年1月1日0点0分0秒）// 之间的间隔的秒数constexpr uint32_t kNtpJan1970Sec = 2'208'988'800UL;// 秒转微秒constexpr int64_t kNumMicrosecsPerSec = 1'000'000;// UTC时间转NTP时间，时间单位为微秒int64_t ntp_time_us = utp_time_us + kNtpJan1970Sec * kNumMicrosecsPerSec;// NTP格式转换NTPTime ntp_time;// Convert seconds to uint32 through uint64 for a well-defined cast.ntp_time.seconds = static_cast&lt;uint64_t&gt;(ntp_time_us / kNumMicrosecsPerSec);// A wrap around, which will happen in 2036, is expected for NTP time.ntp_time.fractions = (ntp_time_us % kNumMicrosecsPerSec) * kFractionsPerSecond / kNumMicrosecsPerSec; 系统时间转NTP时间 结合上述两种转换，系统时间转NTP时间的步骤是：系统时间→UTC时间→NTP时间。 参考资料Linux时间子系统之（一）：时间的基本概念 - ArnoldLu - 博客园 網路時間協定 - 维基百科，自由的百科全书 RaymondSQ VDSO与vsyscall_MillionSky的博客-CSDN博客 CMOS 内存和实时时钟_x86ipc的博客-CSDN博客_cmos时钟","link":"/2020/03/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E5%87%A0%E4%B8%AA%E4%B8%8E%E6%97%B6%E9%97%B4%E7%9B%B8%E5%85%B3%E7%9A%84%E6%A6%82%E5%BF%B5/"},{"title":"跳表（skiplist）","text":"简述跳表是一种基于并联的链表，底层是一个普通的有序链表，更高层链表是基于随机方式构建的稀疏子链表，充当下层链表的快速通道，因此链表的长度由低到高层层递减。 跳表的查找、插入和删除操作的平均时间复杂度都为O(logn)，有效地解决有序链表查询效率低下的问题。 注意：跳表的最底层必须是一个有序链表。 实现原理构建一个跳表可分以下4个步骤： 给定一个有序的链表作为底层。 构建上一层链表： 选出当前层中的最大和最小的元素； 从当前层的剩余的元素中按照随机算法选出一定数量n的元素，n+2小于当前层元素个数； 将所有选出的元素组成有序链表，作为当前层的上一层链表； 给新增的链表中的所有元素添加一个指针域，该指针指向下一层中元素的值与自己相等的元素。 重复步骤2，直到当前层的只剩下最大和最小的两个元素为止。 C语言中常使用结构体+可变长数组的结构作为节点，如： 12345typedef struct NodeStructure { int key; int value; struct NodeStructure* forward[1]; // struct hack,可变长数组}Node; 这样做的的好处在于所有层的值相同的节点共享一个节点，通过可变长数组实现不同层的定位。 注：C++由于虚表指针的位置存放在对象的最末端（一般是在对象起始位置，由编译器决定），因此struct hack不适应与C++对象。 基本操作 插入 新建一个数组update，长度为当前跳表的最大层数值。 从高层往下遍历，查找新节点在每一层的插入位置，即新节点在该层的上一个节点，将该节点放入update。 生成一个随机数k用于表示新节点即将插入的层数。如果该值大于当前层数n，则需要更新链跳表。 在更高层新建k-n层，并将新建层的头指针指向跳表头指针。 更新跳表的层数为k。 基于k值，逐层插入新节点，与普通链表插入操作一样。 删除 删除操作与插入操作的前两步一样，使用update数组记录删除的位置，然后逐层删除目标节点。 不同之处在于，如果目标节点是当前层的最大值，则需要更新跳表的层数。 查询 从高层往下查找，逐层遍历。 在该层找到值小于或等于目标节点的节点： 如果当前节点的值等于目标节点，则查找完成。 否则，从当前节点进入下一层，继续向后查找。 否则进入下一层遍历。 复杂度分析跳表是按层构造的，底层是一个有序链表，而更高层是按某个固定的概率p从下一层选取元素，换言之下一层的元素个数是上一层的1/p倍。 时间复杂度 跳表的时间复杂度取决于跳表的层数，跳表的层数为log(1/p)^n。且p是常数，所以跳表的查询、插入和删除操作的平均时间复杂度为O(logn)，最坏情况是退化为链表的复杂度O(n)。 空间复杂度 假设底层链表的元素个数为n，那么第i级索引的个数为n/(p^i)。跳表所有节点的总和是：∑ = n + n/(p^1) + n/(p^2) + n/(p^3) + … + 1，又因为p是常数，所以跳表的平均空间复杂度为O(n)。 最坏情况是每一层都与底层链表的元素个数相同，此时空间复杂度为O(nlogn)。 对比平衡树跳表的出现是为了解决有序链表查询效率低下的问题，而平衡树的发明也同样是为了解决有序链表的查询瓶颈。常用的平衡树有AVL树和红黑树。 跳表在查询、插入和删除操作的时间复杂度上能与AVL树和红黑树媲美。相较于平衡树通过复杂的旋转操作为维持平衡，跳表采用的是以空间换时间的方式，因此在实现上比平衡树更为简单。redis就是选择跳表作为底层存储结构。 参考资料跳跃列表 - 维基百科，自由的百科全书 Skip List（跳跃表）原理详解与实现 - One thing I know,that is I know nothing.(Socrates Greek) - ITeye博客 跳表(SkipList)原理篇 为啥 redis 使用跳表(skiplist)而不是使用 red-black？","link":"/2019/09/01/%E8%B7%B3%E8%A1%A8%EF%BC%88skiplist%EF%BC%89/"},{"title":"还房贷最省钱的理财方法","text":"最近看了紫竹张先生的一篇名为还贷款最省钱的理财方法的文章，里面讲述的经济学知识与我们日常生活息息相关，却又是最容易被忽视和误解的部分。在一口气看了两遍感觉收获不小之后，觉得很有必要总结一下，作为备忘。 最省钱的还贷方式在国内最常见的还贷方式有两种，分别是等额本金和等额本息： 等额本金的月供是由每个月固定的还款本金数额加上当前未还款总额的利息组成。这种还款方式的特点是前期月供数额较大，后面随着未还总额的减少，利息也越来越少。 等额本息采用浮动本金还款，结合贷款年限计算出每个月还款的平均数。特点是每个月的还款金额几乎一样，前期月供中利息占的比重较大，后期的月供则主要是本金。 结合上述两种还贷方式的特点容易产生一种误解，即大家会认为等额本息前期还的都是利息，有一种被银行剥削的感觉，因此倾向于提前还款，能还多少还多少。假如前面三五年没能提前还款，后面再提前还款就没有意义了，因为该交的利息都已经交了。这种观点表面上很有说服力，但仔细想想是完全错误的。 记住两个前提，一是等额本金和等额本息使用的利率都是一样的，二是银行房贷的利率较于其他大多数的贷款利率都低且贷款额度更大和年限更长。然后，我们分别从银行和个人的角度来分析。首先，从银行的角度来说，银行借出去多少钱就应该收多少利息，而收取利息的基数就是你尚未还清的贷款总额，也就是说你当前欠银行的钱越多就应该支付越多的利息。因此，从这个角度来说等额本金和等额本息对银行来说没有熟好熟劣的差别。等额本金因为前期还给银行的本金较多导致后期利息减少，但是银行可以用你还的这些本金继续贷款给其他人获取利息甚至是更高的利息。再者，从个人的角度来说，你欠银行多少钱就应该付多少利息。假设在经济能力允许且你口袋里的钱没办法获得一个高于贷款利率的收入，那么选择等额本金还贷从某个角度来说也算是一种理财方式。但是如果你手中的钱能够创造更高的收益，那么使用等额本金的方式就不一定是个好选择了。但是更多的人属于后者，在支付首付之后是储蓄大幅下降，所以会选择等额本息的方法以减缓经济压力。此外如果使用其他的贷款方式所需要支付的利息会更高。既然我们没有足够的钱来偿还贷款也就没有理由抱怨银行收取利息了。因此，在个人经济能力有限的前提下，选择等额本息对个人来说是最划算的。 此外，我们从银行贷款的利率只是名义上的利率，而非实际利率。原因在于中国未来都将处于不断通货膨胀的趋势，意味着人民币也不断在贬值。因此，你的实际利率等于名义上的履历扣除通货膨胀率，结果是实际利率值变成一个很低的值。接下来解释为什么说未来中国的通货膨胀会一直继续下去。 众所周知，过去的三十多年，中国通过改革开放实现从计划经济向市场化经济的转变，并且加入了WTO（世界贸易组织）。随着世界各国的经济全球化，中国的经济的决定权已经不在中国政府手上。当前全球经济根基的经济学理论源自于美国，该西方经济理论体系认为： 适当的通货膨胀有助于经济发展，能够刺激生产和增加投资。人民倾向于花出手中的现金购买其他保值资产从而刺激了消费和生产，以及提供了更多的就业岗位。而通货紧缩则恰恰相反，人民倾向于存储现金以便提高未来的购买力。 当政府出现财政危机且需要增加财政收入时，一般会采取三种方式：一是增加税收；二是向公众借债；三是增加货币供应。前两种方式在政治上不得人心，所以一般都采取第三种方式。 政府不应该任由经济危机发生，政府有义务通过量化宽松（间接增印钞票）的方式来“熨平”经济波动，避免社会出现动荡，即便代价是通货膨胀。 这种理论体系在西方大行其道，直接导致布雷顿森林货币体系的崩溃，美元和黄金脱钩，从此美元不断通货膨胀，全球货币也随之一路贬值，人民币自然不能独善其身。 有一个典型的通货膨胀的例子是：在1989年北京房价在1600-1900，当时的大学生工资是89元左右，每个月节衣缩食可以攒下50元。假设当时你倾其所有凑够首付，按月供60进行还贷款，等额本息三十年，到了2019年刚好还完。然而，当年你每个月要还的“巨款”60元，现在只能买一个披萨。 结合上述内容，最划算的贷款方式是使用等额本息的方式贷款最大金额，分三十年（最长还款年限）还款。此外，即便后面有了一定的储蓄也不要提前还款。原因在于流动资金具有一定的溢价效应。虽然某些现金类的理财产品收益率可能不如房地产投资，但是我们在投资房地产之余一定要配置一定比例的现金资产。因为固定资产的流动性很差，变现速度慢，而现金类产品能在你急性用钱的时候快速变现，以解燃眉之急。 最后一个建议是不要让你的公积金账户有闲置的资金。公积金有一个特性，除了还房贷之外很难提现，而且存款利率极低。如果你的公积金除了还房贷之外还有剩余，那么这些存款就是没有流动性的死款，存款越多亏的越多。结果就是名义上里面的钱是你的钱，实际上你却没有支配权。","link":"/2018/08/21/%E8%BF%98%E6%88%BF%E8%B4%B7%E6%9C%80%E7%9C%81%E9%92%B1%E7%9A%84%E7%90%86%E8%B4%A2%E6%96%B9%E6%B3%95/"},{"title":"阅读的意义","text":"阅读的意义是什么？这是我一直在思索的问题，也一直在寻找满意的答案。我觉得让我从厌恶读书变得有点喜欢读书的过程中，有两个关于读书意义的比喻对我影响很深。 比喻一来源于一个故事：祖孙二人居住在山区庄园里，爷爷每天清晨都坚持读书，孙子受爷爷的影响，也尽自己最大的能力阅读书籍。有一天，他问爷爷：“我也每天读书，可我不能真正地理解它，那读书有什么用呢？”爷爷拿来一个装煤的竹篮，让孙子去打水，一趟，两趟，三趟……孙子以最快的速度跑回家，可竹篮总是空空如也。“竹篮是不能打到水的！”孙子说，可爷爷让他仔细看看篮子：原来黑乎乎、脏兮兮的竹篮变得洁净如新了。“孩子，阅读好书也是如此。”爷爷语重心长地说：“你可能无法完全理解它，也记不住多少内容，但只要你用心阅读它，它就会在不知不觉中净化了你的心灵。”是的，竹篮是打不来水的，但并不是一无收获，什么都没有留下来，一次次的打水，让竹篮一次次浸到水里，使竹篮一次比一次变干净了。读书其实也和竹篮打水一样，留不住其形，却留得住其神，知识不可能让我们吃饱穿暖，但它可以让我们的心灵变得宁静明洁，不会浮燥，天长日久可让人的灵魂得到净化。 比喻二是北大教授陈原平教授的一段话：如果你半夜醒来发现自己已经好长时间没有读书，而且没有任何负罪感的时候，你就必须知道，你已经堕落了。不是说书本本身特了不起，而是读书这个行为意味着你没有完全认同这个现世和现实，你还有追求，还在奋斗，你还有不满，你还在寻找另外一种可能性，另一种生活方式。 我一直坚信读书多的人能在这世上活得更明白，看得更全面，减少因信息不对称带来的无知与愚昧。","link":"/2017/05/14/%E9%98%85%E8%AF%BB%E7%9A%84%E6%84%8F%E4%B9%89/"},{"title":"需求第一定律","text":"注：本文属于《薛兆丰经济学讲义》第28讲的读书笔记 人总是善于根据代价的高低而灵活应变–对人性深刻而基本的刻画 需求第一定律的定义是：当其他情况不变时，只要价格提高，商品的需求量就会减少；价格降到一定程度，需求量就会增加。 需求曲线 基于其他条件不变的前提，需求曲线是一条斜率不变的减函数，随着价格（自变量）的增大，需求量（因变量）递减。 当存在价格之外的其他任何因素发生变化时，整条需求曲线发生变动和转动，但是仍然是一个减函数。 很多时候我们容易被一些社会想象误导，误以为需求曲线在某些情况下是增函数的。比如股市出现追涨杀跌，其实是因为股票的盈利能力变了。存在这种误解是忽视了需求定律中“其他条件不变”的前提。在人性不变得前提下，价格越高，需求将越低。此外，需求不等同与需求量，一个人对某个商品的需求是不会随着价格变动而出现变化的。 供应曲线 在需求曲线中，当价格上升到一定程度会出现负需求，也就是供给。换言之，需求和供给完全取决于市场价格。当价格足够高时，原本属于需求者的一部分会变成供给者。 交易剩余 需求曲线上的任何一点都代表一个人对某个商品的在这个单位上的个人估值，即为了获得这个单位的服务愿意付出的最大代价。 但是，一个人对某个商品的估值与他最终得到这个商品所付出的代价之间往往存在着差距，这个差距就是“剩余”。同理，商品生产者也享受“剩余”，厂商对一个商品的估值与商品的市场价格之间的差距。因此这种剩余更合理的名称应该是“交易剩余”。 思考题 我们讲，凡是交易就有剩余，有剩余，买卖双方都皆大欢喜。但如果是这样的话，为什么世界上许多国家都有所谓的价格法，专门打击商人定价过高的行为呢？ 我的理解：虽然存在交易，买卖双方就都能享受剩余。但是卖家和买家享受的剩余来源不同，或者说是相斥的。卖家享受的剩余=商品交易价格-卖家对商品的估值，因此商品的成交价格越高，卖家享受的剩余就越大。反观，买家享受的剩余=买家对商品的估值-商品的交易价格，即商品的成交价越高，买家享受的剩余就越小。根据需求曲线，价格越高，需求量越低。如果卖家对商品的定价过高，需求者可能会转变成供给者，整个市场会出现供大于求的现象。因此，为了保护消费者的权益以及维护市场供需平衡，需要通过法律手段来制衡商家定价过高的行为。","link":"/2018/11/11/%E9%9C%80%E6%B1%82%E7%AC%AC%E4%B8%80%E5%AE%9A%E5%BE%8B/"},{"title":"需求第三定律","text":"需求第三定律的含义：每当消费者必须支付一笔附近费时，高品质的产品相对低品质的产品就变得便宜了。这笔附加费越高，高品质产品相对就越便宜。因此，这个定律又叫“好东西运到远方去定律”。 附加成本大，精选品才值得 当人们不得不支付一笔巨大的附加费时，就只有精选品才值得人们去运送、去提供，才值得人们享受。 附加成本上升并非好事 当附加成本上升，精选品就显得便宜，那么是否附加成本越高越好？ 以中国出口香烟为例，如果进口国家对香烟实施配额制，每包香烟多付5元的附加费。那么这时只有较贵的香烟才值得出口。这样出口的香烟种类就减少了，国外消费者的选择也相应的少了。因此，虽然出口商品的平均质量提高了，但是出口商品的品种少了。国外的消费者和出口国生产商都蒙受了损失。","link":"/2018/11/14/%E9%9C%80%E6%B1%82%E7%AC%AC%E4%B8%89%E5%AE%9A%E5%BE%8B/"},{"title":"需求第二定律","text":"理解了需求第二定律，就可以更懂人与人之间互相作用、互相博弈的规律 需求第二定律的定义：需求对价格的弹性，和价格变化之后流逝的时间长度成正比。换言之，随着时间的推移，需求对价格的弹性会增加。 需求对价格的弹性 需求对价格的弹性，就是需求量随着价格变动而变动的程度。它等于需求量的变化比例除以价格的变化比例。注：由于需求曲线是减函数，所以弹性永远都是负数。一般讲弹性都是指绝对值。 奢侈品：弹性&gt;1.0，需求量的变化幅度大于价格的变化幅度的物品属于奢侈品必需品：弹性&lt;1.0，需求量的变化幅度小于价格的变化幅度的物品属于必需品 弹性不等同于斜率，其他条件不变的前提下，需求函数的斜率为1。而弹性是渐变的。 由于需求曲线中，价格是自变量，因此一件商品是奢侈品还是必需品完全取决于价格。 寻找替代方案 现实生活中是否存在一种商品，无论价格多高，它的需求量都是不变的。那么这种商品的需求曲线是一条垂直于需求量的直线。 但是实际情况下是不存在的，人们一定会找到替代方案，整个人类历史就是一个不断寻找替代方案的历史。以食用盐为例，当盐的价格高到一定程度，人们就会想办法寻找替代方案，包括最终生病或死亡都属于替代方案。 正如需求第二定律所说，随着时间推移，需求对价格的弹性就越大，也就是寻找到的替代方案就越多，应变的空间也越来越大。 商品的税负问题 一件商品的税负由用买卖双方共同承担的，正确的答案由两句话组成：税负是双方共同承担的；双方各付多少，取决于需求者和供应者双方的相对弹性，谁的弹性低，谁对这份交易的需求更迫切，谁就付得多一点。 注：买家对应于需求曲线，而卖家对应于供应曲线。 情况一：在买卖双方对商品的弹性是一致的时候，各自均摊税负。如下图所示： 图中的平衡点N是需求曲线D与供应曲线S的相交点，表示在没有对商品征税的情况下，需求量和价格分别为q0、p0。对商品征税后，买家付出的价格从p0上涨到pd，卖家收到的价格从p0下降到ps，商品的需求量从q0下降到q1。面积A+B恰好等于税收。 情况二：买家的对交易更为迫切，对商品的弹性较低，即需求曲线的较为陡峭，而供应曲线相对平缓。 由图可知，这种情况下，买家承担的税负更高。 情况三：卖的对交易更为迫切，对商品的弹性较低，即供应曲线的较为陡峭，而需求曲线相对平缓。 由图可知，这种情况下，卖家承担的税负更高。 推广： 1、有人说房价太高，建议政府通过收取很高的房产交易税来压低房价，这种想法完全是错误的。重税只会增加买卖双方的负担，而且如果是买房者是刚需，则会承担大部分的税负。 2、不管是法律是否规定了雇主付养老保险还是雇员付养老保险，最后双方的分担都取决于雇主和雇员谁的弹性更大，谁的谈判能力就越高，承担的负担比例就相对小。","link":"/2018/11/13/%E9%9C%80%E6%B1%82%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B/"},{"title":"Effective Objective-C 2.0 学习笔记","text":"这篇文章是在阅读《Effective Objective_C》一书时的学习笔记，这本书对Objective-C语言的特性进行有深入浅出的分析和讲解，让我受益匪浅。 第1章 熟悉Objective-C1: 了解Objective-C语言的起源 Objective-C语言是由Smalltalk演化而来，后者是消息型语言的鼻祖。 消息机构的语言，不论是否多态，其运行时所执行的代码都由运行环境来决定；而使用函数调用的语言则由编译器决定，但调用函数是多态的，则是在运行时通过查询“虚方法表（virtual table）”决定具体执行函数。 如果只需要保存int、flot、double、char等非对象类型，通常使用CGRect这种结构体，因为结构体可以使用栈空间，而不用分配和释放堆空间，避免额外开销。 2: 在类的头文件中尽量少引用其他头文件 除非确实有必要，否则不要引入头文件，尽量使用向前声明，这样不但可以缩短编译时间和降低类之间的耦合。 如果无法使用向前声明，比如要声明某个类遵循一项协议。尽量把所遵循的协议移至实现文件中的匿名分类。如果必须在头文件引入协议头文件，则把协议单独放在一个头文件中。 3: 多用字面量语法，少用与之对等的方法 使用字面量语法创建字符串、数值、数组、字典更为简单扼要。 使用取下标操作访问数组下标或者字典中的键对应的元素。 使用字面量语言更为安全，遇到nil对象会抛出异常。 字面量语法的限制：除了字符串以外，所创建出来的对象必须属于Foundation框架才行。 4: 多用类型常量，少用#define预处理指令 若常量局限于某个实现文件之内，则前面加字面k，若常量在类之外，则通常以类名为前缀。 static修饰符意味着变量仅在定义此变量的编译单元中可见，在Objective-C的语境下，编译单元通常指每个类的实现文件，即以.m为后缀名。 常量必须使用const修饰符声明，常量定义从右至左解读，下面例子中定义了一个常量指针，const修饰的是指针，指向NSString对象。12extern NSString *const ECOStringConstant;NSString *const ECOStringConstant = @\"VALUE\"; 如果一个变量同时声明为static和const,那么编译器根本不会创建符号，而是会像#define预处理指令一样，把所有遇到的变量都替换为常值。 在头文件中使用extern来声明全局常量，并在相关实现文件中定义其值。这种常量要出现在全局符号中，因此通常与之相关的类名做前缀加以区分。 5：用枚举表示状态、选项、状态码 C++11标准修订了枚举的某些特性，其中包括可以指定何种“底层数据类型”来保存枚举类型的变量。这样做的好处是可以向前声明枚举变量了，如果编译器不清楚底层数据类型就不知道分配空间大小。 如果枚举类型是多个选项且同时使用，那么久将各选项值定义为2的幂，以便按位或操作进行组合。 用NS_ENUM与NS_OPTION宏来定义枚举类型，并指明其底层数据类型，这样确保枚举是用开发者所选的底层数据类型实现出来的，而不会采用编译器所选的类型。 在处理枚举类型的switch语句中不要实现default分析，这样加入新的枚举之后，编译器就会提示开发者：switch语句并未处理所有枚举。 第2章 对象、消息、运行期第6条： 理解“属性”这一概念 使用@property语法编译器会自动创建一套存取方法，因此访问属性实质上就是调用存取函数，走消息派发流程。 @synthesize语言可以指定属性实例变量的名字，默认的属性名前加下划线。 @dynamic关键字可以阻止属性创建实例变量和存取方式，编译器即使在编译过程中没有发现该属性的存取方法也不会保存，而是相信这些方法在运行期能够找到。 原子性只能确保每次都能获取属性的有效值，即确保属性修改完成再被其他线程访问，但是不能确保线程安全。 处于性能考虑，iOS程序所有属性都是nonatomic，Mac OS X程序使用atomic属性通常不会有性能瓶颈。 对应一个属性定义的变量来说，直接访问实例变量会绕开指定的属性特质和消息派发流程。 第7条：在对象内部尽量直接访问实例变量 使用“点语法”（本质上使用实例变量存取方法）与直接访问实例变量的区别： 直接访问实例变量不经过Objective-C的消息派发流程，因此速度比点语法快。 直接访问实例变量不会调用属性配置的存取方法，从而绕过了属性指定的相关特质。 直接访问实例变量不会触发“键值观测KVO”通知，因为键值观测是建立在存取方法之上的。 在初始化方法和dealloc中尽量直接访问实例变量，因为子类可能覆写父类属性的存取方法，从而无法输出预期。 在对象内部读取数据时，应该直接通过实例变量来读，除惰性初始化技术之外。而写入数据时则应通过属性来写。 第8条：理解“对象等同性”这一概念 检测对象的等同性，必须提供“isEqual:”和hash方法。相等的对象hash值必须相同，但是has值相同的对象未必相等。 计算hash值时应考虑减少碰撞。因为collection检索哈希表时会用对象的哈希值作为索引。hash方法的高效与低碰撞率可以使collection减少开销。 等同性判定的执行深度根据具体的对象决定，不一定将整个对象进行判定，有时候只需要判定代表对象唯一性的值即可。 在容器中放入可变类对象时，确保对象加入后就不再改变哈希值，否则容易造成未知行为。 第9条：以“类簇模式”隐藏实现细节 类簇模式可以把实现细节隐藏在一套简单的公共接口后面。 系统框架中经常使用类簇，比如NSArray、NSNumber等。 从类簇的公共抽象基类中继承子类时，遵循几条规则： 子类应该继承自类簇中的抽象基类。 子类应该定义自己的数据存储方式。 子类应当覆写超类文档中指明需要覆写的方法。 第10条：在既有类中使用关联对象存放自定义数据 使用关联对象可以将两个对象以属性的方式关联起来，并指定类似于@property的内存管理语义和存储策略。 设置关联对象的键值是个“不透明指针”，若想令两个键值匹配到同一个值，二者必须是完全相同的指针才行。鉴于此，设置关联对象值时通常使用静态全局变量做键值。 由于关联对象容易引入难于排查的bug，所以不要轻易使用。 第11条：理解objc_msgSend的作用 objc_msgSend通过在运行期搜索接收者类的方法列表实现“动态绑定”，以选择子为key值搜索函数指针。 函数原型与objc_msgSend函数很像，在objc_msgSend函数内部搜索到选择子对应的函数并在函数最后return语句调用，利用“尾调用优化”进行优化。 第12条：理解消息转发机制 消息转发分两大阶段：动态方法解析和完整的消息转发机制（分两阶段） 动态方法解析：实例对象收到无法解析的消息会触发类方法：+（BOOL）resolveInstanceMethod:(SEL)selector，如果是类对象对应的类方法为：+（BOOL）resolveClassMethod:(SEL)selector。在这个方法中可以通过class_addMethod动态插入方法，所添加的方法是用纯C函数（IMP指针）。 完整的消息转发机制第一阶段：调用函数-(id)forwardingTargetForSelector:(SEL)selector，看是否能把消息转发其他对象处理。通过此方案可以用“组合”来模拟”多重继承“的某些特性。 完整的消息转发机制第二阶段：- (void)forwardInvocation:(NSInvocation *)invocation;此阶段可以在转发消息前修改消息内容。若本类不处理，则需调用父类同名方法。 ###第4章 协议与分类 23：通过委托与数据源协议进行对象间通信 委托模式为对象提供了一套接口，使其可由此将相关事件告知其他对象 当某对象需要从另外一个对象中获得数据时，可以使用委托模式【数据源协议】。 若有必要，可实现含有位段的结构体，将委托对象是否能响应相关协议方法这一信息缓存至其中。 24：将类的实现代码分散到便于管理的数个分类之中 使用分类机制将类的实现代码划分成易于管理的小块 将应该视为“私有”的方法归入名叫private的分类中，以隐藏实现细节。 25：总是为第三方类的分类名称加前缀 分类机制通常用于向无源代码的既有类中增加新功能，且分类中的方法会覆盖既有类的同名方法，后一个分类会覆盖前一个分类的同名方法。 为了减少同名函数覆盖的概率，以命名空间来区分各个分类的名称与其中所定义的方法，在Objective-C中实现命名空间的方法就是给分类名和函数名添加专用的前缀。 26：勿在分类中声明属性 属性是封装数据的方式，尽管可以通过关联对象的方式合成实例变量，但是建议最好全部在主接口中实现，分类的作用在于扩展类的功能，而非封装数据 除了“class-continuation分类【匿名分类】”之外可以定义属性，其他分类最好只定义方法 27：使用“class-continuation分类”隐藏实现细节 匿名分类可以定义方法和实例变量，原因在于“稳固的ABI”机制（详见第6条） 在实现块中添加匿名分类可隐藏实现细节，即私有变量和方法。 编译objective-C++时，在匿名分类中定义c++相关的变量，从而避免了因为在头文件中声明C++变量，进而导致凡是引用该类的其他类都必须改为Objective-C++类。 利用匿名分类扩展头文件中声明为“只读”的属性为“可读写”状态 利用匿名分类隐藏该类遵循的协议。 28：通过协议提供匿名对象 使用协议可将具体的对象类型谈化成遵循某种协议的id类型，协议中规定了对象需实现的方法 如果对象类型不重要，重要的是对象是否实现了某些方法，此时可用“匿名对象”来实现这一概念，与Python的“鸭子类型”有点相似。 ###第5章 内存管理 第29条：理解引用计数 悬挂指针：对象在release之后，内存被放回“可用内存池”，但是不一定保证马上被回收，此时指针属于悬挂指针，容易导致crash。 为了避免不经意间使用了悬挂指针，在调用完release之后清空指针 autorelease能延长对象生命周期，使其在跨越方法调用边界后依然跨越存活一段时间，释放操作会在清空最外层自动释放池时执行，即在当前线程进入下一次事件循环时释放。 通常采用“弱引用”来避免循环引用发生，从而避免内存泄漏 第30条：以ARC简化引用计数 Clang的静态分析器（static analyzer）不但可以指明程序中引用计数出现问题的地方，还能根据需要预先加入适当的retain和release操作以避免这些问题。自动引用计（ARC）数的思路也是源于此。 ARC在执行retain、release和autorelease等操作时，不是通过普通的Objective-C消息派送机制，而是直接调用其对应的C语言版本，这样效率更高。 ARC通过命名约定将内存管理标准化，方法名以下列词语开头，其返回的对象归调用者所有： alloc new copy mutableCopy 否则，返回对象会自动释放，即相当于执行autorelease操作. 在编译期和运行期，ARC都把能够相互抵消的retain、release、autorelease操作约简。 运行期，为了优化代码，在方法返回自动释放的对象时，调用objc_autoreleaseReturnValue,此函数会检视当前函数调用的代码是否需要对返回对象执行retain操作，如果是则设置一个全局标志位。而不执行autorelease操作；与只对应的是在调用代码如果要保留对象，则不执行retain操作，而是调用objc_retainAutoreleasedRetuenValue.此函数检测之前设置的全局标志位，如果已经置位，则不执行retain操作。 ARC环境优化方式具体实现由编译器决定，比如将全局标志位存储在STL(Thread Local Storage:线程局部存储，以key-value的形式读写)中，STL只适用于调用和被调用方都是ARC模式的情况，使用__builtin_return_address可以在被调用函数中获得调用函数的栈空间，进而可以推算出调用方后续操作是否调用了objc_retainAutoreleasedReturnValue，如果调用则是ARC环境，反之使用没优化的老逻辑。 变量的内存管理的边界问题，在设置变量值时，需要先保留新值，释放旧值，最后设置实例变量，确保即便是新值与旧值是同一对象也不能引发错误。在ARC情况下，无需考虑这种“边界情况” ARC下清理实例变量是借用Objective-C++的析构函数实现的，不需要重载dealloc，如果存在CoreFoundation等非Objective-C对象时，只需在dealloc函数中执行CFRetain/CFRelease等释放操作，而不需要调用超类的dealloc方法。 第31条：合理使用dealloc方法 在dealloc中只释放对其他对象的引用，解除监听和取消订阅的KVO等，不要做其他事情 不要在dealloc中释放开销大或系统内稀缺资源，如文件描述符、套接字以及大块内存等，因为这些资源可能被其他对象持有，不宜保留过长时间，而是实现一个专门用于清理的函数，如close等 出于优化效率的目的，系统不能保证每一个对象的dealloc都会执行 不应在dealloc中调用执行异步任务的方法或只能在正常状态下执行的方法，因为dealloc所在的线程会执行final release。 第32条：编写“异常安全代码”时留意内存管理问题 MRC环境下，在@try中创建的对象应在@finaly中释放而非@try中，以避免因抛出异常导致内存泄漏 ARC环境下，出于对运行期的性能考虑默认情况下是不会处理异常捕获过程中出现的内存泄漏情况。 ARC环境下，可以通过-fobjc-arc-exceptions这个编译标志开启安全处理异常功能，默认情况是关闭的，但是出于Objectve-C++模式下会自动打开。 第33条：以弱引用避免保留环 虽然垃圾回收机制可以检测并回收保留环，但是Mac OS X 10.8之后以及iOS平台不支持这个功能 MRC环境下，使用unsafe_unretained（表明属性不安全且不归实例所拥有）或者weak属性来避免保留环，且效果等同 ARC环境下，weak属性在修饰对象被回收后自动清空，更为安全，避免访问悬挂指针。 第34条：以“自动释放池块”降低内存峰值 GCD或主线程都默认自带自动释放池。 自动释放池是以栈的形式存在的，对象收到autorelease消息后，会被放入最近的自动释放池的栈顶。 合理运用自动释放池，用以降低应用程序的内存峰值，如for循环中。 ARC环境下的@autoreleasepool比MRC环境下NSAutoreleasepool更为轻便与安全。 第35条：用“僵尸对象”调试内存管理问题 向已回收的对象发送消息是不安全与不稳当的，如果内存已经被复用且复用的对象不能响应此消息则会crash，如果复用对象能够响应消息也许输出不能达到预期，如果内存部分存活则可能消息可能依然有效。 “僵尸对象”是调试内存管理问题最佳方式。 僵尸类是从名为_NSZombie_的模板类复制而来，通过创建一个名为_NSZombie_原类名的新类，再将已回收对象的指针指向新类，原对象的类变了，但是内存结构不变，便于调试。示例代码： 123456789101112Class cls = object_getClass(self);const char *clsName = class_getName(cls);const char *zombieClsName = \"_NSZombie_\" + clsName;Class zombieCls = objc_lookUpClass(zombieClsName);if (!zombieCls) { class baseZomeCls = objc_lookUpClass(\"_NSZombie_\"); zombieCls = objc_duplicateClass(baseZombieCls, zombieClsName, 0);}//Perform normal destruction of the object being deallocatedobjc_destructInstance(self);//Set the class of the object being deallocated to the zombie classobjc_setClass(self, zombieCls); 代码的关键在于：对象的内存没有释放，因此这块内存不可被其他对象复用，虽然会造成内存泄漏，但是出于调试的目的可以忽略。 僵尸类的作用是通过消息转发机制体现，因为僵尸类没有实现任何方法，和Object一样是根类，只有一个实例变量isa。在消息转发机制通过类名检测到当前对象是一个僵尸对象时会进行特殊处理：打印原类的相关信息，然后终止程序。示例代码： 123456789Class cls = object_getClass(self);const char *clsName = class_getName(cls);//If so, this is a zombieif (string_has_prefix(clsName, \"_NSZombie_\")) { const char *originClsName = substring_from(clsName, 10); const char *selectorName = sel_getName(_cmd)); Log(\"*** - [%s %s]: message sent to deallocated instance %p\" , originalClsName, selectorName, self);} 第36条：不要使用retainCount retainCount返回的保留计数只是某个给定时间点上的值，并未考虑到对象加入自动释放池的情况，因此不能反映真实的保留计数。 有时系统出于优化的目的，retainCount可能永远都不返还0，在保留计数为1的时候就被回收了。 ###第6章 块与大中枢派发 ####第37条 理解“块”这一概念 块在定义与使用方面与函数类似，但是块本身是一个对象，有引用计数。 在块中直接访问实例变量，虽没有显性使用self，但是self变量还是会被块捕获。 块的内存结构中，最重要的是invoke函数指针，指向块的实现代码，第一个void *参数指代块，用于访问块对象所捕获的变量。此外descriptor变量指向结构体指针，每个块里都包含此结构体，其中声明了块对象的总大小和copy与dispose两个辅助函数的指针。 根据内存位置分为全局块、栈块和堆块。 栈块只在定义氛围有效，下述代码存在一个比较隐蔽的错误，存在危险：块的内存都分配在if及else范围内，在离开相应范围后如果编译器覆写了分配给块的内存则会导致crash，否则正常运行。 12345678910111213void (^block)();if (/* some condition */) { block = ^{ NSLog(@\"I am block A\"); };}else { block = ^{ NSLog(@\"I am block B\"); };}//解决方式：将块拷贝到堆中，成为堆块void (^block)();if (/* some condition */) { block = [^{ NSLog(@\"I am block A\"); } copy];}else { block = [^{ NSLog(@\"I am block B\"); } copy];} 在全局范围声明的块及为全局块，其所使用的内存区域也在编译器全部确定。 第38条 为常用的块类型创建typedef 以typedef重新定义块类型，可令块变量用起来更简单 定义新类型时应遵循现有的命名习惯，勿使其名称与别的类型相冲突。 可以为同一个块签名定义多个类型的别名，便于理解类型的用途。 第39条 用handler块降低代码分散程度 异步任务执行完成之后，可使用委托协议或者内联块。相比于委托代理，块更为简洁和聚合。 建议使用同一个块来处理成功与失败的情况。 设计API时如果用的了handler块，可以增加一个参数，使调用者可通过此参数来决定块执行的队列。 第40条 用块引用其所属对象时不要出现保留环 如果块所捕获的对象直接或者间接地保留了块本身，那么得注意是否存在保留环的问题。 一定要找个适当的时机解除保留环，而不能把责任推给API调用者。 网络下载器可在任务启动时将自己加入全局的容器对象中，在任务结束后移除，从而保证自己在任务执行期间存活的同时不需要API调用方引用，大部分网络通信库都是采用这办法，如Twitter框架的TWRequest对象。 第41条 多用派发队列，少用同步锁 同步块@synchronized(obj)会根据给定对象自动创建一个锁，锁在代码块执行完成释放。由于给定对象相同，那么意味着它们使用的同一个锁，代码块需按顺序执行。如果在两个或多个没有逻辑关联的代码块给同一个对象加锁，会影响执行效率。 滥用@synchronized(self)很危险，因为所有同步块都会彼此抢夺同一个锁。示例：使用@synchronized实现属性的原子性（atomic）： 1234567891011- (NSString *)someString { @synchronized(self) { return _someString; }}- (void)setSomeString:(NSString *)someString { @synchronized(self) { _someString = someString; }} 如果有很多属性都是类似写法，那么每个属性的同步块都要等其他同步块执行完成才能执行。理想情况应该是属性各自独立地同步。 使用GCD实现属性原子性： 123456789101112131415_syncQueue = dispatch_queue_create(\"com.effectiveobjectivec.syncQueue\", NULL);//同步队列+同步派发- (NSString *)someString { __block NSString *localSomeString; dispatch_sync(_syncQueue, ^{ localSomeString = _someString; }); return localSomeString;}//同步队列+同步派发- (void)setSomeString:(NSString *)someString { dispatch_sync(_syncQueue, ^{ _someString = someString; });} GCD版本优化：设置方法不需要返回值，所以并不一定非得同步；获取方法可以并发执行，且设置方法与获取方法之间不能并执行。 12345678910111213141516_syncQueue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);//异步队列+同步派发- (NSString *)someString { __block NSString *localSomeString; dispatch_sync(_syncQueue, ^{ localSomeString = _someString; }); return localSomeString;}//异步队列+异步派发（同步派发可能效率更高，原因在于异步派发需要拷贝块，如果拷贝时间超过代码执行时间，则得不偿失。异步派发适合较为复杂的任务）+栅栏块- (void)setSomeString:(NSString *)someString { //栅栏块会单独执行，执行前会等待当前所有并发块执行完成，避免出现读写竞赛 dispatch_barrier_async(_syncQueue, ^{ _someString = someString; });} 第42条 多用GCD，少用performSelector系列方法 performSelector系列方法在内存管理方面容易有疏忽，由于无法确认将要执行的选择子是什么，因而ARC编译器无法插入适当的内存管理方法。 performSelector系列方法所能处理的选择子有局限性，选择子的参数个数与类型以及返回类型都受到限制。 第43条 掌握GCD及操作队列的使用时机 对于只需要执行一次的代码来说，GCD的dispatch_once是首选，但是执行后台任务则可以考虑NSOperationQueue。 在iOS4与Mac OSX 10.6开始，操作队列在底层是用GCD来实现的。 GCD是纯C的API，任务使用轻量级数据结构块来表示；操作队列则是Objective-C的对象，采用更为重量级的NSOperation对象执行任务。 使用操作队列的优势： 可取消还未启动的任务 可指定操作间的依赖关系 可通过键值观测机制监控NSOperation对象的属性 可指定操作的优先级，而GCD只能指定队列的优先级 可重用NSOperation对象 是否使用底层实现方案还是高层API，可通过实际性能测试来确定。 第44条 通过Dispatch Group机制，根据系统资源状况来执行任务 一系列的任务可归入一个dispatch group中，开发者可以在所有任务完成后获得通知 利用dispatch group并发地执行多项任务。 dispatch_apply是持续阻塞的，直到所有任务都执行完成。 第45条 使用dispatch_once来执行只需要运行一次的线程安全代码 dispatch_once采用“原子访问”来判断块中的代码是否已经执行过，而非使用重量级的同步机制，相比于@sychronized更为高效，如果想了解@synchronized的实现机制可以看看这篇博客。 标记dispatch_once_t应该声明为static，确保每次调用都复用同一个变量。 第46条 不要使用dispatch_get_current_queue dispatch_get_current_queue已被废弃，只应做调试使用 派发队列是按层级来组织的，子队列是包含于父队列的，所以无法单用某个队列对象来描述“当前队列”这一概念 dispatch_get_current_queue用于解决由不可重入代码所引发的死锁，可以使用“队列特定数据”来解决：dispatch_queue_set_specific(dispatch_queue_t queue,const void *key, void *context, dispatch_function_t destructor); 第7章 系统框架 标准根类NSObject属于Foundation框架，而非语言本身。如果不适应Foundation框架，则需要自己实现根类 第47条 熟悉系统框架 在众多框架中，Foundation和CoreFoundation这两个框架最为重要，提供了许多核心功能 Objective-C编程经常会使用纯C实现的框架，比如CoreFoundation，里面用到底层C语言级API，这样可以绕过运行时系统，提升速度，但是需要手动管理内存。 第48条 多用块枚举，少用for循环 遍历collection有四种方式。最基础的是for循环，其次是NSEnumerator遍历和NSFastEnumeration协议下的快速遍历，最快、最先进的方式是“块枚举发” “块枚举法”本身能够通过GCD来并发执行遍历，无须另行代码，其他遍历方式则不能做到这一点 如果提前知道遍历collection中的对象，应修改块签名，指出对象的具体对象。 第49条 对自定义其内存管理语义的collection使用无缝桥接 Foundation框架中的collection类都有与之对应的CoreFoundation框架版的C语言API 桥接符号__bridge表示ARC保留对Objective对象的所有权，而__bridge__retain则刚好相反，需要使用CFRelease释放内存。 使用CoreFoundation框架可以创建出Foundation框架所不具备的功能，比如NSDictionary的键值内存管理语义是“copy”，即键值必须支持Copying协议，使用CoreFoundaition创建一个键值内存管理语义为“Retain”的CFDictionary。 第50条 构建缓存时选用NSCache而非NSDictionary 实现缓存时应选NSCache而非NSDictionary对象。NSCache提供了优雅的自动删减功能，而且线程安全。此外，它与字典不同，不会拷贝键值，而是retain一次。 可以给Cache对象设置上限：缓存对象总个数和缓存总大小，这些设置定义了缓存删减其中对象的时机。但是这些设置仅对Cache起指导作用，并非一定在系统资源紧张时删减Cache中的某个对象，因此不能通过设置上限来迫使Cache优先删减某个对象。 将NSPurgeableData与NSCache搭配使用，可实现自动清除数据功能，也就是说当NSPurgeableData对象所占内存被系统丢弃时，对象也会从缓存中移除。 缓存的设计初衷是为了提高响应速度，只有那些“重新计算起来费劲”的数据才值得放入缓存，比如网络获取或者磁盘读取的数据。 第51条 精简+initialize与+load的实现代码 在加载过程中，如果类实现了+load方法，那么系统会通过函数指针调用+load。调用顺序是父类-&gt;子类-&gt;分类。因为程序加载时是使用函数指针调用而非消息机制，所以分类中的+load不会覆盖子类中的+load方法。 程序启动时，运行期处于“脆弱状态（fragile state）”，如果+load方法中使用了其他非系统库（系统库的类在这之前已经加载好了）的类，那么这些类的+load方法也在此时被调用。如果子类没有实现+load方法，那么各级超类是否实现此方法都不被系统调用。 +load方法务必实现的精简一些，因为整个程序在+load方法时都会阻塞。其真正的用途在于调试程序。 +initialize方法会在程序首次调用该类之前调用，只调用一次，如果某个类未被使用，那么其+initialize方法一直不会被调用。 +initialize方法被调用时，运行期系统已经处于正常状态，理论上可以在其中调用任何类的任意公开方法，且是线程安全的。 +initialize方法与其他消息一样，如果子类未实现它而其超类实现了，那么会子类也会调用一次超类的实现方法。 无法再编译器设定的全局变量，可以放在+initilize方法中初始化。 第52条 别忘了NSTimer会保留其目标对象 NSTimer对象会保留其目标，知道计时器调用invalidate方法后失效为止。另外，一次性的计数器在触发任务后就会立即失效。 反复执行任务的计时器，很容易引入保留环，可通过扩充NSTimer功能，用块来打破保留环。代码如下： 1234567891011121314151617181920@interface NSTimer (ECOBlocksSupport)+ (NSTimer *)eoc_scheduledTimerWithTimeInterval:(NSTimerInterval)interval block:(void(^)())block repeats:(BOOL)repeats;+ @end@implementation NSTimer (ECOBlocksSupport)+ (NSTimer *)eoc_scheduledTimerWithTimeInterval:(NSTimerInterval)interval block:(void(^)())block repeats:(BOOL)repeats { return [self scheduledTimerWithTimerInterval:interval target:self selector:@selector(eoc_blockInvoke:) userInfo:[block copy] repeats:repeats];}+ (void)eco_blockInvoke:(NSTimer *)timer { void(^block)() = timer.userInfo; if (block) { block(); }}@end 这个方法仍然存在保留环，计时器现在的target是NSTimer类对象，但是因为类对象无需回收，所以不用担心。 上述方法本身不能解决问题，但是提供了解决问题的工具。使用分类中的eoc_scheduledTimerWithTimeInterval来创建计时器： 1234567- (void)startPolling { __weak type(self) weakSelf = self; _pollTimer = [NSTimer eoc_scheduledTimerWithTimeInterval:1.0 block:^{ EOCClass *strongSelf = weakSelf; [strongSelf p_doPoll]; } repeats:YES];}","link":"/2017/10/07/Effective%20Objective-C%202.0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"《swift编程语言中文版》学习笔记","text":"这篇文章是在阅读《swift编程语言中文版》一书时的部分学习笔记，这本书对Swift语言进行详解而全面的讲解，是Swift入门的不二之选。 2.9 类和结构体swift中类和结构体的关系比其他语言更加密切，二者主要的区别在于： 类支持继承 类支持运行时检测类实例类型 类有deinit函数 类是引用类型而结构体是值类型 swift中类或结构体允许直接修改其属性（存在子属性的一般也就是类或结构体）的子属性，而在Objective-C不行 结构体有一个默认的成员逐一初始化器 在Swift中，整数、浮点数、布尔值、字符串、数组、字典都是值类型，并且是以结构体的形式存在的，结构体和枚举也都是值类型，意味着赋值或参数传递过程都是属于值拷贝，而类是引用类型 用于判定多个类引用是否指向同一个类实例的两个恒等运算符：等价于（===）和 不等价于（===） swift中同样存在指针，比如引用类型，但是其声明方式同值类型一样 由于集合类型（数组和字典）都是以结构体实现的值类型，因此在赋值或传参过程中会发生拷贝，但是swift只会在有必要拷贝的情况下（比如拷贝后的数组长度发生变化等）才会执行拷贝，因此不必顾虑集合类型拷贝带来的性能问题。 字典类型的拷贝过程，如果键或值是值类型，则拷贝对应的值类型，如果是引用类型则拷贝的引用（其实就是指针） 数组类型只有在操作困难修改数组长度时才会发生，即使是修改数组内的元素值也不会发生拷贝，而是引用。 使用unshare函数可以确保数组的唯一性，但是并不意外这一定会发生拷贝，而是在有必要时才会拷贝。而copy函数属于强制拷贝数组。 可以使用恒等运算符来判定两个数组是否共用了相同的元素 数组只有在长度发生变化的操作中才会进行值拷贝，否则属于引用赋值 2.10 属性属性分为存储属性和计算属性，前者用于存储常或变量作为实例的一部分，只能用于类或结构体中，而后者用于计算一个值，可以理解成一种运算，可用于类、结构体和枚举中。 存储属性 当值类型的实例赋值给一个常量时，值类型的所有属性都会变成常量，即使是变量属性也不能再修改，而当引用类型的实例赋值给一个常量时，仍可以修改实例的变量属性。 @lazy关键字用于声明延长存储属性：在第一次被调用时才会计算初始值的属性，类似懒加载。用前提包括必须是存储属性且是变量属性。因为常量属性在构造之前必须要有初始值，因此不能声明为延迟存储属性。 计算属性 计算属性必须声明为（var）变量属性，因为它的值是不固定的。计算属性不直接存储值，而是提供一对getter和setter用来获取和访问其他属性或者变量的值。 如果计算属性的setter没有定义表示新值的参数名，则可以使用默认名称newValue。 一个计算属性如果只有getter没有setter那就是只读类型， 属性监视器 作用类似于OC的KVO，可以为延迟存储属性之外的属性添加属性监视器，也可以通过重载的方式为父类的属性添加属性监视器。 两种监视器：willSet和didSet，前者的参数是新属性值，缺省参数名为newValue。后者的参数是旧属性值，缺省值参数名为oldValue。监视器在属性初始化时不会被触发。 全局变量和局部变量 计算属性和属性监视器同样适用于全局和局部变量。全局的常量或变量默认就是延迟计算的且不需要标记@lazy关键字。 类型属性 存储属性和计算属性通常用于特定类型的实例，但是属性也可以直接用于类型本身，称之为类型属性 类型属性类似于OC中声明在超类中的属性（swift没有超类的概念）。类型属性可以被所有实例访问。 用关键字static定义值类型的类型属性，用class定义类的类型属性。 值类型可以定义存储型和计算型的类型属性，而类只能定义计算型的类型属性。存储类型的类型属性必须在声明时指定默认值，因为类型本身没有构造器（只有为实例提供的初始化构造器）。 为什么类不能定义存储型的类型属性？很可能与类是引用类型有关系？ 123456789101112131415161718192021222324252627//结构体类型struct SomeStructure { //static关键字 //存储型 static var storedTypeProperty = \"Some value.\" //计算型 static var computedTypeProperty: Int { //return a int value }}//枚举类型enum SomeEnumeration { //存储型 static var storedTypeProperty = \"Some value.\" //计算型 static var computedTypeProperty: Int { //return a int value }}//类类型class SomeClass { //class关键字 //只能定义计算型属性 class var computedTypeProperty: Int { //return a int value }} 2.11 方法方法是与某些特定类型相关联的函数，方法分：实例方法和类型方法 实例方法 方法和函数的局部名称和外部名称的默认行为的区别： 方法的第一个参数的外部参数可以省略，等价于在参数前加下划线（_），第二个及后面的参数名称可以同时作为局部和外部参数名称，等价于在参数前加#号。 self属性 self属性不需要显式调用，主要使用场景在于区分方法参数与实例属性，方法参数享有优先权，因此需要self指定实例属性消除歧义。 mutating关键字 类中的成员为引用类型，所以修改实例及其属性的值不会改变类型；而结构体和枚举中成员均为值类型，修改变量的值就是相当于修改变量的类型。Swift中默认不允许修改类型，因此需要前置mutaing关键字来表示该函数中能够修改类型。 值类型中的一般的实例方法不能修改其实例属性，而使用mutating关键字声明实例方法可以修改属性，并且修改的状态保留在原始结构中。在此方法中还可以给self重新赋值一个全新的实例，并替换原有实例。 枚举的mutating方法可以把self设置为枚举类型中不同的成员。 类型方法 类型方法的声明与类型属性声明类似，类的类型方法加关键字class，结构体和枚举的类型方法加static。 在本类或结构体的范围内，类型方法可以相互调用，也可以直接调用类型属性，不需要显式类型名称做为前缀。 2.12 附属脚本附属脚本本质上提供了一种访问对象、集合或序列的快捷方式，可以定义在类、结构体和枚举中。使用时配合”[]”语法糖直接对多个属性同时访问或赋值 对于同一个目标可以定义多个附属脚本，通过索引值类型的不同进行重载，而且索引值得个数可以是多个。 定义附属脚本使用subscript关键字，没有函数名，或者说subcript就是默认函数名称。附属脚本对于索引入参的数量和类型没有限制，返回值可以是任何类型，但是不能使用in-out参数和对参数设置默认值。 附属脚本在定义上与实例方法类似，区别在于使用时附属脚本不需要指定函数名，而是根据参数自动匹配对应的脚本函数。 附属脚本与计算型属性类似，可以设定读写或者只读属性。区别在于附属脚本不是具体的属性，并且可以自定义参数和返回值类型和个数。而计算性属性的参数和返回值在定义时已经指定，可以理解为是对某一个具体属性的附属脚本，但是调用方式却没有附属脚本那么便捷，而是类似实例方法调用。 2.13 继承在swift中，继承是区分“类”和其他类型的一个基本特征。子类可以调用和访问超类的方法、属性和附属脚本，并且可以重载这些方法。 不继承与其它类的类，称之为基类。不同于OC有一个共同的基类NSObject 在swift中，初始化器默认是不继承的。 重写 子类可以重写类方法、实例方法和附属脚本，使用关键字override标明 子类可以通过重写的方式将超类的存储型属性以计算型属性存在，但是该属性在超类还是存储型属性。 使用关键字final来防止重写 2.14 构造过程与OC的构造器不同，Swift的构造器无返回值，主要任务是确保新实例在第一次使用之前完成正确的初始化。 在构造器中给存储型属性赋值时不会触发任何属性观测器 不同的构造器通过参数的不同进行区分，如果没有定义外部参数名，Swift会自动生成一个与内部参数名相同的外部名，等价于在内部名前添加#号。也可以使用下划线(_)来覆盖默认行为。 默认构造器 只有在所有成员变量都有默认值得时候，才能省略构造器，或者说Swift提供了一个默认的构造器。结构体的默认构造器是逐一成员构造器。 值类型的构造代理 构造器可以通过调用其他构造器完成部分构造过程，此过程称之为构造代理，且构造器代理的实现规则和形式在值类型和类类型有所不同。 值类型不支持继承，构造器代理任务只能给本身提供的其他构造器。而类类型可以调用超类的构造器完成构造代理。 值类型中一旦自定义了构造器后将无法访问到默认构造器，结构体则无法访问逐一成员构造器。如果定制的构造器是定义在扩张中，则不会覆盖默认构造器。 类的继承和构造过程 指定构造器是类中最主要的构造器：初始化类中所有的属性，并且根据父类链往上调用父类的构造器来实现父类初始化。每一个类至少拥有一个指定构造器，可继承自父类。 便利构造器则通过调用指定构造器实现，并给部分参数提供默认值。 构造器的继承与重载 与OC不同，一般情况下，Swift不会默认继承父类构造器，即此时创建子类时不能调用父类的构造器。可通过重载的方式继承与父类相同的构造器，且不需要使用override关键字。 两种特殊情况下，自动继承父类构造器： 子类没有定义任何指定构造器，它将自动继承所有父类的指定构造器和便利构造器。 子类提供了所有父类指定的构造器实现，将自动继承所有父类的便利构造器。 使用闭包或全局函数设置属性的默认值 如果某个存储型属性的默认值需要特别的定制，使用闭包或全局函数为其提供定制的默认值。赋值时执行闭包或调用函数，将返回值赋给该属性。 使用闭包初始化属性时，不能在闭包中访问其它的属性，即便属性有默认值也不允许。同时，不能使用隐式的self属性或调用其它的实例方法。 2.15 反初始化反初始化函数使用关键字deint来标识，只适用于类类型，在实例释放前一步自动调用。 反初始化函数调用链与初始化函数调用链相反，先完成子类的资源释放再执行父类的反初始化函数。与OC类似。 2.16 自动引用计数(ARC)引用计数只用于类类型的实例，值类型不是以引用的方式存储和传递的。 循环引用 使用weak引用或者无主引用来解除循环引用，弱引用可以为nil，所以必须是可选类型的，指向的实例释放后ARC自动将weak指针置空。无主(unowned)引用默认始终有值，因此必须是非可选型。如果无主引用指向的实例已释放，再次通过无主引用访问该实例即为野指针错误，需要手动置空。 weak指针适用情况：当两个对象AB之间均非一对一关系，即A对B或者B对A都是一个可选值，允许是nil unowned指针适用情况：当对象A必须引用对象B，而A之于B是一个可选项，允许为空 unowned + 隐式展开可选项：对象AB属于一对一关系，且A对象是B的初始化参数之一，设置B为隐式展开的可选属性，此时B对象为赋值之前默认值为nil，不影响A的初始化操作，从而A初始化后可以作为参数完成B的初始化。 下面代码思路正确，但是代码执行出错，隐式展开可选项似乎没起作用，待进一步研究！ 1234567891011121314151617//Country与City属于一对一关系，且City的初始化依赖于Country1. class Country {2. let name: String3. let capitalCity: City! //隐式展开可选项4. init(name: String, capitalName: String) {5. self.name = name6. self.capitalCity = City(name: capitalName, country: self) 7. }8. }9.10.class City {11. let name: String12. unowned let country: Country //unowned指针13. init(name: String, country: Country) {14. self.name = name15. self.country = country 16. }17. } 闭包产生的循环引用 类似于OC中Block产生的循环引用。 Swift中的约束：只要闭包内使用self的成员，就必须通过self指针调用，而不能直接调用，可提醒存在强引用的风险 通过定义占有列表解除强循环引用，占有列表有关键字weak或unowned和实例的引用组成，包含在一个中括号中，有逗号隔开。eg: [(weak|unowned), self] 占有列表放置在闭包参数和返回类型之前。如果没有指定参数或返回类型则放在关键字in前面。 当闭包和占有实例总是互相引用并总是同时销毁时，使用unowned定义占有列表。当占有引用有可能为nil时，使用weak。 2.17 自判断链接Swift的自判断链和OC中的消息为空类似，但是Swift可用于任意类型（值类型和类类型），并且一定会有返回值，返回值一定是可选项类型。 可使用自判断链代替强制拆包二者调用方式类似：自判断值后面使用？号，而强拆使用的是！号。当自判断值为空时，强拆会引发运行时错误，自判断链则会返回一个空值，表示自判断链调用失败。 自判断链适用于调用属性、实例方法和附属脚本（子脚本）中，三者的任意组合成自判断链。 2.18 类型转换Swift中的is和as两个操作符分别用来做类型检测和类型转换。 假如向下转换可能出现失败的情况，使用as?返回一个可选值，转换失败返回nil。假如确定一定能转换成功则使用as，有点类似强制解包。 Swift为不确定类型提供了两种特殊类型别名： AnyObject可以代表任何class类型实例 Any可以表示除了方法类型之外的任何类型 2.2 扩展扩展是向一个已有的类、结构体或枚举类型添加新功能。与OC中的分类类似，但是Swift的扩展不需要知道名称，可以理解成OC中的匿名分类？。 Swift中的扩展可以： 添加计算型属性和计算静态属性 定义实例方法和类型方法 提供新的构造器 定义下标 定义和使用新的嵌套类型 使一个已有类似符合某个接口 Swift中扩展和OC中分类一样，扩展中的功能在该类型的所有实例都是可用的。 注意：扩展可以添加新的计算型属性，但是不能添加存储属性，也不可以向已有属性添加属性观测器 2.21 协议类、结构体和枚举均可实现多个协议，中间用逗号分隔。 属性要求 协议能够要求遵循者包含一些特定名称和类型的实例属性或类属性，同时可以指定类型的读写权限，但是具体属性最终实现可以是存储型或者计算型属性。 方法要求 协议方法的声明和普通方法声明相似，但是不需要方法内容。 class中实现协议中的mutating方法时，不用写mutating关键字，因为类为引用类型，可直接修改类的属性；用结构体和枚举实现协议中的mutating方法时，则必须写mutating。 协议类型 协议可当做一种满足一定要求的类型对待，可用于声明满足协议的变量。比如委托模式，声明一个满足委托协议的代理变量，然后通过代理变量调用委托协议中的方法。 在扩展中添加协议成员 通过扩展为已存在的类型遵循协议是，该类型的所有实例也会随之添加协议中的方法。 当一个类型实现了某个协议中的所有要求却没有声明相应的协议时，可以通过扩展来补充协议声明。 集合中的协议类型 协议类型可以用来声明集合，表示集合中的元素均为协议类型。 协议的继承 协议能够继承一到多个其他协议。语法和类的继承相似。 协议合成 一个协议可又多个协议采用protocol&lt;SomeProtocol, AnotherProtocol, ThirdProtocol&gt;这样的格式进行组合。 协议合成不会生成一个新的协议类型，而是将多个协议合成为一个临时的协议，超出范围后立即失效。 检验协议的一致性 使用is检验协议的一致性，使用as将协议类型向下转换为其他的协议类型。 is操作符用来检查实例是否遵循了某个协议 as?返回一个可选值，当实例遵循协议时，返回该协议类型，否则返回为nil。 as用以强制向下转换。 @objc @objc表示协议的可选的，用可以用来表示暴露给Objective-C的代码。此外，@objc型协议只对类有效，因此只能在类中检查协议的一致性。 在@objc声明的协议中，可以使用@optional关键字作为前缀定义可选的属性或者方法。 调用可选方法是，在函数名和参数直接加上?来检查该方法是否被实现，当其不可访问时，？之后的语句不会执行，并且返回nil。 2.22 泛型泛型是一种清晰和抽象的代码表达方式，可以根据自我需求定义、适用于任何类型的，灵活且可重用的函数和类型，从而避免了代码重复。 泛型是Swift强大特征之一，许多Swift标准库是通过泛型代码构建的。 关联类型 定义协议时，通过associatedtype声明一个关联类型，不用具体指定实际类型。直到实现协议时，才给出关联类型的实际类型。 通过extension为已知类型添加协议的兼容性 如果某个类型已经覆盖了某个协议所包含的要求，那么可以通过拓展将已知类型和协议建立关联。有点像JS中的鸭子类型。 2.23 高级运算符","link":"/2018/06/01/Swift%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"WebRTC之RTT的两种计算方式","text":"简述RTT（round-trip time），往返时延，表示在通信过程中，发送端发送的数据包或信号抵达接收端后，再返回发送端的整个往返过程所需时长。 RTT由三个部分决定，分别是 链路的传输时长 路由器的排队和处理时长 接收端的处理时长 由于接收端的处理时长只与接收端的处理逻辑相关，不涉及网络传输，所以在RTT计算过程中一般不包括接收端的处理时长。即： 1RTT = 链路的传输时长 + 路由器的排队和处理时长 其中，路由器的排队和处理时长会随着整个网络的拥塞程度的变化而变化。简言之，网络拥塞程度越严重，RTT的值也就越大。因此，RTT的变化在一定程度上反应了整个网络的拥塞程度的变化。这也是RTT常被当做重要指标用于分析网络性能的原因。 RTT的计算方式在WebRTC中根据RTT计算的发起端的不同，可分为以下两种的计算方式： 基于发送端 这是WebRTC中默认开启的RTT计算方式，其流程图如下所示： 计算公式： 与之相关的RTCP报文有：SR（Sender Report）、RR（Receiver Report）和Report Block。 相关报文的格式 Send Report 1234567891011121314151617181920// Sender report (SR) (RFC 3550). 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+header |V=2|P| RC | PT=SR=200 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+sender | NTP timestamp, most significant word |info +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | NTP timestamp, least significant word | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | RTP timestamp | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender's packet count | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | sender's octet count | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | report block(s) | | ... | 字段解析： NTP timestamp：64 bits 表示该SR包发送时的NTP时间戳，之所以使用NTP时间，是因为NTP可以同步不同计算机之间的时钟，降低时间误差。 关于NTP时间的介绍，可参考文章： 计算机中几个与时间相关的概念 RTP timestamp：32 bits 表示该SR包发送时的RTP时间戳，单位是采样时间戳，一般与NTP timestamp指向同一时刻，但也有可能会引入一个随机的偏移值。 sender’s packet count ：32 bits 表示在生成该SR包时已经发送的RTP包的总个数。 sender’s octet count：32 bits 表示在生成该SR包时已经发送的RTP包的总字节数。 SR包除了自身信息之外，还可以作为Report Block的载体。 Receiver Report 12345678910// RTCP receiver report (RFC 3550). 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+header |V=2|P| RC | PT=RR=201 | length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSRC of packet sender | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | report block(s) | | ... | RR包只是Report Block的载体，此外除了RTCP头，无其它字段。 Report Block 12345678910111213 +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+report | SSRC of media source |block +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | fraction lost | cumulative number of packets lost | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | extended highest sequence number received | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | interarrival jitter | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | last SR (LSR) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | delay since last SR (DLSR) | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ 字段解析： SSRC of media source：32 bits 表示该Report Block包所属的数据流，与发送SR包的数据源所对应的SSRC一致。 fraction lost：8 bits 表示从发送上一个Report Block包到发送当前Report Block包的这段时间内的丢包率。 采用Q8格式，即用0255映射0.01.0范围。 cumulative number of packets lost：24 bits 表示SSRC对应的数据流从开始到现在所累积的丢包个数， extended highest sequence number received：32 bits 表示接收端当前所接收到的最大的RTP包序号。 该序号是一个解回绕后的值，高16 bits表示序号回绕的次数，低16位表示RTP序号。 NOTE：关于序号回绕技术的介绍留待后续。 interarrival jitter：32 bits 表示接收端先后接收到的两个RTP包之间的抵达间隔抖动。关于抖动的计算，可参考文章： WebRTC之抖动估计 last SR：32 bits 该字段对应接收端接收到的最新SR包中所携带的NTP时间戳。 NOTE：该字段是一个紧凑型的NTP时间戳，即分别取NTP时间中秒部分的低16 位和小数秒部分的高16位，然后拼凑成一个32位的值。采用紧凑型的NTP时间戳是一种以精度换空间的优化。 NTP时间转换成紧凑型NTP时间戳的方式： 1234567891011struct NTPTime { uint32_t seconds; // 秒 uint32_t fractions; // 小数秒};// 接收端接收到的最新SR包中的NTP字段NTPTime last_received_ntp;// Compacted NTP timestamp// 紧凑型的NTP时间戳uint32_t last_sr_timestamp = ((last_received_ntp.seconds &amp; 0x0000ffff) &lt;&lt; 16) + ((last_received_ntp.fractions &amp; 0xffff0000) &gt;&gt; 16); delay since last SR：32 bits 表示从接收端接收到的最新SR包到发送当前Report Block包之间的时间间隔，即接收端处理SR包的时间。如果截止目前没有收到SR包，则该值为0。 NOTE：该字段也是一个紧凑型的NTP时间戳。 代码导读 发送端发送SR包 有两种情况会触发SR包的发送，分别是： 在每次发送RTP包之前会检查是否可以发送一个SR包 12345678910111213141516171819bool ModuleRtpRtcpImpl2::OnSendingRtpFrame(uint32_t timestamp, int64_t capture_time_ms, int payload_type, bool force_sender_report) { // 如果当前端不是发送端，则直接返回 if (!Sending()) return false; ... // 确保SR包在关键帧之前发送，因为SR包的RTP timestamp字段会用于抖动估计和音视频同步 // Make sure an RTCP report isn't queued behind a key frame. // 检查是否可以发送新的SR包 if (rtcp_sender_.TimeToSendRTCPReport(force_sender_report)) // 通过RTCPSender来发送SR包 rtcp_sender_.SendRTCP(GetFeedbackState(), kRtcpReport); return true;} 在RTCPSender发送Report Block包时，如果是当前端是发送端则会使用SR作为载体 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// RTCP的Report包：Report Block、XR中扩展报告、SDES包等void RTCPSender::PrepareReport(const FeedbackState&amp; feedback_state) { bool generate_report; // 允许发送RTCP Report的两类情况： if (IsFlagPresent(kRtcpSr) || IsFlagPresent(kRtcpRr)) { // 情况一：在每次发送SR包或RR包时携带Report Block，因为Report Block只能以SR包或RR包作为载体发送 // Report type already explicitly set, don't automatically populate. generate_report = true; RTC_DCHECK(ConsumeFlag(kRtcpReport) == false); } else { // 情况二：当前发送的RTCP包类型中不包括SR或RR，则需要满足以下任一条件： // a. 当前RTCP模式是复合模式（kCompound） // 这种模式下，发送任意的RTCP包都会触发Report Block的发送。 // b. 当前RTCP模式是简化模式（kReducedSize） // 只有当前发送的RTCP包类型中包含了Report Block类型，即添加了kRtcpReport标识，才会触发Report Block的发送。 generate_report = (ConsumeFlag(kRtcpReport) &amp;&amp; method_ == RtcpMode::kReducedSize) || method_ == RtcpMode::kCompound; // 如果是发送端则使用SR包作为Report Block的载体，否则使用RR包作为载体。 if (generate_report) SetFlag(sending_ ? kRtcpSr : kRtcpRr, true); } // 检测是否需要发送SDES包 if (IsFlagPresent(kRtcpSr) || (IsFlagPresent(kRtcpRr) &amp;&amp; !cname_.empty())) SetFlag(kRtcpSdes, true); // 允许发送RTCP Report。 if (generate_report) { // 检测是否需要发送扩展报告包，载体是XR包。 // 与基于接收端的RTT计算方式相关的两个RTCP包：Receiver Reference Time Report Block // 和DLRR Report Block**，**以及视频分配码率的报告都是通过XR包作为载体发送。 if ((!sending_ &amp;&amp; xr_send_receiver_reference_time_enabled_) || !feedback_state.last_xr_rtis.empty() || send_video_bitrate_allocation_) { SetFlag(kRtcpAnyExtendedReports, true); } // Report Block的发送是周期性的 // generate next time to send an RTCP report TimeDelta min_interval = report_interval_; if (!audio_ &amp;&amp; sending_) { // 音频的RTCP报告使用固定的周期，视频的RTCP报告周期则与当前的码率相关：优先取当前码率的36%用于发送RTCP报文。 // Calculate bandwidth for video; 360 / send bandwidth in kbit/s. int send_bitrate_kbit = feedback_state.send_bitrate / 1000; if (send_bitrate_kbit != 0) { min_interval = std::min(TimeDelta::Millis(360000 / send_bitrate_kbit), report_interval_); } } // 部署下一次发送Report Block的间隔时间，是一个任意值。 // 取范围是下一次发送时刻的前后0.5毫秒内：[interval_ms - 0.5，interval_ms + 0.5] // The interval between RTCP packets is varied randomly over the // range [1/2,3/2] times the calculated interval. int min_interval_int = rtc::dchecked_cast&lt;int&gt;(min_interval.ms()); TimeDelta time_to_next = TimeDelta::Millis( random_.Rand(min_interval_int * 1 / 2, min_interval_int * 3 / 2)); // 部署下一次Report Block的发送 RTC_DCHECK(!time_to_next.IsZero()); SetNextRtcpSendEvaluationDuration(time_to_next); // RtcpSender expected to be used for sending either just sender reports // or just receiver reports. RTC_DCHECK(!(IsFlagPresent(kRtcpSr) &amp;&amp; IsFlagPresent(kRtcpRr))); }} 接收端收到SR包之后，返回一个RR包或SR包 如果当前端本身既是发送端又是接收端，则在收到SR包后会在下次发送SR包时将Report Block一并返回。 如果当前端只是接受端，那么则为以RR为载体将Report Block返回。 同上，相关代码见函数RTCPSender::PrepareReport。 发送端在收到RR包或SR包后，提取相关字段计算RTT值 RTT的计算位于发送端的RTCPReceiver中，以下是相关代码： 12345678910111213141516171819202122232425262728293031323334353637383940void RTCPReceiver::HandleReportBlock(const ReportBlock&amp; report_block, PacketInformation* packet_information, uint32_t remote_ssrc) { // 过滤不属于当前端的Report Blocks if (!registered_ssrcs_.contains(report_block.source_ssrc())) return; // 接收到Report Block的系统时间 last_received_rb_ = clock_-&gt;CurrentTime(); ... // 根据Report Block计算RTT int64_t rtt_ms = 0; // T0：接收端收到的最新的SR包中的NTP时间戳 uint32_t send_time_ntp = report_block.last_sr(); // send_time_ntp为0表示接收端暂未收到SR包 if (send_time_ntp != 0) { // 接收端的处理时长 uint32_t delay_ntp = report_block.delay_since_last_sr(); // T1：将系统时间转换成NTP时间后再格式化成紧凑型NTP时间戳 // Local NTP time. uint32_t receive_time_ntp = CompactNtp(clock_-&gt;ConvertTimestampToNtpTime(last_received_rb_)); // 计算RTT，因为在NTP时间戳中，秒和小数秒部分都是16位，所以单位是1/(2^16)秒 // RTT in 1/(2^16) seconds. uint32_t rtt_ntp = receive_time_ntp - delay_ntp - send_time_ntp; // 将RTT的单位转换成毫秒 // Convert to 1/1000 seconds (milliseconds). rtt_ms = CompactNtpRttToMs(rtt_ntp); report_block_data-&gt;AddRoundTripTimeSample(rtt_ms); if (report_block.source_ssrc() == main_ssrc_) { rtts_[remote_ssrc].AddRtt(TimeDelta::Millis(rtt_ms)); } packet_information-&gt;rtt_ms = rtt_ms; } ...} 基于接收端 WebRTC中可通过设置RTCPSender中的xr_send_receiver_reference_time_enabled_来开启这种计算方式，其流程图如下所示： 计算公式： 与之相关的RTCP报文有：RRTR（Receiver Reference Time Report Block）、DLRR（DLRR Report Block）。 相关报文的格式 Receiver Reference Time Report Block 1234567891011// Receiver Reference Time Report Block (RFC 3611). 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| BT=4 | reserved | block length = 2 |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| NTP timestamp, most significant word |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| NTP timestamp, least significant word |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ RRTRB其实就是一个简化版的SR，字段解析可参考上述SR报文的解析。 DLRR Report Block 123456789101112131415// DLRR Report Block (RFC 3611). 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| BT=5 | reserved | block length |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+| SSRC_1 (SSRC of first receiver) | sub-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ block| last RR (LRR) | 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| delay since last RR (DLRR) |+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+| SSRC_2 (SSRC of second receiver) | sub-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ block: ... : 2 sub-block其实就是一个简化版的Report Block，而DLRR则是sub-block的载体。一个DLRR报文可包含多个sub-block，字段解析可参考上述Report Block报文的解析。 代码导读 接收端发送一个RRTRB包 RRTRB包的发送逻辑同Report block一样，位于RTCPSender::PrepareReport中。 发送端收到RRTRB包后，返回一个DLRR包 DLRR包的发送逻辑同Report block一样，位于RTCPSender::PrepareReport中。 接收端收到DLRR包后，提取相关字段计算RTT值 RTT的计算位于接收端的RTCPReceiver中，以下是相关的代码： 123456789101112131415161718192021222324252627282930313233343536void RTCPReceiver::HandleXrDlrrReportBlock(uint32_t sender_ssrc, const rtcp::ReceiveTimeInfo&amp; rti) { // 过滤不属于当前接收端的DLRR包 if (!registered_ssrcs_.contains(rti.ssrc)) return; // 这种RTT计算方式需要显示设置启动 // Caller should explicitly enable rtt calculation using extended reports. if (!xr_rrtr_status_) return; // T0：发送端收到的最新的RRTRB包中的NTP时间戳，因为在NTP时间戳中，秒和小数秒部分都是16位，所以单位是1/(2^16)秒 // The send_time and delay_rr fields are in units of 1/2^16 sec. uint32_t send_time_ntp = rti.last_rr; // send_time_ntp == 0表示发送端暂时尚未收到RRTRB包 // RFC3611, section 4.5, LRR field discription states: // If no such block has been received, the field is set to zero. if (send_time_ntp == 0) { auto rtt_stats = non_sender_rtts_.find(sender_ssrc); if (rtt_stats != non_sender_rtts_.end()) { rtt_stats-&gt;second.Invalidate(); } return; } // 发送端的处理时长 uint32_t delay_ntp = rti.delay_since_last_rr; // T1：接收端收到DLRR的NTP时间戳 uint32_t now_ntp = CompactNtp(clock_-&gt;CurrentNtpTime()); // 计算RTT，格式为NTP时间戳 uint32_t rtt_ntp = now_ntp - delay_ntp - send_time_ntp; // 将RTT的单位转换成毫秒 xr_rr_rtt_ms_ = CompactNtpRttToMs(rtt_ntp); non_sender_rtts_[sender_ssrc].Update(TimeDelta::Millis(xr_rr_rtt_ms_));} 参考资料RFC 3550 - RTP: A Transport Protocol for Real-Time Applications RFC 3611 - RTP Control Protocol Extended Reports (RTCP XR)","link":"/2021/04/10/WebRTC%E4%B9%8BRTT%E7%9A%84%E4%B8%A4%E7%A7%8D%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F/"},{"title":"WebRTC之Trendline滤波器","text":"简述在GCC（Google Congestion Control）拥塞控制算法中，包含了两种带宽估计算法，分别是基于延迟的带宽估计算法和基于丢包的带宽估计算法。 其中，基于延迟的带宽估计算法有新旧两个不同的实现版本，分别是：旧版使用基于接收端的Kalman滤波器带宽估计算法，新版使用基于发送端的Trendline滤波器带宽估计算法。 在WebRTC中，为了向前兼容仍保留了旧版的实现，且对于视频流会同时开启两种基于延迟的带宽估计算法。因此，如果存在视频流时，GCC还好收到从接收端返回的带宽估计值：REMB（Remote Estimated Maximum Bitrate）。GCC算法最终会选取这三个带宽估计值中的最小值作为当前的带宽估计值。 本文介绍的是新版基于延迟的带宽估计算法中的Trendline滤波器，可根据数据包的延迟梯度的变化预测带宽的变化趋势，以此为参考对当前码率进行相应的调整，进而获得更为接近真实情况的带宽估计值。 Trendline滤波器在Trendline滤波器涉及了多个子模块，分别是： 样本的计算和处理 包组的延迟梯度 在WebRTC中，Trendline滤波器的样本为包组的延迟梯度值作。以下是包组的延迟梯度值的计算方式： 12// 包组的延迟梯度 = 包组的抵达时间间隔 - 发送时间间隔的差值propagation delay = inter-arrival - inter-departure 关于包组的发送时间间隔和抵达时间间隔的计算，可参考文章 WebRTC之包组的时间间隔 。 一次指数平滑法 由于网络拥塞以及包组划分方式等原因，包组的延迟梯度值或多或少存在一些误差，因此需要对其进行平滑处理。 在WebRTC中，使用的是一次指数平滑法，其本质上也是一种加权的平均算法。关于一次指数平滑法的介绍，可参考文章 时序模型初探之三：指数平滑法 。 一次指数平滑算法特点在于：加权系数是随着时间呈指数变化，且距离现在越远的样本对应的系数越小，这也是其名字的由来。一次指数平滑法兼容了所有样本对未来值的影响，且符合历史样本对未来值的影响是随着时间地推移而递减的客观规律。 以下是一次指数平滑公式： 其中，\\hat{y}_{t+1}为未来预测值， 为当前预测值，为当前样本值，为加权系数，且：。 关于加权系数的选取建议是： 如果时间序列波动不大，则的值应取小一点，e.g. 0.1~0.5之间 如果时间序列具有迅速且明显的变动倾向，则的值应取大一点，e.g. 0.6~0.8之间。这样预测模型更为灵敏，以便迅速响应变化。 在WebRTC中，的默认值为0.9，换言之，的取值为0.1。 代码导读 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768void TrendlineEstimator::UpdateTrendline(double recv_delta_ms, double send_delta_ms, int64_t send_time_ms, int64_t arrival_time_ms, size_t packet_size) { // 传输延迟 const double delta_ms = recv_delta_ms - send_delta_ms; // 统计样本个数 ++num_of_deltas_; // 限定样本个数 num_of_deltas_ = std::min(num_of_deltas_, kDeltaCounterMax); // 首个包的抵达时间，作为样本计算相对抵达时间的参考点 if (first_arrival_time_ms_ == -1) first_arrival_time_ms_ = arrival_time_ms; // Exponential backoff filter. // 累积的延迟值 accumulated_delay_ += delta_ms; BWE_TEST_LOGGING_PLOT(1, \"accumulated_delay_ms\", arrival_time_ms, accumulated_delay_); // 计算延迟一次指数平滑值 smoothed_delay_ = smoothing_coef_ * smoothed_delay_ + (1 - smoothing_coef_) * accumulated_delay_; BWE_TEST_LOGGING_PLOT(1, \"smoothed_delay_ms\", arrival_time_ms, smoothed_delay_); // Maintain packet window // 相对抵达时间和累积的延迟平滑值分别作为线性回归样本的x和y值 delay_hist_.emplace_back( static_cast&lt;double&gt;(arrival_time_ms - first_arrival_time_ms_), smoothed_delay_, accumulated_delay_); // 最小二乘法的样本按抵达时间排序 if (settings_.enable_sort) { for (size_t i = delay_hist_.size() - 1; i &gt; 0 &amp;&amp; delay_hist_[i].arrival_time_ms &lt; delay_hist_[i - 1].arrival_time_ms; --i) { std::swap(delay_hist_[i], delay_hist_[i - 1]); } } // 由于只需要关注近期的斜率变化趋势，因此使用滑动窗口过滤掉历史数据的影响 if (delay_hist_.size() &gt; settings_.window_size) delay_hist_.pop_front(); // Simple linear regression. double trend = prev_trend_; // 使用最小二乘法求拟合函数 if (delay_hist_.size() == settings_.window_size) { // Update trend_ if it is possible to fit a line to the data. The delay // trend can be seen as an estimate of (send_rate - capacity)/capacity. // 0 &lt; trend &lt; 1 -&gt; the delay increases, queues are filling up // trend == 0 -&gt; the delay does not change // trend &lt; 0 -&gt; the delay decreases, queues are being emptied trend = LinearFitSlope(delay_hist_).value_or(trend); // 限定延时梯度斜率值 if (settings_.enable_cap) { absl::optional&lt;double&gt; cap = ComputeSlopeCap(delay_hist_, settings_); // We only use the cap to filter out overuse detections, not // to detect additional underuses. if (trend &gt;= 0 &amp;&amp; cap.has_value() &amp;&amp; trend &gt; cap.value()) { trend = cap.value(); } } } BWE_TEST_LOGGING_PLOT(1, \"trendline_slope\", arrival_time_ms, trend); // 带宽状态检测 Detect(trend, send_delta_ms, arrival_time_ms);} 基于线性回归求延迟的拟合函数 由于一次指数平滑法只适用于时间序列没有明显变化趋势的场景，但是包组的延迟梯度会随着网络拥塞程度的变化而出现某种线性变化。因此，如果仅用一次平滑法预测的未来值会存在明显的滞后偏差。因此，我们需要建立线性趋势模型进行修正。在WebRTC中，采用最小二乘法来建立线性趋势模型。 最小二乘法 最小二乘法，是一种基于线性回归求拟合函数的方法，它通过寻找误差的平方和的最小值来获得最接近真实情况的线性函数，所谓”二乘“就是平方的意思。以下是其数学推导过程： 假设线性关系函数为，其中a为斜率，b为截距： 对于任意样本点，误差值为： 总误差的平方为： 分别求a和b的一阶偏导数： 根据极值定理，当a和b的一阶偏导数为0时原函数存在极值点。再分别求a和b的二阶导数： 由于a的二阶偏导数是一个凹函数，b的二阶偏导数是一个正数，因此，极值点为最小值，即误差值最小。令a和b的一阶偏导数为0，最终可推导出关于a和b的函数： 其中，和分别表示x和y的算术平均值。 NOTE：由于误差是随机且独立的，即误差的分布符合正态分布。根据中心极限定量，当误差最小时，使用最小二乘法进行线性回归求得拟合函数最接近真实情况。 延迟梯度变化的预测模型 在Trendline滤波器中，假设抵达时间和延迟梯度平滑值之间存在线性关系，其线性函数为： 12// 延迟梯度平滑值 = 斜率 * 相对于第一个包的抵达时间 + 截距smoothed_delay_ms = k * relative_arrival_time_ms + b 斜率k值表示延迟的变化趋势，分以下三种情况： 0 &lt; k &lt; 1：表示数据包的延迟正在变大，路由器的缓存队列处于不断地增加的趋势，直到整个网络缓冲区被填满为止。 k == 0：表示数据包的延迟无变化，即路由器的缓存队列长度无变化。 k &lt; 0：表示数据包的延迟正在变小，即路由器的缓冲队列处于不断地减少的趋势，直到整个网络缓冲区被清空为止。 代码导读 12345678910111213141516171819202122232425262728293031// 求线性函数的斜率值absl::optional&lt;double&gt; LinearFitSlope( const std::deque&lt;TrendlineEstimator::PacketTiming&gt;&amp; packets) { RTC_DCHECK(packets.size() &gt;= 2); // Compute the \"center of mass\". // x：表示相对抵达时间 // y：表示延迟平滑值 double sum_x = 0; double sum_y = 0; // 计算当前窗口下，x和y的总和 for (const auto&amp; packet : packets) { sum_x += packet.arrival_time_ms; sum_y += packet.smoothed_delay_ms; } // 计算算术平均值 double x_avg = sum_x / packets.size(); double y_avg = sum_y / packets.size(); // 计算斜率k的值 // Compute the slope k = \\sum (x_i-x_avg)(y_i-y_avg) / \\sum (x_i-x_avg)^2 double numerator = 0; double denominator = 0; for (const auto&amp; packet : packets) { double x = packet.arrival_time_ms; double y = packet.smoothed_delay_ms; numerator += (x - x_avg) * (y - y_avg); denominator += (x - x_avg) * (x - x_avg); } if (denominator == 0) return absl::nullopt; return numerator / denominator;} 带宽过载检测 在WebRTC中，带宽评估有三个状态值，分别是： 12345enum class BandwidthUsage { kBwNormal = 0, // 正常状态 kBwUnderusing = 1, // 低载状态 kBwOverusing = 2, // 过载状态}; 这三种状态的切换是基于延迟梯度斜率值与阈值的比较，以下是状态切换图： 其中，表示修正后梯度延迟梯度斜率值，即图中的蓝色曲线，表示自适应阈值，即图中的两条红色曲线。带宽状态切换条件： 优化处理 在检测带宽状态时，并不是简单地将延迟梯度的斜率值与固定的阈值进行比较，从而获得带宽评估的状态值。因此这种直接比较的方式会导致评估结果对于延迟梯度的变化过于敏感，实际上，在具体实现时进行加入了以下优化处理： 修正延迟梯度的斜率值 本质上是将斜率值的波动范围变大，修正公式如下： 12// 修正后的斜率值 = 样本数 * 修正前的斜率值 * 阈值增益double modified_trend = min(num_of_samples, 60) * trend * threshold_gain 关于这个公式背后的原理还尚未弄明白，我目前的理解是： 由于threshold_gain是一个定值，所以当样本数小于60时，影响修正结果的是样本数和斜率值本身，此后唯一的变量则只有斜率值。因此，修正可以理解为就是对斜率值的一次增益处理，且增益值除起始阶段外就是一个定值。 增益值的大小决定了自适应阈值的取值范围，因为阈值的自适应算法是基于修正后的趋势值进行自适应更新的。 加入额外的过载触发条件 带宽过载的触发条件除了修正后的斜率值大于当前阈值，还加入了以下三个额外的条件： 时间上：过载维持时长大于10ms 次数上：过载次数超过1次 趋势上：当前延迟梯度斜率值（未修正）大于上一次的斜率值，即延迟在持续增加 使用自适应的阈值 使用自适应阈值的原因，主要包括以下三个： 由于带宽检测相较于带宽变化是滞后的，即基于延迟的带宽评估算法的检测结果具有一定的滞后性，因此，基于该算法的带宽调整不宜过于灵敏。 使用固定的阈值，不能及时响应带宽变化，要么不够灵敏，要么过于灵敏。 由于TCP数据流采用的是基于丢包的带宽评估算法，这是一种贪婪算法，在丢包率低时会不断地增加码率。因此，如果GCC中基于延迟的带宽评估算法过于灵敏，即一旦检测出带宽过载就立即开始降低码率，最终可能会导致GCC数据流一直处于低码率状态，即处于饥饿状态。 阈值的自适应算法，本质是一次指数平滑法，其特点在于加权系数的计算，分别是增益系数k和距离上次更新的时间间隔。其中，增益系数k的取值公式为： 其中，表示当前的增益系数值，表示修正后的趋势值，表示上一次的阈值，和分别表示阈值范围缩小和扩大的速度，WebRTC中的取值分别是0.039和0.0087。 增益系数k的取值逻辑为： 当修正后的势趋值的波动处于阈值范围内，说明当前的阈值范围过大，需适当缩小。 当修正后的趋势值的波动超出阈值的范围，说明当前的阈值范围过小，需适当扩大。 自适应算法的一次指数平滑公式： 其中，表示更新后的阈值，表示上一次阈值，表示距离上一次更新的时间间隔，表示当前的增益系数k。 代码导读 过载检测 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051void TrendlineEstimator::Detect(double trend, double ts_delta, int64_t now_ms) { // 样本个数少于2个时，趋势值的拟合度太低 if (num_of_deltas_ &lt; 2) { // 视为起始阶段的状态 hypothesis_ = BandwidthUsage::kBwNormal; return; } // 对趋势值进行修正处理 const double modified_trend = std::min(num_of_deltas_, kMinNumDeltas) * trend * threshold_gain_; prev_modified_trend_ = modified_trend; BWE_TEST_LOGGING_PLOT(1, \"T\", now_ms, modified_trend); BWE_TEST_LOGGING_PLOT(1, \"threshold\", now_ms, threshold_); // 基于修正后的趋势值和自适应阈值进行带宽评估 if (modified_trend &gt; threshold_) { // 带宽过载 // 统计过载时长 if (time_over_using_ == -1) { // Initialize the timer. Assume that we've been // over-using half of the time since the previous // sample. time_over_using_ = ts_delta / 2; } else { // Increment timer time_over_using_ += ts_delta; } // 统计过载次数 overuse_counter_++; // 额外的三个过载触发条件，同时满足才更新带宽状态为过载状态 if (time_over_using_ &gt; overusing_time_threshold_ &amp;&amp; overuse_counter_ &gt; 1) { if (trend &gt;= prev_trend_) { time_over_using_ = 0; overuse_counter_ = 0; hypothesis_ = BandwidthUsage::kBwOverusing; } } } else if (modified_trend &lt; -threshold_) { // 带宽处于低载状态 time_over_using_ = -1; overuse_counter_ = 0; hypothesis_ = BandwidthUsage::kBwUnderusing; } else { // 带宽处于正常状态 time_over_using_ = -1; overuse_counter_ = 0; hypothesis_ = BandwidthUsage::kBwNormal; } prev_trend_ = trend; // 更新自适应阈值 UpdateThreshold(modified_trend, now_ms);} 更新自适应阈值 12345678910111213141516171819202122232425262728void TrendlineEstimator::UpdateThreshold(double modified_trend, int64_t now_ms) { // 记录此次更新时间。 if (last_update_ms_ == -1) last_update_ms_ = now_ms; // 过滤延迟峰值 if (fabs(modified_trend) &gt; threshold_ + kMaxAdaptOffsetMs) { // 由于峰值一般都是突发的，避免对其进行自适应更新，确保阈值维持在一个合理范围。 // Avoid adapting the threshold to big latency spikes, caused e.g., // by a sudden capacity drop. // 阈值不更新，可理解为维持原值，所以仍视为一次更新操作。 last_update_ms_ = now_ms; return; } // 计算增益系数k const double k = fabs(modified_trend) &lt; threshold_ ? k_down_ : k_up_; const int64_t kMaxTimeDeltaMs = 100; // 计算距离上一次更新的时间间隔 int64_t time_delta_ms = std::min(now_ms - last_update_ms_, kMaxTimeDeltaMs); // 采用一次指数平滑法更新阈值 threshold_ += k * (fabs(modified_trend) - threshold_) * time_delta_ms; // 确保修正后的阈值在一个合理的范围 threshold_ = rtc::SafeClamp(threshold_, 6.f, 600.f); // 记录此次更新时间 last_update_ms_ = now_ms;} 参考资料最小二乘法的本质是什么？ 从零开始推导最小二乘法 深度学习数学基础（三）极值与二阶导数 Gcc-analysis.pdf","link":"/2021/04/25/WebRTC%E4%B9%8BTrendline%E6%BB%A4%E6%B3%A2%E5%99%A8/"},{"title":"WebRTC之传输协议初探：SRTP协议","text":"简述SRTP协议，全称Secure Real-time Transport Protocol。顾名思义，SRTP就是在RTP协议的基础上提供了安全保障，主要包括数据加密、消息认证和重放保护。 SRTP提供了一套框架用于加密和认证RTP和RTCP数据流，且内置一系列预定义的加密套件。当然也可以使用自定义加密套件。 SRTP协议建立于在RTP协议之上，在RTP/RTCP包的基础上通过增加额外的空间和计算量来实现安全保障。因此SRTP增加的额外开销越小，对RTP传输影响也越小。而SRTP额外开销的大小主要取决于加密套件的选择，SRTP中预定义的加密套件是一个不错的选择，详见 RFC 3711。 实现细节由于RTP和RTCP包在结构、功能以及传输上都存在差异，因此SRTP对二者的具体实现也存在差异。以下是SRTP基于预定义的加密套件的实现细节。 密钥上下文在RTP/RTCP协议中将通信参与者称之为一个RTP session，常见的会话类型有video RTP session、audio RTP session和text RTP session。 每一个RTP session可以包含多个stream，每个stream通过SSRC标识。RTP session对其中的每个stream的处理过程都是对等的，即发送或接收每个stream中的RTP/RTCP包。因此RTP session用使用一个二元组&lt;destination network address, destination transport port number&gt;来标识即可。 SRTP/SRTCP协议中新增了SRTP stream，一个三元组&lt;SSRC, destination network address, destination transport port number&gt;，用于标识RTP session下的每个stream。这样可以给每个SRTP stream提供不同的加密处理，具体实现原理是基于每个stream的SSRC生成不同的初始化向量（IV）： 1IV = (k_s * 2^16) XOR (SSRC * 2^64) XOR (i * 2^16) 两种密钥类型 SRTP中有两类密钥，分别是： master key master key是一串随机生产的字符串，一般由密钥协商协议提供，比如TLS。 session keys session keys中包含加密密钥、签名密钥和盐值，用于数据加密和消息认证。 SRTP和SRTCP共用一个master key和各自的KDF（Key Derivation Function）生成对应的session keys，如下图所示： 12345678910 packet index ---+ | v+-----------+ master +--------+ session encr_key| ext | key | |----------&gt;| key mgmt |--------&gt;| key | session auth_key| (optional | | deriv |----------&gt;| rekey) |--------&gt;| | session salt_key| | master | |----------&gt;+-----------+ salt +--------+ Session keys的导出函数除了master key和master salt之外还需要以下参数： key_label 用于标识key的类型，取值范围为0x00~0x05的含义如下： 12345678enum KeyLabel : int { label_rtp_encryption = 0x00, // 导出RTP加密密钥 label_rtp_msg_auth = 0x01, // 导出RTP校验密钥 label_rtp_salt = 0x02, // 导出RTP盐值 label_rtcp_encryption = 0x03, // 导出RTCP加密密钥 label_rtcp_msg_auth = 0x04, // 导出RTCP校验密钥 label_rtcp_salt = 0x05, // 导出RTCP盐值} packet_index SRTP/SRTCP的包序号，注意不是RTP/RTCP包的序号。为了防止重放攻击，SRTP和SRTCP都有一套自己的包管理方式，详见下文。 key_derivation_rate 表示key的导出速率，取值范围是{1,2,4,…,2^24}。除了初始时导出一次，之后的导出条件需要同时满足r &gt; 0，且packet_index mod r = 0，其中r的计算方式如下： 1r = packet_index / key_derivation_rate; 新导出的key值会替换原有的session keys用于数据加密和签名。 Session keys导出函数调用过程的伪代码如下： 12345678// 计算r值let r = packet_index / key_derivation_rate// 计算key_id，由lable和r值组成，label位于高字节，r位于低字节let key_id = &lt;label&gt; || r// 计算xlet x = key_id XOR master_salt// 调用导出函数kDF生成不同的key值let key = KDF(master_key, x) 预定义加密套件 SRTP协议中预定义了一些加密套件，包括加密和校验算法以及密钥导出函数等，这些加密套件所需的额外空间和计算都比较小，因此推荐使用。此外也可以自定义加密套件。 其中优先预定义的加密套件必须在SRTP协议的实现中强制实现，如下所示： 123456 必须实现 可选 默认 mandatory-to-impl. optional default encryption AES-CM, NULL AES-f8 AES-CMmessage integrity HMAC-SHA1 - HMAC-SHA1key derivation (PRF) AES-CM - AES-CM SRTP包 包结构 123456789101112131415161718192021222324 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&lt;+ |V=2|P|X| CC |M| PT | sequence number | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | timestamp | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | synchronization source (SSRC) identifier | | +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ | | contributing source (CSRC) identifiers | | | .... | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | RTP extension (OPTIONAL) | |+&gt;+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || | payload ... | || | +-------------------------------+ || | | RTP padding | RTP pad count | |+&gt;+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&lt;+| ~ SRTP MKI (OPTIONAL) ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || : authentication tag (RECOMMENDED) : || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || |+- Encrypted Portion* Authenticated Portion ---+ SRTP包主要包括两个部分，分别是： 加密部分：Encrypted Portion 该部分在RTP包负载（payload + padding）的基础上新增了MKI字段和authentication tag字段： MKI (Master Key Identifier)：可变长度，可选字段 该字段最大长度为32比特。该字段表示一个master key，可用于后续生产加密和认证的密钥。 Authentication tag：可变长度，推荐使用 该字段用于存储校验值，其最大长度为32比特。 通常情况下SRTP只需要对RTP负载进行加密，但是也可以对RTP header extensions进行加密，详见 RFC 6904。 校验部分：Authenticated Portion 该部分由RTP的header和Encrypted Portion组成，即RTP包和SRTP新增的字段。值得注意的是完整性校验只针对RTP包本身（header、payload和padding），不包括MKI字段。 SRTP包序号管理 RTP包使用一个16bit的字段来表示序号，其最大值为2^16(65535)，能表达范围很有限，一旦超过最大值便会循环使用之前的序号。因此当收到一个与之前的包列号相同的包时，RTP协议没有办法判断其是一个新包还是之前的包重放了一次，这也是重放攻击的依据所在。 鉴于RTP包序号的局限性，SRTP包序号在RTP包序号的基础上引入回绕技术以表示每个SRTP包的绝对下标。所谓回绕就是RTP包的序号超过最大值65535后重置为0继续使用，SRTP使用ROC来记录RTP包序号的回绕次数，发送端和接收端的具体实现有差异，如下所示： 发送端 由于发送端不存在乱序和丢包的问题，因此只需维护ROC即可，即当RTP包的序号出现回绕时ROC加1： 1234// ROC：32-bit unsigned，初用于表示RTP包的回绕次数，初始值为0// SEQ：16-bit unsigned，RTP包的序号，初始值任意// i：48-bit unsigned，高32位为ROC，低16位为SEQ，表示SRTP包的序号i = 2^16 * ROC + SEQ 接收端 对于接收端，考虑到丢包和乱序的因素，除了维护ROC，还需记录当前已收到的最大的RTP包序号，记为s_l，初始值为第一个RTP包序号。当收到一个新包时，接收端需要推算出当前包所对应的SRTP的序号，具体实现如下： 1234// v：表示当前包可能的回绕次数，取值范围{ ROC-1, ROC, ROC+1 }i = 2^16 * v + SEQ// s：表示当前已收到的最大的SRTP包序号s = 2^16*ROC + s_l v分别取ROC-1、ROC和ROC+1计算出i值，再与s进行比较，假定最接近s的值为新包的SRTP序号。具体分三种情况： v = ROC - 1，表示乱序包，ROC和s_l都不更新 v = ROC，表示正常包，s_l = max(SEQ, s_l) v = ROC + 1，表示正常包但出现回绕，ROC += 1，s_l = SEQ 防重放攻击 所谓重复攻击是攻击者将截获的SRTP/SRTCP包保存下来，然后再重新发送出去，使接收端就会大量出现重复的包，以达到攻击的效果。而防重发攻击的目的就是用最高效的方式识别出重复包并将其丢弃，只处理为接收过的包。 此外，防重放攻击的有效性是基于包的完整性，即提供SRTP协议提供了消息认证，否则攻击者可以任意修改SRTP包的内容，包括序号，导致接收端无法判断被修改过的包是否为重发包。 具体实现方式：在每个SRTP包的接收端会维护一个重发列表replay list，用于存储已收到并校验的SRTP包序号。出于性能考虑不会将所有已接收的SRTP包序号（48bits）都存储起来，而是引入一个滑动窗口SRTP_WINDOW_SIZE来推断新收到的包是否为重发包。SRTP_WINDOW_SIZE是一个定值，最小值要求为64，用户可根据需求自定义，比如WebRTC中SRTP_WINDOW_SIZE的默认值为1024。 SRTP_WINDOW_SIZE将replay list划分为了三个区域，分别表示重发区，待定区和新包区： 123 重发区 | 待定区 | 新包区--replay packet--|---check replay failed---|--new packet-- |-----SRTP_WINDOW_SIZE----| 此外，接收端还需要记录当前接收的最大的SRTP包序号，记为last_packet_index。当接收到新的SRTP包时先推算出其序号，记为packet_index，用于确定新包在replay list中的位置，具体过程如下： 计算差值delta delta = packet_index - last_packet_index 如果delta &gt; 0，表示收到了新包，并更新last_packet_index和replay list。 如果delta &lt; -SRTP_WINDOW_SIZE，表示收到重发包，丢弃。 如果-SRTP_WINDOW_SIZE &lt; delta &lt; 0，表示收到重发窗口之内的包，如果能在replay list中找到相同序号的包则表示收到重发包，否则视为乱序包并接收。 SRTCP包 包结构 123456789101112131415161718192021222324252627282930310 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&lt;+ |V=2|P| RC | PT=SR or RR | length | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | SSRC of sender | |+&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ || ~ sender info ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || ~ report block 1 ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || ~ report block 2 ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || ~ ... ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || |V=2|P| SC | PT=SDES=202 | length | || +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ || | SSRC/CSRC_1 | || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || ~ SDES items ~ || +=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ || ~ ... ~ |+&gt;+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+ || |E| SRTCP index | || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&lt;+| ~ SRTCP MKI (OPTIONAL) ~ || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || : authentication tag : || +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ || |+-- Encrypted Portion Authenticated Portion -----+ SRTCP包主要包括两大部分，分别是： 加密部分：Encrypted Portion 该部分在RTCP包负载的基础上新增了四个字段，分别是： E-flag：1 bits，必需值。 该字段用于标识SRTCP包是否加密。 SRTCP index：31 bits，必需值。 该字段表示SRTCP包的序号。不同于SRTP包序号使用回绕技术的处理方式，SRTCP包序号只是简单的将RTCP包序号的长度从16比特扩展为32比特，即同样会出现序号回绕的情况，只是间隔时间更长。 MKI：可变长度，可选值。 该字段的作用同SRTP中的MKI字段一样。 authentication tag：可变长度，必须值。 该字段的作用同SRTP中的MKI字段一样，只是在SRTCP包要求必须支持完整性校验。原因在于SRTCP包中携带的是控制RTP包发送和接收端反馈等重要信息，决定着整个传输的效果，所以需要确保其数据是完整的。 校验部分：Authenticated Portion 该部分由RTCP的header和Encrypted Portion组成，即RTCP包和SRTCP新增的字段。值得注意的是完整性校验只针对RTCP包本身（header、payload），不包括MKI字段。 防重放攻击 SRTCP防重放攻击的实现方式与SRTP基本相同，不同的地方在于SRTCP使用的滑动窗口大小更小，比如在libsrtp库中的值为128。 总结SRTP/SRTCP协议主要是为RTP/RTCP协议提供数据安全保障，即数据加密、数据校验和防重放攻击。从其实现细节可知SRTP/SRTCP并不保证数据的有序性和可靠性，即不提供丢包和乱序包的保障。 参考资料RFC 3711 - The Secure Real-time Transport Protocol (SRTP) RFC 5764 - Datagram Transport Layer Security (DTLS) Extension to Establish Keys for the Secure Real-time Transport Protocol (SRTP) WebRTC 传输安全机制：深入显出 SRTP 协议","link":"/2020/11/20/WebRTC%E4%B9%8B%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE%E5%88%9D%E6%8E%A2%EF%BC%9ASRTP%E5%8D%8F%E8%AE%AE/"},{"title":"Objective-C Runtime 解析","text":"这是一篇译文，作为一个英语水平处于半吊子的理科男，因此一定存在不尽原意的地方，翻译此文纯属个人喜好，希望能得到大家的指点和反馈，读者如有兴趣的话可以查看原文。 以下是正文： 一般而言，当人们刚接触Cocoa/Objective-C的时候，运行时机制（Objective-C Runtime）是最容易被忽视的特征之一。究其原因在于Objective-C是一门简单的语言，花费几个小时便能入门，此后，新手们通常会将大部分的时间和精力用于研究Cocoa Framework以及如何使用它。然而，每一个人至少应该清楚运行时是如何运转的，而不仅仅停留在编译方式的认知层面，如：[target doMethodWith:var];编译之后变成object_msgSend(target,@selector(doMethodWith:),var1)。了解运行时机制的工作原理可以帮助你进一步理解Objective-C这门语言以及你编写的App的运转流程。我相信各个水平层次的Mac/iPhone开发者都会在研究运行时机制的过程中有所收获。 Objective-C Runtime库是开源的Objective-C Runtime库是开源的，你随时可以在源代码上查阅。事实上，查阅源代码是弄清楚Objective-C原理的首选途径之一，胜过阅读苹果开发文档。下载最新版本的源代码点击我。 动态 &amp; 静态 语言Objective-C是基于运行时的语言，意味着它会尽可能地将决定代码执行逻辑的操作从编译&amp;链接阶段延迟到代码被执行的阶段。这将给你带来很大的灵活性，因此如果有必要的话你可以将消息重定向到合适的对象，或者你甚至可以交换两个方法实现，等等。实现上述功能需要运行时具备审查对象可以响应哪些请求和不能响应哪些请求然后准确地派发消息的能力。如果我们将Objective-C这一特性对比C语言。C语言程序运行始于main()函数，基于至上而下的设计执行你的逻辑和调用你实现的函数。C结构体不能通过发送请求到其他的结构体来执行某个函数。很可能你会编写一段C语言代码，如下所示： 123456#include &lt; stdio.h &gt;int main(int argc, const char **argv[]){ printf(\"Hello World!\"); return 0;} 上述代码经过编译器编译、优化，然后将优化后的代码转化成汇编语言： 12345678910111213141516171819202122232425262728.text .align 4,0x90 .globl _main_main:Leh_func_begin1: pushq %rbpLlabel1: movq %rsp, %rbpLlabel2: subq $16, %rspLlabel3: movq %rsi, %rax movl %edi, %ecx movl %ecx, -8(%rbp) movq %rax, -16(%rbp) xorb %al, %al leaq LC(%rip), %rcx movq %rcx, %rdi call _printf movl $0, -4(%rbp) movl -4(%rbp), %eax addq $16, %rsp popq %rbp retLeh_func_end1: .cstringLC: .asciz \"Hello World!\" 随后链接相关的库生成一个可执行文件。对比于Objective-C，虽然代码处理过程很相似，但是编译后的代码取决于Objective-C Runtime库。当我们最初学习Objective-C时被告知中括号里面的代码是如何被处理的，如下 1[self doSomethingWithVar:var1]; 被转变成 1objc_msgSend(self,@selector(doSomethingWithVar:),var1); 除此之外我们并不真的知道运行时机制是如何工作的，也许很久以后会知道。 何为Runtime(运行时)Objective-C Runtime就是一个Runtime库，主要有C语言&amp;汇编语言编写而成，在C语言的基础上加上面向对象的功能之后就成为了Objective-C语言。这意味着运行时机制负责加载类，方法派发，方法传达等操作。本质上而言，运行时机制提供了所有的需要的结构用以支持Objective-C的面向对象编程。 Objective-C 运行时术语在进一步深入之前，让我们扫清一些术语的障碍，这样使我们处于同一立场。就MacOS X App &amp; iPhone OS App开发者所关心而言，这里有两种运行时机制: Modern Runtime和Legacy Runtime。Modern Runtime适用于所有64位MacOS应用和所有iPhone应用，Legacy Runtime适用于所有的32位MacOS应用。运行时机制中有两种类型的函数：实例函数（以‘-’符号开头如-(void)doFoo）;类函数（以‘+’开头如+(id)alloc）。两种函数都与C函数很像，包含一组实现某个任务的代码，如下所示 1234-(NSString *)movieTitle{ return @\"Futurama: Into the Wild Green Yonder\";} 选择器：在Objective-C中，选择器本质上是一个C数据结构体用以标识一个对象将要执行的函数。在运行时机制中的定义如下 1typedef struct objc_selector *SEL; 使用方式 1SEL aSel = @selector(movieTitle); 消息调用： 1[target getMovieTitleForObject:obj]; Objective-C消息就是中括号[]里面的所有东西，包括消息的接受者target，调用的函数getMovieTileForObject以及所有发送的参数obj。消息调用虽然样式上类似于c函数调用但是实现却不同。实际上，当你发送一个消息给一个对象并意味着函数会被执行。对象可能会检测谁是消息的发送者，基于此再决定执行一个不同的函数或者转送消息给其他不同的目标对象。如果你查看运行时机制里的类定义，你将会看到如下所示的内容： 1234typedef struct objc_class *Class;typedef struct objc_object { Class isa;} *id; 这里有几个要点。首先是类Class和对象Object都有一个对应的结构体。所有的objc_object结构体都有一个类指针isa，这就是我们所说的“isa指针”。运行时机制需要通过检测一个对象的isa指针去查看对象的类别，然后查看该对象是否能响应你当前发送过来的消息。接下来是id指针，id指针默认不属于任何类别只表明指向的是一个Objective-C对象。对于id指针指向的对象，你可以获知对象的类别，查看对象是否能响应某个函数等等，然后当你具体了解了id指针指向的对象之后便可以更好的使用该对象。你同样可以查看LLVM/Clang文档中Blocks的定义： 1234567891011121314struct Block_literal_1 { void *isa; // initialized to &amp;_NSConcreteStackBlock or &amp;_NSConcreteGlobalBlock int flags; int reserved; void (*invoke)(void *, ...); struct Block_descriptor_1 { unsigned long int reserved; // NULL unsigned long int size; // sizeof(struct Block_literal_1) // optional helper functions void (*copy_helper)(void *dst, void *src); void (*dispose_helper)(void *src); } *descriptor; // imported variables}; Block结构的设计兼容于运行时机制。因此Block被视为一个Objective-C对象，所有也就可以响应消息如-retain,-release,-copy等等。 IMP:Method Implementations 1typedef id (*IMP)(id self,SEL _cmd,...); IMP是一个函数指针，由编译器生成且指向函数的实现内容。如果你目前是一个Objective-C新手则浅尝辄止，但是我们随后会了解运行时机制是如何调用你的函数的。 Objective-C类：类里面是什么？在Objective-C中，类实现基本上类似于： 1234567@interface MyClass : NSObject {//varsNSInteger counter;}//methods-(void)doFoo;@end 但是类在运行时机制中定义远不如此，如下 1234567891011#if !__OBJC2__ Class super_class OBJC2_UNAVAILABLE; const char *name OBJC2_UNAVAILABLE; long version OBJC2_UNAVAILABLE; long info OBJC2_UNAVAILABLE; long instance_size OBJC2_UNAVAILABLE; struct objc_ivar_list *ivars OBJC2_UNAVAILABLE; struct objc_method_list **methodLists OBJC2_UNAVAILABLE; struct objc_cache *cache OBJC2_UNAVAILABLE; struct objc_protocol_list *protocols OBJC2_UNAVAILABLE;#endif 我们可以看到一个类中声明了一个父类的引用，类名，实例变量列表，方法列表，缓存以及协议列表。当响应发送给类或对象的消息时，运行时机制需要用到这些信息。 类定义对象同时类本身也是对象？何解？之前我提到过在Objective-C中类本身也是对象，运行时机制通过引入元类（Meta Class）来处理类对象。当你发送一个类似于[NSObject alloc]消息的时候，实际上是发送一个消息给类对象，此时将类对象视为元类的实例对待，而元类本身也是一个根元类（Root Meta Class）的实例。While if you say subclass from NSObject, your class points to NSObject as it’s superclass. However all meta classes point to the root metaclass as their superclass. (原文似乎表达观点有误，暂不翻译)。所有的元类仅有一个类函数列表（不同于类处理实例函数列表，还有变量列表和协议列表等等）。因此，当你发送一个消息给类对象时，如[NSObject alloc]，objc_megSend()实际上是搜索元类的函数列表查看是否有响应的函数，如果存在则在该类对象上执行该函数。 为什么继承Apple的原生类？在你刚开始Cocoa编程时，相关教程都是说创建一个类继承于NSObject然后开始编写自己的代码，简单地继承Apple的原生类会让你获益匪浅。其中一个你甚至意识不到的好处就是让你创建的类运行于运行时机制之上。当我们新建一个实例对象，如下： 1MyObject *object = [[MyObject alloc] init]; 最先被执行的消息是+alloc。如果你查阅这个文档会发现：“isa这一实例变量被初始化指向一个描述对于类的数据结构体，其他所有的实例变量都被初始化为0”。所以，通过继承Apple原始类不仅仅继承一些不错的属性，而且还能让我们轻易地创建符合于运行时机制要求的对象（包含一个指向类的isa指针）。 类缓存机制当OC的运行时机制机制通过检视一个对象的isa指针指向的类时会发现该对象实现了很多函数。然而，你可能仅仅调用其中的一小部分也就意味没必要每一次查找某个函数时都去搜索一遍类中的函数列表。因此，类创建了缓存，将你每次搜索函数列表后找到的相应函数存入缓存中。所以，当objc_msgSend()在类中搜寻某个函数是首先会遍历缓存列表。这样做的理论依据在于如果你发送过某个消息给一个对象，你很可能回再次发送同样的消息。因此如果我们将该理论考虑在内意味着如果你有一个NSObject的子类MyObject,并运行以下代码： 1234567891011MyObject *obj = [[MyObject alloc] init];@implementation MyObject-(id)init { if(self = [super init]){ [self setVarA:@”blah”]; } return self;}@end 接下来发生： [MyObject alloc]最先被执行。因为MyObject类没有实现alloc函数所以在该类自然找不到对应的函数，随后进入父类指针指向的NSObject类。 询问NSObject类是否响应+alloc，发现其实现了alloc函数。+alloc检测到接收类是MyObject然后分配一块响应大小的内存并在其中初始化一个isa指针指向MyObject类。现在，我们获得了一个实例对象，随后运行时机制将NSObject类的+alloc函数指针存入NSObject对象对应的类中的缓存列表中。 截至目前，我们发送了一个类消息，现在我们发送一个实例消息：调用-init函数或者自定义的初始化函数。显然，MyObject的实例对象能响应这个消息，因此-(id)init会被存入缓存列表中。 随后self=[super init]被调用。super作为一个魔法关键字指向父类对象，因此转向NSObjct类中，调用init函数。这样做是为了确保面向对象继承体系（OOP inheritance）正常运转，因为所以的父类都将会正确地初始化它们的变量，然后作为子类对象可以正确地初始化自身的变量和必要时重载父类。 在这个NSObject类的例子中，没有特别的要点出现。但是事实并不总是如此，有时候初始化很重要，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#import &lt; Foundation/Foundation.h&gt; @interface MyObject : NSObject{ NSString *aString;} @property(retain) NSString *aString; @end @implementation MyObject -(id)init{ if (self = [super init]) { [self setAString:nil]; } return self;} @synthesize aString; @end int main (int argc, const char * argv[]) { NSAutoreleasePool * pool = [[NSAutoreleasePool alloc] init]; id obj1 = [NSMutableArray alloc]; id obj2 = [[NSMutableArray alloc] init]; id obj3 = [NSArray alloc]; id obj4 = [[NSArray alloc] initWithObjects:@\"Hello\",nil]; NSLog(@\"obj1 class is %@\",NSStringFromClass([obj1 class])); NSLog(@\"obj2 class is %@\",NSStringFromClass([obj2 class])); NSLog(@\"obj3 class is %@\",NSStringFromClass([obj3 class])); NSLog(@\"obj4 class is %@\",NSStringFromClass([obj4 class])); id obj5 = [MyObject alloc]; id obj6 = [[MyObject alloc] init]; NSLog(@\"obj5 class is %@\",NSStringFromClass([obj5 class])); NSLog(@\"obj6 class is %@\",NSStringFromClass([obj6 class])); [pool drain]; return 0;} 如果你是Cocoa初学者，然后我问你上述代码的打印结果，你的回答可能如下： 123456NSMutableArrayNSMutableArray NSArrayNSArrayMyObjectMyObject 但是运行结果却是： 123456obj1 class is __NSPlaceholderArrayobj2 class is NSCFArrayobj3 class is __NSPlaceholderArrayobj4 class is NSCFArrayobj5 class is MyObjectobj6 class is MyObject 这是因为在Objective-C中，调用+alloc会隐性地返回一个类的实例对象而调用-init会返回另外一个类的实例对象。 objc_msgSend的工作流程是什么？objc_msgSend函数实现比较复杂。比如我们写了如下代码… 1[self printMessageWithString:@\"Hello World!\"]; 上述代码实际上会被编译器转化成： 1objc_msgSend(self,@selector(printMessageWithString:),@\"Hello World!\"); 随后，objc_msgSend函数根据目标对象的isa指针去查询对应的类（或者任一父类）看是否响应选择器@selector(printMessageWithString:)。假设在类的函数派发列表或者缓存中找到了对应的函数实现，那么执行该函数。如此看来，objc_msgSend函数没有返回值，它开始执行然后找到对应的目标函数并执行，因此目标函数的返回值被视为objc_msgSend函数的返回值。 Bill Bumgarner对于objc_msgSend的研究比我要表达的更为深入（part 1,part 2,part 3）。总结一下他所要表达的以及你在查阅运行时机制源代码时可能发现的内容： 检测屏蔽的函数和死循环，很显然如果代码运行在垃圾回收的环境下，我们可以忽略-retain,-release的调用，诸如此类。 检测空对象。 不同于其他编程语言，在Objective-C中发送一个消息给空对象是完全合法的。[there are some valid reasons you’d want to. Assuming we have a non nil target we go on… ] 然后在一个类中查找函数指针，首先是搜索缓存列表，如果找到了对应的函数指针就跳转对其实现代码段，即执行函数。 如果在缓存列表中没有找到对应的函数指针，便搜索类中的函数派发列表。如果找到了对应的函数指针即跳转到其实现代码段。 如果在缓存列表和函数列表都没有找到对应的函数，随即跳转到消息转发机制，意味着代码会被编译成c语言代码。所以一个函数如下所示： 1-(int)doComputeWithNum:(int)aNum 将会被编译成： 1int aClass_doComputeWithNum(aClass *self,SEL _cmd,int aNum) 此时，运行时机制通过这些函数的指针来调用这些转化后的函数，现在你已经不能直接调用这些函数，但是Cocoa库提供了一个方法来获得这些函数的函数指针。。。 12345678910//declare C function pointerint (computeNum *)(id,SEL,int); //methodForSelector is COCOA &amp; not ObjC Runtime//gets the same function pointer objc_msgSend getscomputeNum = (int (*)(id,SEL,int))[target methodForSelector:@selector(doComputeWithNum:)]; //execute the C function pointer returned by the runtimecomputeNum(obj,@selector(doComputeWithNum:),aNum); 这样，你可以知道访问这些函数并在运行时中直接调用，甚至利用这种方法来绕开运行时的动态调用来确保一个指定的函数被执行。运行时机制同样可以调用你的函数，只不过是通过objc_msgSend()。 Objective-C消息传送在Objective-C中，发送一个消息给一个不会做出响应的对象是合法的，甚至可能是有意这样设计的。苹果在其开发文档中给出的原因之一是为了模拟Objective-C不支持的多继承，或者你只是想抽象化你的设计，隐藏能处理这些消息的实例对象或类。这是运行时机制必要的功能之一。消息传送工作流程： 运行时机制搜寻了对象的类和它所有父类中的缓存列表和函数列表，但是并没有找到指定的方法。 随后运行时机制将会调用你类中的 +(BOOL)resolveInstanceMethod:(SEL)aSEL方法给你一次机会为指定的函数提供函数实现，并告诉运行时机制你已经实现了这个方法。如果运行时机制再次搜索这个函数就能找到对应的函数实现。你可以如下所示，实现这个功能： 定义一个函数 1234void fooMethod(id obj, SEL _cmd){ NSLog(@\"Doing Foo\");} 如下所示，使用class_addMethod()来实现 12345678+(BOOL)resolveInstanceMethod:(SEL)aSEL{ if(aSEL == @selector(doFoo:)){ class_addMethod([self class],aSEL,(IMP)fooMethod,\"v@:\"); return YES; } return [super resolveInstanceMethod];} class_addMethod()最后一个参数“v@:”表示函数fooMethod的返回值和参数，你可以在运行时机制指南中类型编码Type Encodings了解你可以具体的规则。3. 运行时机制随后会调用- (id)forwardingTargetForSelector:(SEL)aSelector函数，给你一次机会将运行时指向另外一个能响应目标函数的对象。这样做比触发消耗更大的函数：-(void)forwardInvocation:(NSInvocation *)anInvocation更划算。你的具体实现可能如下所示： 1234567- (id)forwardingTargetForSelector:(SEL)aSelector{ if(aSelector == @selector(mysteriousMethod:)){ return alternateObject; } return [super forwardingTargetForSelector:aSelector];} 很显然你不想返回self指针，否则可能导致死循环。 此时，运行时机制尝试最后一次去获取消息的预期目标，并调用- (void)forwardInvocation:(NSInvocation *)anInvocation。如果你未曾了解NSInvocation点击查看,这是Objective-C消息中很重要的构成部分。一旦你持有一个NSInvocation对象，你基本上可以更改消息的任何内容，包括目标对象，选择器和函数参数。你可能操作如下： 12345678910-(void)forwardInvocation:(NSInvocation *)invocation{ SEL invSEL = invocation.selector; if([altObject respondsToSelector:invSEL]) { [invocation invokeWithTarget:altObject]; } else { [self doesNotRecognizeSelector:invSEL]; }} 如果类是继承自NSObjct，- (void)forwardInvocation:(NSInvocation *)anInvocation函数的默认实现是调用-doesNotRecognizeSelector函数，如果你还想做点什么来响应这次消息转送，重载这个函数将是最后一次机会。 实例变量的无碎片化（Modern Runtime）目前我们所了解到关于Modern Runtime的概念之一是实例变量无碎片化（Non Fragile ivars）。编译器在编译类的时候确定了实例变量的布局，决定了某个实例变量的访问位置。这属于底层细节，关乎于获得一个对象的指针，查找某个实例变量相对于对象起始位置的偏移，根据实例变量的类型读取相应数量的字节。因此，实例变量的布局可能如下所示，左侧的数字表示实例变量的字节偏移量 如上所示，NSObject对象的实例变量布局以及继承NSObject后添加了自己的变量之后的布局。这样的布局在苹果发布更新之前都能正常运行，但是苹果发布了Mac OS X 10.6之后，布局就会变成如下所示： 因为与父类的实例变量重叠，自定义的对象的实例变量被抹掉。防止这样的情况发生唯一的可能是苹果能保持更新之前的布局。但是如果苹果这样做的话，那么苹果的框架将不可能得到改进，因为这些框架的实例变量布局已经写死了。处于实例变量碎片化的情况下只能通过重新编译所有继承于苹果类的类来保证兼容新的框架。那么实例变量无碎片化的情况下会是如何处理？ 实例变量无碎片化的前提下，编译器创建同实例变量碎片化情况下一样的实例变量布局。但是当运行时检测到一个重叠的父类时会调整自定义变量的偏移量，因此子类中自定义的变量得以保留。 Objective-C 关联对象最近Mac OS X 10.6 Snow Leopard推出了一个新特性，称之为关联引用。不同于其他一些语言，Objective-C不支持动态添加实例变量到某个对象的类中。所以在此之前你不得不耗尽脑力去构建一个特定的基础架构，营造一个可以给某个对象动态添加变量的假象。现在在Mac OS X 10.6中，运行时已经支持这一功能。如果想添加一个变量到任一个已经存在的苹果原生类中，比如NSView，我们可以做如下操作： 123456789101112131415161718192021222324#import &lt; Cocoa/Cocoa.h&gt; //Cocoa#include &lt; objc/runtime.h&gt; //objc runtime api’s @interface NSView (CustomAdditions)@property(retain) NSImage *customImage;@end @implementation NSView (CustomAdditions) static char img_key; //has a unique address (identifier) -(NSImage *)customImage{ return objc_getAssociatedObject(self,&amp;img_key);} -(void)setCustomImage:(NSImage *)image{ objc_setAssociatedObject(self,&amp;img_key,image, OBJC_ASSOCIATION_RETAIN);}@end 在runtime.h头文件中可以看到存储关联对象方式的可选项，作为objc_setAssociatedObject()函数的参数传入。 123456789101112/* Associated Object support. */ /* objc_setAssociatedObject() options */enum { OBJC_ASSOCIATION_ASSIGN = 0, OBJC_ASSOCIATION_RETAIN_NONATOMIC = 1, OBJC_ASSOCIATION_COPY_NONATOMIC = 3, OBJC_ASSOCIATION_RETAIN = 01401, OBJC_ASSOCIATION_COPY = 01403}; 这些可选值与@property语法的可选值相匹配。 混合虚函数表派发（Hybrid vTable Dispatch）如果你查阅现代版运行时的源代码，你会看到以下内容（位于objc-runtime-new.m）: 12345678910111213141516171819202122232425262728293031/************************************************************************ vtable dispatch* * Every class gets a vtable pointer. The vtable is an array of IMPs.* The selectors represented in the vtable are the same for all classes* (i.e. no class has a bigger or smaller vtable).* Each vtable index has an associated trampoline which dispatches to * the IMP at that index for the receiver class's vtable (after * checking for NULL). Dispatch fixup uses these trampolines instead * of objc_msgSend.* Fragility: The vtable size and list of selectors is chosen at launch * time. No compiler-generated code depends on any particular vtable * configuration, or even the use of vtable dispatch at all.* Memory size: If a class's vtable is identical to its superclass's * (i.e. the class overrides none of the vtable selectors), then * the class points directly to its superclass's vtable. This means * selectors to be included in the vtable should be chosen so they are * (1) frequently called, but (2) not too frequently overridden. In * particular, -dealloc is a bad choice.* Forwarding: If a class doesn't implement some vtable selector, that * selector's IMP is set to objc_msgSend in that class's vtable.* +initialize: Each class keeps the default vtable (which always * redirects to objc_msgSend) until its +initialize is completed.* Otherwise, the first message to a class could be a vtable dispatch, * and the vtable trampoline doesn't include +initialize checking.* Changes: Categories, addMethod, and setImplementation all force vtable * reconstruction for the class and all of its subclasses, if the * vtable selectors are affected.**********************************************************************/ 上述内容阐述的要点就是运行时会尽量存储调用最频繁的函数以达到提高软件运行速度的目的，因为通过虚函数表查找比调用objc_msgSend函数使用的指令更少。虚函数表中的16个函数调用次数远多于其他所有函数。实际上，进一步深入研究代码你会发现垃圾回收机制和无垃圾回收机制下虚函数表中默认的函数： 123456789101112131415161718192021222324252627282930313233343536static const char * const defaultVtable[] = { \"allocWithZone:\", \"alloc\", \"class\", \"self\", \"isKindOfClass:\", \"respondsToSelector:\", \"isFlipped\", \"length\", \"objectForKey:\", \"count\", \"objectAtIndex:\", \"isEqualToString:\", \"isEqual:\", \"retain\", \"release\", \"autorelease\", };static const char * const defaultVtableGC[] = { \"allocWithZone:\", \"alloc\", \"class\", \"self\", \"isKindOfClass:\", \"respondsToSelector:\", \"isFlipped\", \"length\", \"objectForKey:\", \"count\", \"objectAtIndex:\", \"isEqualToString:\", \"isEqual:\", \"hash\", \"addObject:\", \"countByEnumeratingWithState:objects:count:\", }; 那么你如何知道是否调用了这些函数？调试模式下，你将会在栈中看到以下函数中的某一个被调用，出于调试的目的，所有的这些方法都可以视为通过objc_msgSend函数调用的。 objc_msgSend_fixup：是当运行时正在派发一个位于虚函数表的函数时触发，即用于派发虚函数表中的函数。 objc_msgSend_fixedup：是当调用一个本应存在于虚函数表的函数但是现在已经不存在的函数时触发（个人觉得应该是调用在objc_msgSend_fixup函数之后，并且由前者触发的）。 objc_msgSend_vtable[0-15]：调试模式下，也许会看到某个函数调用类似于objc_msgSend_vtable5意味着正在调用虚函数表中对应序号的某个函数。 运行时可以决定是否派发这些函数，所以不要指望以下这种情况存在：objc_msgSend_vtable10在运行时的一次循环中对应的函数是-length,意味着后面任一次循环中也是同样情况。 结论我希望你能喜欢这些内容，这篇文章基本上覆盖了我在Des Moines Cocoaheads 上谈及的内容。Objective-C运行时是一个了不起的杰作，它为我们的Cocoa/Objective-C应用提供了一个强大的平台，让很多我们正在受用的功能都成为可能。如果你还没有查阅关于如何使用Objective-C运行时的Apple开发文档，我希望你马上行动，谢谢。附上：运行时开发文档，运行时介绍文档","link":"/2015/01/01/objective-c_runtime_%E8%A7%A3%E6%9E%90/"},{"title":"《人类简史》第一部分认知革命读书笔记","text":"人类：只是一种普通的动物一直以来，我和很多人一样以为地球同一时期只有一种人类且是独特于其他的物种之外的特殊物种，不然怎么会站在了食物链的顶端。现在我才知道这种想法是错误的，其实我们现代人即智人（human sepiens）只是人属的一种，就像豹属包括狮子，豹子等。人属也包括多个物种，只是现存的人种只有智人，就容易让人造成智人是唯一人种的假象。 早在250万年前人类开始由猿属中的南方古猿开始演化，人类的足迹在200万年前开始从东非欧亚大陆扩散，结合当地的环境各自演化出不同的人种，有匠人、鲁道夫人、尼安德特人、直立人、梭罗人等等。这些人分别先后出现，并在某一段时间同时存在地球的不同地方。其中，直立人出现时间是200万年前到5万年前，存活了将近200万年，是目前所知存续时间最长的人类物种，目前地球上唯一的人种智人已知的是大约15万年前在非洲出现，具体何时、有何种早期人类演化而来无从得知，就目前的发展来看是很难打破直立人存续的记录了。此外，这些人种的演化并不是呈线性发展的，这些人种在大约200万年前到大约一万年前之间同时存在世界各地，各种进化或灭亡，直到一万年前左右，仅剩下智人一种人类。 人类比其他物种有一个共同特征就是脑容量大。然而庞大的大脑也是庞大的负担，大脑不仅结构脆弱且消耗能量巨大，占身体体重约2%~3%却消耗能量占25%。时至今日，大脑发达带来的好处显而易见，但是远古人类为此付出一定的代价，主要包括两种：一是人类需要更多的食物满足热量需求，其次就是为了保证大脑能量供需导致肌肉退化萎缩。至于为什么人类大脑会在200万年间不断演化，无从得知。 人类另外一个共同特征就是直立行走，直立行走将手从移动的功能中分离出来，着重神经发展，进一步演化成可以处理精细任务。与此同时，直立行走也有不利之处。直立行走意味着脊椎需要支撑一个超大的头盖骨，为此需要面对背痛与颈椎脖子疾病。特别对妇女造成的负担更大，直立行走需要让臀部变窄，然而根据人类演化趋势，婴儿的头越来越大，从而导致分娩风险增高。于是，根据自然选择的原理，在婴儿还尚未完全发育之前分娩，这时候头部毕竟小且柔软，风险也会降低很多。所以，相对于其他物种，人类都是早产儿，许多重要的器官都未发育完善，出生之后需要母亲的悉心呵护与培养。这也是导致人类发展出突出的社交技巧的原因之一。正因为小孩出生后需要长时间的抚养，作为母亲必须依赖于家族部落的协助才能获得足够的食物，为此需要一种能够形成强大的社会关系的能力。此外，人类出生后的发育不完善也意味着更好的可塑性，需要外界的教育，这也依托于强大的社会化的背景。正因如此，人类的性格、信仰和价值观等观念才会各种各异，才有基督徒或佛教徒，自由主义者或民族主义者，好战派或和平派。 尽管人类拥有超强的大脑，但是在过去的200万年前，人类一直都是一种弱小、边缘化的物种。直到10万年前，智人这一人类物种崛起，一跃而居于食物链的顶端才结束弱者的命运。然而，这次仓促的跳跃对整个生物链造成了巨大的影响。在此之前其他处于食物链顶端的物种都是经过好几百万年的进化才站上了顶峰，因此生态系统有足够的时间协调各物种之间的平衡。相比之下，智人在很短的时间内一步青云，让生态系统猝不及防，人类本身也不知所措，为此付出的代价就是人类史上众多的灾难。 在人类踏上食物链顶端的路上，火的使用功不可没。早在80万年前部分人类偶然的机会学会使用火，到了30万年前直立人、尼安德特人以及智人的祖先已经能够熟练的使用火。火之于人类有两大主要好处：一是烹饪食物，烹饪食物不仅扩大了食物来源，使原本不可直接使用的食物，比如小麦、马铃薯等食物再烹饪供人类使用。此外烹饪让食物发生化学反应，同时对食物进行高温消毒，大大地减少了人类咀嚼与消化食物的时间。这样不仅让人类的牙齿缩小，肠道缩短，还能提供更多的热量供大脑发育。第二个好处是火可以成为御敌的工具，不同于其他动物经过数百万年进化而来的利爪或翅膀，这些功能都无法突破先天的身体限制，而火是一种可操作且力量无穷的工具，为人类更好的存续提供了保障。 在200万年前1万年前，地球上的还存在多个人类物种，但是随着智人的出现以及扩散，其他物种先后走上了灭绝的道路。每当智人到达某个地方，当地原本的人种就在不久之后消失了。究其原因，有两种大相径庭的理论。一是“混种繁衍理论”，即智人与其他人种混种繁衍，最终形成了现代的人类。另外一种则是“替代理论”，即不同物种之间处于争夺资源与排外的情绪，互相厮杀，最终智人取得了胜利，替代了原有人类。最近数十年，替代理论一直是大致共识，不仅因为有考古证据支持，政治上也更为正确。如果非洲人、欧洲人和亚洲人是智人与不同人类物种的混种后代，那么基因上的差异也会很大，那么在政治、民族等多个方面的理解也会存在差异，从而导致种族间的大冲突，然而现实情况并非如此。然而，混种繁衍理论也并非没有可能。最近的一些研究发现中东和欧洲人有%1%4尼安德特人的基因，澳大利亚原住民和现代美拉尼西亚人有6%的丹尼索瓦人的基因。如果这些发现属实，则说明混种繁衍理论至少是部分正确，有可能在某个时间点，不同人种还属于同一人种的不同族群，即使族群差异到了一定程度，但是仍然可以交配产下后代，再经过进一步演化才彻底切断彼此连接，形成两种不同的物种，也就不能再混种繁衍了。也许在物种分化的某个灰色地带，尼安德特人与智人在即将演化成两个不同的物种之前发生了混种繁衍，并产生了新的人类，导致智人的基因中残存着尼安德特人的DNA。 按照自然选择的规律来说，尼安德特人比智人进化的更完善，有更大的大脑和更发达的肌肉。但是结果却是智人存活了下来，而尼安德特人在地球消失了。智人最终成为最后的人类，战胜了其他人类物种的真实原因不得而知，但是有一个很有说服力的解答，那就是：智人有独特的语言。 知善恶树在距今7万~3万年前，智人发生了认知革命，具体原因不得而知，普遍认为是某次基因突变，改变智人大脑内部连接方式，从而改变了智人的思维方式与沟通语言能力。智人的语言并不是世界上第一种语言，每种动物都有其交流的语言，并且有其精密复杂的结构。然而，智人的语言较于其他动物的语言，它更为灵活，通过有限的词汇排列组合，可以产生无限多的句子和含义，从而大幅度提高了交流的效率。另外智人的语言有“八卦”和“虚构”的功能。 智人可以通过“八卦”功能让部落规模变得更大。在一般的动物族群里，成员数量一般在20~50左右。族群的团结依赖于首领的管理与威望。一旦族群扩大，族群内部就会发生动摇，最后造成分列。即便如此，八卦维系的规模也是有限制。社会研究学家指出，借由八卦维持的最大“自然”团体一般是150人。原因在于超过这个数之后，团体之间就不能深入了解和八卦彼此的生活情况。然而，事实是智人突破了这个界限，创造出了城市、国家等这些有成千上万成员的团体。其原因很可能在于智人的语言的“虚构”功能，能够虚构一些现实中不存在的事物，“虚构”这一功能不仅可以让智人拥有想象，更重要的意义在于可以让大家一起想象，共同相信某个虚构的事物，从而可以共同合作。现实生活中，很多的概念都是虚构的，包括国家，民族，宗教，金钱，法律，人权，正义等等。只是我们现代人从出生就接触这些概念，根本没怀疑它们的真实性，更不会发觉它们只是存在我们共同的想象之中。 在没有发生认知革命之前，智人和其他具有社会行为的动物一样，行为有相当的程度是有基因决定的。因此，一旦出现社会结构改变、发明新科技或者移居都是因为基因突变或者环境改变导致的。正因如此，远古人类没有什么革命性的改变。然而，智人出现认知革命之后，可以基于某个虚构的故事让大批互不相识的人有效的进行合作，而且只要改变虚构故事的内容，合作的方式也随之改变。这意味着智人找到了一条绕开基于组的快车道，可以迅速改变社会结构和发展速度。 认知革命通过虚构故事创造了很多想象现实，也发展处许多的行为模式，这成为我们所谓的“文化”的主要成分。文化出现之后，无法停止地继续改变和发展，就成了我们所谓的“历史”。认知革命正是历史从生物学中脱离而独立存在的起点。在此之前，所有人类的行为属于生物学的范畴，因为都是有基因主导的。换言之，智人生存在一个双重现实的社会中，一方面是客观存在的现实，即生物的范畴，另外一方面的虚构的现实，即历史和文化的范畴。生物学与历史的关系可以简化为三点：1、基本上，生物学为智人的行为和能力设下了基本限制，设定了一个活动范围，所有的历史都在这个范围之内发生。 2、然而，这个范围非常大，能让智人有各种惊人的发挥空间，让虚构故事的能力和虚构的故事不断发展精进。 3、想了解智人的行为，就必须描述人类行为的历史演化，而不能只考虑人类在生物上的限制。 智人通过认知革命发展出独特的语言，无异于获得了《圣经》里面那个知善恶树的果实，从此改变了智人的命运，智人摇身一变成为了亚丹和夏娃。 亚丹和夏娃一天在智人的历史上，绝大多数时间都是靠采集为生。相比于几万年时长的采集生活，智人已知或者现存的生活方式不足以改变人类的思维方式。换言之，现代人类早在农业时代之前的采集时代就开始塑形，我们的大脑和内心的思维方式仍停留在以狩猎和采集的时代。农业革命之后，人类大脑的进化速度远不及周围生活环境的发展速度，造成了一种物质世界与内心世界脱轨的普遍现象。 这种现象影响这现代人生活的方方面面，狩猎采集时代的思维方式深植于我们的潜意识中。其中包括是已经得到广泛接受的“贪吃基因”理论和颇具争议的“一夫一妻制”。远古人类在那个甜食匮乏的时代为了获得更多的热量会偏爱高热量的甜食，导致物质丰富的现代人不知觉地喜爱甜食，造成肥胖等疾病。 因此，想要更好地了解我们自己、我们的社会和政治，就需要更了解我们祖先的生活条件。然而，我们对于采集者祖先的生活几乎没有可以确定的事实。目前普遍的研究方法有两种，一是考古学研究，通过远古社会遗存的文物进行推断。然而远古的狩猎采集生活用具保存下来的大都是骨骼化石和石器，其他容易腐烂的材料都无从考证，另外远古人类没有固定的生活居住地，而是不断的迁移，所以很少使用人造物品。因此，通过现存文物来还原远古人类的生活必定会有偏差；另外一种研究方式是人类学观察，通过研究现存的采集社会来推测远古采集社会的样貌。首先，现存采集社会多少已经受到周围的农业或者工业社会影响，不可同日而语。其次，现存的采集社会之所以能够存活到现在，是因为它们都位于气候恶劣或者地形险峻的地区，从而逃避了农业与工业社会的侵蚀，这与远古富饶地区的采集社会不论在人口规模和生活方式上都存在差异。再者，狩猎采集社会最显著的特点就是它们彼此之间的差异很大，各有特色。因此，通过人类学方式观察现存的采集社会只能帮助我们了解部分远古采集社会的可能性，而非全貌。 根据现有的证据，我们对远古采集社会虽然只有管中窥豹的认识，但是也能获得一些可靠的推断。首先，他们大部分人都是生活在小部落里面，且所以成员都是人类，而不同于农工社会中，存在家禽家畜的数量超过人类的社会群体。远古采集社会没有家禽家畜，但是有狗的存在，狗是第一种由智人驯化的动物，狗与人类的感情远超过人类与其他动物之间的感情。此外，同属一个部落的成员彼此熟悉，终其一生都生活在一起，没有孤单和隐私。不同的智人部落之间偶尔会有交流与交换物品，大多数时间都是互相独立，各行其是。大多数智人部落都是处于不断迁移的状态，只有很少的部落在食物富饶的地区会选择永久定居。远古智人部落与农业革命以后的人类的生活方式的差异主要有以下几点：1、远古智人有着多样化的饮食结构，不依赖单一的某种食物，饮食结构更灵活，相比之下我们的饮食显得单一固定，容易受自然灾害影响；2、整体而言，现代人类的知识范围远超远古人类，但是个人层面，远古智人是有史以来具备最多知识与生存技能的人类；3、狩猎采集的生活方式更为轻松与舒适，不像现代人那样忙碌；4、远古智人没有像现代人那样饱受传染病的困扰，原因在于多数传染病都是来自家禽家畜，采集社会只有狗是唯一会和人类近距离接触的动物。另外，采集社会人口密度小且分散，疾病不易传播流行。 正因为远古采集者有着比现代人更健康和多样的饮食结构，更短的工作时间，更少的传染病困扰。因此被定义为“最初的富裕社会”。但是这并不表示远古采集社会是理想与美好的，它们同样存在着残酷的一面，存在物资匮乏、族群相杀、时节难过以及儿童死亡率高等问题。有时候，他们会杀害儿童、病人和老人，但是他们的想法其实和现在许多人赞同堕胎和安乐死没有区别。远古的狩猎采集者和我们一样，都是人类。 除了生活方式与环境上的差别，远古采集者的心理和精神世界又是如何？多数学者都同意，远古采集者普遍信奉泛神论的信仰（animism，源自拉丁文anima，意为灵魂或精神）。泛神论相信，几乎任何一个地点、任何一只动物或植物、任何一种自然现象，都有其意识和情感，并且与人类之间没有障碍，可以直接通过语言、歌曲、舞蹈和仪式沟通。泛神论的一个特点在于所有的灵都只限于当场当地，某个具体的事物，而非万能的神。泛神论不是特定的宗教，而是数千种不同宗教、邪教或信仰的统称，这些宗教对于世界的看法、对于人类的定位都大同小异。然而，远古采集者是否一定都是泛神论我们无从得知。此外，采集社会是否存在政治，这一点也无法确定。尽管有考古发现一些具有“阶级”意味的表象，虽然具体原因不得而知，但是仍能说明3万年前的智人已经发明了一些社会政治规范，不仅超出了DNA的设定，也超越了其他人类和动物的行为模式。 最后，“战争”在远古采集社会扮演什么样的角色？有学者认为战争是出现在农业革命之后，伴随着私有财产而生。而另外一种主张则认为采集社会已经有各种残忍的暴力事件。然而不管是通过考古学研究还是人类观察学推测，都是无法还原远古采集社会的真实面貌，所以不能一概而论。采集社会可能有许多不同的宗教和社会结构，不同的地区和不同时段的生活情况也大相径庭，或存在暴力或平静祥和。 由于证据的缺乏，远古采集社会的很多事情都无法确定，我们也就无法重建出一副当时的宏观景象，更不用说重塑特定的事件。关于远古采集社会的很多问题，我们都只能沉默以对。这幅沉默的帷幕笼罩了几万年的人类历史，也许会一直尘封，也许未来出现新的研究工具可以揭开这幅厚重的帷幕。我也不能因为对远古采集社会知之甚少便否定远古智人对人类历史的贡献，不能对于7万年人类历史中的六年视而不见。他们做了很多重要的事情，特别是形塑了我们现有的世界，程度之大出乎意料，他们的足迹早已遍布全世界。整个动物界从古至今，最重要也是最具破坏性的力量，就是这群四处游荡、讲着故事的智人。 毁天灭地的人类洪水在认知革命前，所有的人类物种都只住在亚非大陆。那时候地球不同的洲都有自己独特的生态系统和物种，但是随着智人在认知革命之后掌握了航海技术，智人的足迹开始遍布全球各地，对当地的生态与物种来说是致命的灾难，很多物种遭受灭绝，智人就如同毁天灭地的洪水一般“征服”全球。其中，澳洲大陆与美洲大陆都是血淋淋的例子。 大约在45000年前，智人首次抵达与亚非大陆相遇深远且隔海相望的澳洲大陆绝对是一件跨时代的大事，重要性不亚于哥伦布发现美洲大陆或是人类首次登月。这意味着海洋这个阻挡智人扩张最大的障碍也被征服了。随着智人来到澳洲大陆的那一刻起，曾经在这块土地生活了数万年甚至上百万年的物种都消失殆尽。其中澳大利亚当时24中50公斤以上的动物有23中都惨遭灭绝，许多比较小的物种也从此消失，整个澳大利亚的生态系统食物链重新洗牌，这也是澳大利亚生态系统数百万年来最重大的一次转型。 有些学者试着以气候变迁为借口为人类脱罪，然而有三大证据显示智人难辞其咎。 证据一：虽然澳大利亚气候确实在45000年前有一场改变，但是规模幅度不大。更何况在此之前，地球早就经历过许多次更为严重的冷却和暖化循环，在过去百万年间，平均每10万年就有一场冰河时期。换句话说，澳大利亚上的物种在45000年前早就经历过多次气候变迁，并且大多数都存活下来了。然后，45000年以后，全澳大利亚超过90%的巨型动物都从历史消失。如果说智人所有的巨型动物都恰巧死于严寒之后来到澳大利亚，实在很难令人信服。 证据二：如果是气候变迁导致物种灭绝，那么海洋生物受到的冲击通常不亚于陆地生物。然而，我们没有找到任何证据显示在45000年前海洋生物有显著的灭绝情形。如果假设智人的罪魁祸首，那么也很容易解释这波灭绝浪潮只席卷了陆地生物，而放过了附近的海洋生物。因为那时候智人虽然航海技术有大幅度提升，但是人类毕竟还是主要生活在陆地。 证据三：类似澳大利亚这种物质大面积灭绝的案例在接下来的几千年在不同的地点不断上演，而时间点都是在人类首次抵达的时候。 通过上面列出的三个证据，智人对与类似澳大利亚这样物种大灭绝的惨案的频繁上演难辞其咎。当时智人的生活与狩猎工具还是以石器为主，那么他们是如何主导这次生态浩劫的？以下有三种解释： 第一种解释：一般来说大型动物繁殖缓慢，孕期长，胎数少，怀孕周期长。因此就算智人猎杀不频繁，也可能会导致某个物种的死亡率高于出生率，最后导致这个物种的灭绝。 第二种解释：认为智人抵达澳大利亚的时候已经掌握了火耕技术。面对陌生而危险的环境，他们会刻意地烧毁难以跨越的森林，将地貌变成开阔的草原以适合人类的需求。他们在短短的几千年就彻底改变了澳大利亚大部分地区的生态系统。这种说法有植物化石记录为佐证。在45000年前，桉属植物在澳大利亚只是少数，智人的到来开创了桉属植物的黄金时代，因为桉属植物特别耐火。 第三种解释：这种解释不排除智人狩猎与火耕有显著影响，但是强调不能忽视气候因素。45000年前的气候变迁让澳大利亚的整个生态系统失衡，变得特别脆弱。正常情况下，系统会慢慢调整并适应恢复。智人在这个时候到来，将已经脆弱的生态系统推进了无底深渊。 与澳大利亚类似的还有美洲大陆，大约在14000年前，智人通过当时西伯利亚与阿拉斯加相连的陆地抵达美洲大陆。在此之前，美洲大陆的物种远比今天丰富，各种在亚非大陆未曾得见的物种都在此繁衍茁壮。然而在人类抵达后的两千年内，大多数独特物种都惨遭毒手。 回归智人历史，第一波物种灭绝浪潮是由于智人的扩张，第二波物种浪潮是因为农业革命，现在我们正面临第三波物种灭绝的浪潮：由工业革命所造成的物种灭绝。有些环保人士声称我们的祖先智人总是和自然和谐相处，殊不知智人就是造成最多动植物灭绝的元凶。也许，这场人类洪水的唯一幸存者可能只剩下人类自己，其他登上诺亚方舟的也只可能是作为人类盘中佳肴的家禽家畜罢了。","link":"/2017/08/03/%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"剖析@synchronizd底层实现原理","text":"@synchronizd是Objective-C中的一个语法糖，用于给某个对象加锁，因为使用起来简单方便，所以使用频率很高。然而，滥用@synchronizd很容易导致代码效率低下。本篇博客旨在结合@synchronizd底层实现源码并剖析其实现原理，这样可以更好的让我们在适合的情景使用@synchronizd。 @synchronizd本质上是一个编译器标识符，在Objective-C层面看不其任何信息。因此可以通过clang -rewrite-objc指令来获得@synchronizd的C++实现代码。示例代码如下： 123456int main(int argc, const char * argv[]) { NSString *obj = @\"Iceberg\"; @synchronized(obj) { NSLog(@\"Hello,world! =&gt; %@\" , obj); }} 123456789101112131415161718192021222324252627282930313233343536int main(int argc, const char * argv[]) { NSString *obj = (NSString *)&amp;__NSConstantStringImpl__var_folders_8l_rsj0hqpj42b9jsw81mc3xv_40000gn_T_block_main_54f70c_mi_0; { id _rethrow = 0; id _sync_obj = (id)obj; objc_sync_enter(_sync_obj); try { struct _SYNC_EXIT { _SYNC_EXIT(id arg) : sync_exit(arg) {} ~_SYNC_EXIT() { objc_sync_exit(sync_exit); } id sync_exit; } _sync_exit(_sync_obj); NSLog((NSString *)&amp;__NSConstantStringImpl__var_folders_8l_rsj0hqpj42b9jsw81mc3xv_40000gn_T_block_main_54f70c_mi_1 , obj); } catch (id e) { _rethrow = e; } { struct _FIN { _FIN(id reth) : rethrow(reth) {} ~_FIN() { if (rethrow) objc_exception_throw(rethrow); } id rethrow; } _fin_force_rethow(_rethrow); } }} 通过分析C++代码可以看到@sychronized的实现主要依赖于两个函数：objc_sync_enter和objc_sync_exit。此外还有try{}catch{}语句用于捕捉@sychronized{}语法块中代码执行过程中出现的异常。 我们发现objc_sync_enter函数是在try语句之前调用，参数为需要加锁的对象。因为C++中没有try{}catch{}finally{}语句，所以不能在finally{}调用objc_sync_exit函数。因此objc_sync_exit是在_SYNC_EXIT结构体中的析构函数中调用，参数同样是当前加锁的对象。这个设计很巧妙，原因在_SYNC_EXIT结构体类型的_sync_exit是一个局部变量，生命周期为try{}语句块，其中包含了@sychronized{}代码需要执行的代码，在代码完成后，_sync_exit局部变量出栈释放，随即调用其析构函数，进而调用objc_sync_exit函数。即使try{}语句块中的代码执行过程中出现异常，跳转到catch{}语句，局部变量_sync_exit同样会被释放，完美的模拟了finally的功能。 接下来，在苹果公开的源代码文件objc-sync.mm中找到objc_sync_enter和objc_sync_exit这两个函数的实现，一窥其中的奥秘。 12345678910111213141516171819202122232425262728293031323334353637typedef struct SyncData { struct SyncData* nextData; DisguisedPtr&lt;objc_object&gt; object; //当前加锁的对象 int32_t threadCount; //使用对object加锁的线程个数 recursive_mutex_t mutex; //递归互斥锁} SyncData;typedef struct { SyncData *data; unsigned int lockCount; //表示当前线程对object对象加锁次数} SyncCacheItem;typedef struct SyncCache { unsigned int allocated; unsigned int used; SyncCacheItem list[0];} SyncCache;/* Fast cache: two fixed pthread keys store a single SyncCacheItem. This avoids malloc of the SyncCache for threads that only synchronize a single object at a time. SYNC_DATA_DIRECT_KEY == SyncCacheItem.data SYNC_COUNT_DIRECT_KEY == SyncCacheItem.lockCount */struct SyncList { SyncData *data; spinlock_t lock; SyncList() : data(nil) { }};// Use multiple parallel lists to decrease contention among unrelated objects.#define LOCK_FOR_OBJ(obj) sDataLists[obj].lock#define LIST_FOR_OBJ(obj) sDataLists[obj].datastatic StripedMap&lt;SyncList&gt; sDataLists; 上述代码是一些相关的数据结构，下面分别进行介绍： SyncData结构体中有四个成员变量，其中object指针变量指向当前加锁对象，threadCount表示对object加锁的线程个数，mutex是一个递归互斥锁，意味着可以对object进行多次加锁，其具体作用后面会提到。 SyncCacheItem结构体中有两个成员变量，其中data是SyncData结构体类型的指针，lockCount表示当前线程对当前结构体对象加锁次数，其实就是对加锁对象object的加锁次数。我们可以看到SyncCacheItem与SyncData是一对一关系，SyncCacheItem只是对SyncData进行了再次封装以便于缓存，具体使用见后文。 SyncCache结构体中有三个成员变量，其中维护了一个SyncCacheItem类型的数组，allocated和used则分别表示当前分配的SyncCacheItem数组中的总个数和已经使用的个数。这个结构体与线程是一对一的关系，用于存储当前线程已加锁对象对应的SyncCacheItem结构体，因为一个线程可以对同一个对象多次加锁，所以通过引入缓存SyncCache可以提高效率，具体使用见后文。 SyncList结构体中有两个成员变量和一个构造函数，其中data是SyncData结构体类型的指针，lock是一个自旋锁。 sDataLists是一个全局StripedMap哈希列表，其中value为SyncList对象，key为加锁对象object指针进行hash后的值。StripedMap是一个C++模板类，其实现代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940template&lt;typename T&gt;class StripedMap { enum { CacheLineSize = 64 };#if TARGET_OS_EMBEDDED enum { StripeCount = 8 };#else enum { StripeCount = 64 };#endif struct PaddedT { T value alignas(CacheLineSize); }; PaddedT array[StripeCount]; static unsigned int indexForPointer(const void *p) { uintptr_t addr = reinterpret_cast&lt;uintptr_t&gt;(p); return ((addr &gt;&gt; 4) ^ (addr &gt;&gt; 9)) % StripeCount; } public: T&amp; operator[] (const void *p) { return array[indexForPointer(p)].value; } const T&amp; operator[] (const void *p) const { return const_cast&lt;StripedMap&lt;T&gt;&gt;(this)[p]; }#if DEBUG StripedMap() { // Verify alignment expectations. uintptr_t base = (uintptr_t)&amp;array[0].value; uintptr_t delta = (uintptr_t)&amp;array[1].value - base; assert(delta % CacheLineSize == 0); assert(base % CacheLineSize == 0); }#endif}; 上述代码中，由于自己对C++模板类不熟悉，所以只能看个大概。其中有两个值得注意的地方，其中StripeCount表示哈希数组的长度，如果是嵌入式系统值为8，否则值为64，也就意味着哈希数组最大长度为64；函数indexForPointer为散列函数，算法不难，但是很巧妙，值得学习。 下面开始分析相关的函数实现，首先找到@sychronized直接调用的两个函数：objc_sync_enter和objc_sync_exit，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445// Begin synchronizing on 'obj'. // Allocates recursive mutex associated with 'obj' if needed.// Returns OBJC_SYNC_SUCCESS once lock is acquired. int objc_sync_enter(id obj){ int result = OBJC_SYNC_SUCCESS; if (obj) { SyncData* data = id2data(obj, ACQUIRE); assert(data); data-&gt;mutex.lock(); } else { // @synchronized(nil) does nothing if (DebugNilSync) { _objc_inform(\"NIL SYNC DEBUG: @synchronized(nil); set a breakpoint on objc_sync_nil to debug\"); } objc_sync_nil(); } return result;}// End synchronizing on 'obj'. // Returns OBJC_SYNC_SUCCESS or OBJC_SYNC_NOT_OWNING_THREAD_ERRORint objc_sync_exit(id obj){ int result = OBJC_SYNC_SUCCESS; if (obj) { SyncData* data = id2data(obj, RELEASE); if (!data) { result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR; } else { bool okay = data-&gt;mutex.tryUnlock(); if (!okay) { result = OBJC_SYNC_NOT_OWNING_THREAD_ERROR; } } } else { // @synchronized(nil) does nothing } return result;} 不难发现，上述代码都调用了id2data函数来获取一个与obj对应的SyncData对象，然后使用该对象中的递归互斥锁分别进行加锁与解锁。至此@sychronized的大致实现过程已经很清晰了，本质上是为一个对象分配一把递归互斥锁，可以也是为什么可以反复使用@sychronized对同一个对象进行加锁的原因。那么@sychronized是如果管理这把互斥锁，以及是如何处理多个线程对同一个对象进行多次加锁的情况？很明显，一切奥秘都藏在id2data函数中，其代码如下所示： 注：为了描述方便，下面将id2data函数的形参object描述为同步对象obejct。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211static SyncData* id2data(id object, enum usage why){ //从全局哈希表sDataLists中获取object对应的SyncList对象 //lockp指针指向SyncList对象中自旋锁 //listp指向一条SyncData链表，因为C++ STL中的哈希表处理地址冲突的方法是链地址法 spinlock_t *lockp = &amp;LOCK_FOR_OBJ(object); SyncData **listp = &amp;LIST_FOR_OBJ(object); SyncData* result = NULL; //对于同一个线程来说，有两种缓存方式： //第一种：快速缓存（fastCache），适用于一个线程一次只对一个对象加锁的情况，用宏SUPPORT_DIRECT_THREAD_KEYS来标识 //这种情况意味着同一时间内，线程缓存中只有一个SyncCacheItem对象，键值SYNC_DATA_DIRECT_KEY和SYNC_COUNT_DIRECT_KEY分别对应SyncCacheItem结构体中的SyncData对象和lockCount.#if SUPPORT_DIRECT_THREAD_KEYS // Check per-thread single-entry fast cache for matching object //用于标识当前线程的是否已使用fastCache bool fastCacheOccupied = NO; //直接调用tls_get_direct函数获取SyncData对象 SyncData *data = (SyncData *)tls_get_direct(SYNC_DATA_DIRECT_KEY); if (data) { //标识fastCache已被使用 fastCacheOccupied = YES; //比较fastCache中的SyncData对象中的object与当前同步对象object是否为同一个对象 if (data-&gt;object == object) { // Found a match in fast cache. //fastCache中的对象恰好是当前同步对象object，则后续处理直接使用fastCache中SyncData对象 uintptr_t lockCount; result = data; //获取当前线程对应当前SyncData对象已经加锁的次数 lockCount = (uintptr_t)tls_get_direct(SYNC_COUNT_DIRECT_KEY); //无效的SyncData对象 if (result-&gt;threadCount &lt;= 0 || lockCount &lt;= 0) { _objc_fatal(\"id2data fastcache is buggy\"); } //判断当前操作的加锁还是解锁 switch(why) { //加锁 case ACQUIRE: { //加锁一次 lockCount++; //更新已加锁次数 tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)lockCount); break; } //解锁 case RELEASE: //解锁一次 lockCount--; //更新已加锁次数 tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)lockCount); //已加锁次数为0，表示当前线程对当前同步对象object达到锁平衡，因此不需要再持有当前同步对象。 if (lockCount == 0) { // remove from fast cache //将对应的SyncData对象从线程缓存中移除 tls_set_direct(SYNC_DATA_DIRECT_KEY, NULL); // atomic because may collide with concurrent ACQUIRE //此函数为原子操作函数，用于对32位的threadCount整形变量执行减一操作，且确保线程安全。因为可能存在同一时间多个线程对一个threadCount进行加减操作，避免出现多线程竞争。不同于lockCount，threadCount是多个线程共享的一个变量，用于记录对一个对象加锁的线程个数，threadCount对应的SyncData对象除了线程缓存中持有之外，还存在于全局哈希表sDataLists中，sDataLists哈希表是多个线程共享的数据结构，因此存在多线程访问的可能。而lockCount则与线程一一对应且存储在线程的缓存区中，不存在多线性读写问题，因此不需要加锁。 OSAtomicDecrement32Barrier(&amp;result-&gt;threadCount); } break; case CHECK: // do nothing break; } return result; } }#endif // Check per-thread cache of already-owned locks for matching object //这是第二章缓存方式：使用SyncCache结构体来维护一个SyncCacheItem数组，这样一个线程就可以处理对多个同步对象。值得注意的是SyncCache与线程也是一对一的关系。 //获取当前线程缓存区中的SyncCache对象 SyncCache *cache = fetch_cache(NO); if (cache) { unsigned int i; //遍历SyncCache对象中的SyncCacheItem数组，匹配当前同步对象object for (i = 0; i &lt; cache-&gt;used; i++) { SyncCacheItem *item = &amp;cache-&gt;list[i]; if (item-&gt;data-&gt;object != object) continue; // Found a match. //当前同步对象object已存在的SyncCache中 //获取对应的SyncData对象 result = item-&gt;data; //无效的SyncData对象 if (result-&gt;threadCount &lt;= 0 || item-&gt;lockCount &lt;= 0) { _objc_fatal(\"id2data cache is buggy\"); } //后续操作同fastCache一样，参考fastCache的注释 switch(why) { case ACQUIRE: item-&gt;lockCount++; break; case RELEASE: item-&gt;lockCount--; if (item-&gt;lockCount == 0) { // remove from per-thread cache cache-&gt;list[i] = cache-&gt;list[--cache-&gt;used]; // atomic because may collide with concurrent ACQUIRE OSAtomicDecrement32Barrier(&amp;result-&gt;threadCount); } break; case CHECK: // do nothing break; } return result; } } // Thread cache didn't find anything. // Walk in-use list looking for matching object // Spinlock prevents multiple threads from creating multiple // locks for the same new object. // We could keep the nodes in some hash table if we find that there are // more than 20 or so distinct locks active, but we don't do that now. //如果当前线程中的缓存中没有找到当前同步对象对应的SyncData对象，则在全局哈希表中查找 //因为全局哈希表是多个线程共享的数据结构，因此需要进行加锁处理 lockp-&gt;lock(); { SyncData* p; SyncData* firstUnused = NULL; //遍历当前同步对象obejct在全局哈希表中的SyncData链表。这里之所以使用链表，是因为哈希表的hash算法不能确保hash的唯一性，存在多个对象对应一个hash值的情况。 for (p = *listp; p != NULL; p = p-&gt;nextData) { //哈希表中存在对应的SyncData对象 if ( p-&gt;object == object ) { result = p; // atomic because may collide with concurrent RELEASE //此函数为原子操作函数，确保线程安全，用于对32位的threadCount整形变量执行加一操作，表示占用当前同步对象的线程数加1。 OSAtomicIncrement32Barrier(&amp;result-&gt;threadCount); goto done; } //用于标记一个空闲的SyncData对象 if ( (firstUnused == NULL) &amp;&amp; (p-&gt;threadCount == 0) ) firstUnused = p; } // no SyncData currently associated with object //由于此时同步对象object没有对应的SyncData对象，因此RELEASE与CHECK都属于无效操作 if ( (why == RELEASE) || (why == CHECK) ) goto done; // an unused one was found, use it //如果没有找到匹配的SyncData对象且存在空闲的SyncData对象，则直接使用，不需要创建新的SyncData，以提高效率。 if ( firstUnused != NULL ) { result = firstUnused; //关联当前同步对象 result-&gt;object = (objc_object *)object; //重置占用线程为1 result-&gt;threadCount = 1; goto done; } } // malloc a new SyncData and add to list. // XXX calling malloc with a global lock held is bad practice, // might be worth releasing the lock, mallocing, and searching again. // But since we never free these guys we won't be stuck in malloc very often. //到这一步说明需要新建一个SyncData对象 result = (SyncData*)calloc(sizeof(SyncData), 1); result-&gt;object = (objc_object *)object; result-&gt;threadCount = 1; //创建递归互斥锁 new (&amp;result-&gt;mutex) recursive_mutex_t(); //以“入栈”的方式加入当前同步对象object对应的SyncData链表 result-&gt;nextData = *listp; *listp = result; done: //对全局哈希表的操作结束，解锁 lockp-&gt;unlock(); if (result) { // Only new ACQUIRE should get here. // All RELEASE and CHECK and recursive ACQUIRE are // handled by the per-thread caches above. //只有ACQUIRE才需要新建SyncData对象 if (why == RELEASE) { // Probably some thread is incorrectly exiting // while the object is held by another thread. return nil; } if (why != ACQUIRE) _objc_fatal(\"id2data is buggy\"); if (result-&gt;object != object) _objc_fatal(\"id2data is buggy\"); //fastCache缓存模式#if SUPPORT_DIRECT_THREAD_KEYS if (!fastCacheOccupied) { // Save in fast thread cache //直接缓存新建的SyncData对象 tls_set_direct(SYNC_DATA_DIRECT_KEY, result); //设置加锁次数为1 tls_set_direct(SYNC_COUNT_DIRECT_KEY, (void*)1); } else #endif //SyncCache缓存模式，则直接加入SyncCacheItem数组中 { // Save in thread cache if (!cache) cache = fetch_cache(YES); cache-&gt;list[cache-&gt;used].data = result; cache-&gt;list[cache-&gt;used].lockCount = 1; cache-&gt;used++; } } return result;} 通过上述代码的注释，id2data函数的功能已经大致清晰。id2data函数主要是用于管理同步对象object与线程之间的关联。不论是ACQUIRE、RELEASE还是CHECK操作，都会先从当前线程的缓存中去获取对应的SyncData对象。如果当前线程的缓存区中不存在，那么再从全局的哈希数组中查找，查看其它线程是否已经占用过当前同步对象object。如果还是没有，那么就新建一个与之对应的SyncData对象，分别加入全局哈希表和当前线程缓存中。 至此，@synchronized的实现原理已经剖析结束，其有一个最大的特点是：不论是多个线性同一时间内对一个对象进行多次同步还是一个线程对同一个对象同步多次，一个对象只分配一把递归互斥锁。也就意味着对同一个对象而言，当执行某一次同步操作时，其他线程或同一线程的其他同步操作都会被阻塞，不言而喻，这种加锁方式的效率是很低的。 下面代码展示了@synchronized经典的使用案例之一： 1234567891011121314151617- (void)setInstanceMemberObjecObject1:(id)value { @synchronized(self) { self.instanceMember1 = value; }}- (void)setInstanceMemberObjecObject2:(id)value { @synchronized(self) { self.instanceMember2 = value; }}- (void)setInstanceMemberObjecObject3:(id)value { @synchronized(self) { self.instanceMember3 = value; }} 上述代码，调用其中一个设置函数时，另外两个成员变量的设置函数在同一时间被调用都会被阻塞。这里@synchronized同步的代码很简单，所以不会效率差别不大。如果是同步的代码需要执行较长的时间，且被多个线程并发调用，那么效率变得很低。如果不清楚@synchronized的实现原理，可能很难排查出来导致效率低下的问题所在。我建议使用GCD取代@synchronized实现同步功能，GCD不仅是线程安全，且其由底层实现，效率会好很多。我们发生@synchronized的底层实现有捕获异常的功能，因此适合在需要确保发生错误时代码不会死锁，而是抛出异常时使用。","link":"/2017/06/11/%E5%89%96%E6%9E%90@synchronized%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/"},{"title":"揭秘dispatch_once的内部实现","text":"这是一篇译文，原文Secrets of dispatch的作者是Mike Ash大神。在拜读这篇文章之后，颇有收获，不得不感叹Mike Ash专业知识的深度与广度。因此，我想试着进行翻译以加深理解。 以下是原文 一位名为Paul Kim的读者向我推荐了Micheal Tsai的一篇关于“让dispatch_once执行更快”的博客。虽然dispatch_once源代码中的注释精彩且详实，但是它并没有深入剖析那些让人着迷的细节。因为这是我最喜欢研究的方面之一，所以今天的文章我将进行深入地探究dispatch_once内部逻辑和实现原理。 API介绍dispatch_once函数顾名思义，它只执行一次且唯一的一次。函数接收两个参数，第一个参数是一个predicate，用于跟踪和保证函数的“一次性”；第二个参数是一个block，在函数第一次被调用时执行。调用方式如下所示： 12345static dispatch_once_t predicate;dispatch_once(&amp;predicate , ^{ //执行一次性的任务}); 这个函数很适用于共享状态的“懒初始化”，适用范围包括全局字典、单例实体、缓存或者其他任何需要在第一次执行时进行配置的地方。 在只有单线程的环境中，这种调用方式显得有些繁琐，用一个简单的if语句就能取而代之。然而，我们现在面临的都是多线程的运行环境，且diaspatch_once是线程安全的。这就保证了即使多个线程同时调用dispatch_once函数，函数也只执行一个block，并且所有线程直到block中的任务执行结束且dispatch_once退出之前都会处于阻塞状态。尽管你自己实现一个类似的函数不是很难，但是dispatch_once函数执行速度相当之快，并且实现的难度很大。 单线程版本让我们先看一个这个函数精简后的单线程版本。虽然这个版本没有实用性，但是让我们对这个函数有一个具体的视觉感官。注意到dispatch_once_t只是一个long整型，且初始化为0，根据实现被赋予不同的含义。以下是实现： 12345678void SimpleOnce(dispatch_once_t *predicate, dispatch_block_t block) { if (!*predicate) { block(); *predicate = 1; }} 实现很简单：如果predicate是0，执行block且更新predicate的值为1。后续的函数调用会发现predicate未非0值便不会重复执行block。如果不是因为在多线程环境是不安全的，这完全就是我们想要的结果。糟糕的是，如果两个线程可能同时访问if语句，会导致block被调用两次。很不幸，这种情况时有发生，因此，让这份代码变成线程安全意味着一次实质性的成功。 性能当谈及dispatch_once的性能时，主要有以下三种不同的情景： 1、第一次调用dispatch_once时，指定一个predicate，并执行block.2、在第一次调用dispatch_once之后且block未执行完之前，后续调用线程必须等待直到block执行完成。3、在第一次调用dispatch_once且执行完成之后，后续调用不需要等待而是立即执行。 情景1基本上不影响性能，毕竟只执行一次，只要block执行速度不是太慢。 情景2同样不太影响性能。这个情况可能潜在地发生好几次，但是只有在block未执行完才会发生。大多数情况，这种情况几乎不会发生。如果发生了也可能是仅仅出现一次。甚至在极端测试下：很多线程同时调用dispatch_once并且block执行时间很长，后续处于等待的调用也局限在几千个以内。这些后续调用线程全都必须等待block执行完成，所以即使这些线程在等待过程中耗费了一些不必要的CPU时间也是无关紧要的。 情景3则是性能高低的关键所在。这种性质的调用可能在程序中潜在发生成千上万次。我们想通过dispatch_once来保护那些一次性运算，运算结果被作为调用的返回值。理想情况下，dispatch_once的性能应该可以与直接读取一个提前初始化好的全局变量的性能媲美。换言之，一旦你面临情景3，我们想让下面两个代码块执行的效率是一样的。 代码段1： 12345678910id gObject;void Compute(void){ gObject = ....;}id Fetch(void){ return gObject;} 代码段2： 123456789id DispatchFetch(void){ static id object; static dispatch_once_t predicate; dispatch_once(&amp;predicate, ^{ object = ...; }); return object;} 在被编译器内联处理和优化之后，SimpleOnce函数的执行效率接近DispatchFetch函数。在我电脑上测试，DispatchFetch函数执行时间为0.5纳秒。这无疑是线程安全版本中的黄金标准。 如何自己实现一个的dispatch_once版本，关键在于确保线程安全，以下列出几种方式： 使用线程锁常规的线程安全的做法是在共享数据访问前后添加锁。因为是示例代码，我决定只用一个单一的全局锁变量来做。代码中使用一个静态线程锁变量pthread_mutex_t来保护predicate的线程安全。在实际的项目中，随着函数被多个不同的类调用，伴随着很多不同的predicate变量，这将会是一个糟糕的设计。因为每一个互不关联的predicate变量必须一直等待当前被保护的predicate解锁才能获得执行机会。作为一个快速测试，这里我仅仅只测试一个predicate的情况。这份代码除了加了锁之外与前面的SimpleOnce函数没有区别： 12345678910void LockedOnce(dispatch_once_t *predicate, dispatch_block_t block) { static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; pthread_mutex_lock(&amp;mutex); if(!*predicate) { block(); *predicate = 1; } pthread_mutex_unlock(&amp;mutex); } 这段代码是线程安全的，但不幸的是执行速度太慢。在我的电脑上测试结果为每次调用需要30纳秒，相较于上述0.5纳秒的版本实在差太远。线程锁已经算很快的了，但不属于纳秒级别的。 使用自旋锁自旋锁是一种试图将额外的开销降到最低的锁。顾名思义，自旋锁在处于需要等待的时候拥有“自旋”的功能，不断地轮询临锁的状态查看是否已经解锁。一般的锁都会配合操作系统休眠正在等待的线程，等解锁之后再唤醒所在的线程。这种锁虽然节省了CPU时间，但是这种协调休眠的机制也是有代价的。自旋锁不会休眠等待线程，因此在处于等待解锁的情况下节省了很多时间，付出的代价则是当多个线程试图获得自旋锁时效率会比较低。 MacOS X提供了一套便利的自旋锁API名为OSSpinLock.使用OSSinLock实现LockedOnce只需要在原有的基础修改几个名称： 12345678910void SpinlockOnce(dispatch_once_t *predicate, dispatch_block_t block) { static OSSpinLock lock = OS_SPINLOCK_INIT; OSSpinLockLock(&amp;lock); if(!*predicate) { block(); *predicate = 1; } OSSpinLockUnlock(&amp;lock); } 这次有了相当大的提升。在我电脑上测试结果为每次调用需要6.5纳秒，远好于pthread_mutex版本的每次调用30纳秒。然而于dispatch_once比起来还是太慢了。 原子操作原子操作是底层CPU级别的操作且即使没有锁也一直都是线程安全。从技术层面来说，它们使用的硬件锁。使用锁会带来额外的开销，直接使用原子操作可以带来性能上的提升。多线程编程没有锁可能会显得很别捏，所以除非你真的需要原子操作，否则这不是明智的选择。我们现在讨论的是一个可能会被频繁使用的系统库，因此也许值得添加原子操作。 原子操作创建锁的过程是“比较并交换”。这是一个类似于下面代码的简单操作： 1234567BOOL CompareAndSwap(long *ptr, long testValue, long newValue) { if(*ptr == testValue) { *ptr = newValue; return YES; } return NO;} 总而言之，函数CompareAndSwap的功能用来测试内存的一个地址是否存储着一个特定的值，如果是则用新的值替换原有的值，返回结果表示匹配成功与否。因为“比较并交换”是一个CPU级的原子指令，所以即使有多个线程都试着对同一个内存区域进行“比较并交换”的操作都能确保其中只有一个操作能够成功。 LockedOnce的这个版本的实现策略是对predicate赋予三个不同的值。0表示函数还未被调用过；1表示函数block正处于执行状态，后续调用线程则处于等待状态；2表示block执行完成且释放阻塞的等待线程并返回结果。 “比较并交换”原子操作将被用于检测predicate的值是否为0，如果是则自动更新predicate为1。一旦原子操作返回的是YES，意味着当前线程是第一个调用线程，并开始唯一一次地block执行。在block执行完成后更新predicate的值为2作为标识. 如果“比较并交换”原子操作执行失败意味着当前线程不是第一个调用者，然后线程进入一个循环，不断地检测predicate的值是否更新为2，直到predicate更新为2才退出循环。这将导致线程在block执行结束之前一直处于等待状态。 以下是这个版本的函数的具体： 123456789101112131415161718192021222324252627void AtomicBuiltinsOnce(dispatch_once_t *predicate, dispatch_block_t block) { //将predicate指针转换成volatile指针， //以告知编译器这个变量的值可能在函数执行过程中被其他线程更改， //必须每次从内存地址取值，而非寄存器 volatile dispatch_once_t *volatilePredicate = predicate; //调用“比较并交换”原子操作。 //Gcc编译器和clang编译器均提供了各种以_sync开头的内置函数以实现原子操作。 //下面的函数对predicate执行了“比较并交换”的原子操作， //检测predicate的值是否为0，如果是则更新为1 if(__sync_bool_compare_and_swap(volatilePredicate, 0, 1)) { //执行block block(); //一旦block执行完成，更新predicate的值为2用以告知当前正在等待的调用线程以及未来的调用者block已经执行完成。 //然而，考虑到CPU的优化机制，我们使用内存屏障以确保volatilePredicate值的读书顺序是正确的。 //使用内置函数__sync_synchronize在此出设置内存屏障， //确保volatilePredicate在block执行完后立即更新为2，且在此之前不可读。 __sync_synchronize(); //更新 *volatilePredicate = 2; }else { //等待线程循环检测 while(*volatilePredicate != 2); //线程返回之前设置内存屏障，匹配if语句中的内存屏障设置，保证volatilePredicate读取一致性 __sync_synchronize(); }} 上述代码满足需求且是线程安全的，但是性能一般。在我电脑上每次调用时间为20纳秒，明显高于自旋锁版本。 提前预判这里有一个显而易见的优化可以添加到原子操作的版本中。因为通常情况下都是predicate的值已经是2，在函数最开始的地方加一个判断语句，可以在大多数情况下加快函数执行速度： 123456789101112131415161718void EarlyBailoutAtomicBuiltinsOnce(dispatch_once_t *predicate, dispatch_block_t block) { if(*predicate == 2) { __sync_synchronize(); return; } volatile dispatch_once_t *volatilePredicate = predicate; if(__sync_bool_compare_and_swap(volatilePredicate, 0, 1)) { block(); __sync_synchronize(); *volatilePredicate = 2; } else { while(*volatilePredicate != 2) ; __sync_synchronize(); } } 这个版本的执行效率有相当大的提升，大约是调用一次11.5纳秒。然而，对比与dispatch_once版本还是相去甚远，甚至不如自旋锁版本。 设置内存屏障有额外的开销，这也是为什么这个版本的执行速度比dispatch_once慢的原因所在。至于为什么会比自旋锁版本慢，是因为代码中设置了不同类型的内存屏障。__sync_synchronize函数会产生一个mfence的指令，这个指令是可能是最耗费资源的指令之一，然而OSSpinLock使用的是一个效率更高的指令。我们可以尝试不同的内存屏障以到达更好的效果，但是很明显代码最终的执行速度未达到我们预期结果，因为我打算弃用这种方法。 非线程安全的提前预判这个版本与上面的版本很类似，只不过将内存屏障移除了： 1234567891011121314void UnsafeEarlyBailoutAtomicBuiltinsOnce(dispatch_once_t *predicate, dispatch_block_t block) { if(*predicate == 2) return; volatile dispatch_once_t *volatilePredicate = predicate; if(__sync_bool_compare_and_swap(volatilePredicate, 0, 1)) { block(); *volatilePredicate = 2; } else { while(*volatilePredicate != 2) ; } } 不出意外，这个版本的执行速度与SimpleOnce一样都是0.5纳秒。因为*predicate == 2的适用于大多数情况，差不多每次调用都是检测predicate的值并返回。这个版本除了第一次执行block之外，几乎与SimpleOnce函数一样。 正如函数名所示，这是一个非线程安全版本，缺少了内存屏障导致线程不安全。原因何在？ CPU流水线执行方式我们可以将CPU想象成一个简单的机器，我们告诉它做什么，它就做什么。如此反复直到天荒地老。 曾经有一段时间确实如此。老版的CPU的工作方式很简单，一眼一板。不幸的是，这种方式简单，容易且成本低，但是执行效率低。根据摩尔定律，CPU内置的晶体管成指数增长。8086CPU内置了大约29000个晶体管。一个英特尔处理器CPU集成了超过十亿的晶体管。 根据市场需求决定了CPU拥有更好的效率，现在的CPU集成了越来越多的晶体管旨在让电脑运行速度更快。 这里面有很多技巧让CPU执行的更快。其中一种就是流水线。执行单一的CPU指令，分成多个小步骤： 从内存加载指令 指令解码（分析指令解析包含哪些运算操作） 加载输入数据 结合输入执行运算 保存输出数据 在一个早期的CPU，上述流程执行步骤如下所示： 1234567891011加载指令解码加载数据运算保存输出加载下一个指令解码加载数据运算保存输出... 在一个流水线型的CPU，执行步骤则如下所示： 1234567加载指令 解码 加载指令 加载数据 解码 加载指令运算 加载数据 解码保存输出 运算 加载数据 保存输出 运算 保存输出 这种方式执行速度快很多。随着CPU中的晶体管数量越来越多，CPU内部结构也越来越复杂，同步执行的指令也越来越多。更有甚者，如果可以让速度更快，指令的执行顺序会被完全打乱。不同于上述简单的例子，真实情况下，指令更为复杂以及变量更多。 代码执行的顺序并不以总是与代码本身的顺序一致的，比如下面的代码： 12x = 1;y = 2; CPU可能会先写入Y变量的值。有些情况下编译器也会对语法重新排序，即便你屏蔽了编译器的行为，CPU仍然会乱序执行。如果是多核CPU，在其他的CPU看了写入的顺序是乱序的。即使是按代码顺序写入的，其他的CPU也会乱序读取。综合考虑，其它的线程在读取x和y的值时会发现y的值已经改变而x还是原来的值。 在你需要这些值必须按照既定的顺序写入的时候，内存屏障就派上用场了。设置内存屏障以确保上述代码中x的值先被更新： x = 1; memory_barrier(); y = 2; 同样地，内存屏障可以确保读的顺序： use(x); memory_barrier(); use(y); 然而，因为内存屏障的主要功能导致CPU的执行速度，所以自然而然影响性能。 对于dispatch_once来说，代码必须按照既定的顺序执行，因此必须设置内存屏障。但是，内存屏障会导致代码效率低下，所以为了避免额外的开销，我们想办法避免设置内存屏障。 CPU的分支预测和推测性执行流水线和乱序工作模式适用于一系列线性执行的指令，但是对于添加分支语句则变得麻烦。CPU在分支语句执行完之前不知道下一步该执行什么指令，因此不得不停止运行等待前面的分支语句结束再重新运行。这就是所谓的pipeline stall，在一定程度上影响CPU性能。 为了弥补pipeline stall带了的性能损失，CPU加入了推测性执行。当CPU遇到一个分支语句则会进行分支预测判断哪一个分支可能被执行。现在的CPU配置精密的分支预判硬件，准确率在90%以上。在做出预判之后，CPU开始执行假设的分支中的代码块，而不是等待分支语句的结果。如果分支预判是正确的则继续后续执行。如果预判错误则清空推测执行结果重新执行另外一个分支代码块。 这种情况被用在了dispatch_once的读取端，这也是我们期望执行速度越快越好的地方。dispatch_once中有一个判断predicate的值得分支语句。CPU应该会预判并执行else分支，因为这个大多数情况下会执行的分支，即绕过block执行然后立即返回结果。在推测性执行过程中，CPU可能会从内存中加载那些后续需要但是还未被其他线程初始化的变量。如果分支预判是正确的，CPU会使用未初始化的值进行推测性执行。 非对称屏障内存屏障一般都是需要对称的：在写的一端确保按照正确的顺序写入，在读的一端确保按照正确的顺序读取。然而，我们需要非对称屏障来满足我们的性能需求：我们可以容忍写入端的速度缓慢，但是让读的速度越快越好。 这个技巧用来防范推测性执行导致的问题。当分支预判是错误的，推测性执行的结果会被弃用。如果dispatch_once可以在初始化完成之后强制确定CPU的分支预判，这个问题则可以被避免。 此处有一个间隔时间，即最初的推测性执行到条件语句执行结束之间的间隔时间。间隔具体的时间因CPU而异，但是最多几十个CPU周期的时间。 在英特尔CPU中，dispatch_once使用spuid指令到达上述目的。cpuid指令主要是用于获取CPU的ID和功能等信息，但是也可以强行序列化指令流并需要耗费几百个CPU周期的时间。 在dispatch_once的源代码中，你会发现在读的一端没有使用内存屏障： 123456789DISPATCH_INLINE DISPATCH_ALWAYS_INLINE DISPATCH_NONNULL_ALL DISPATCH_NOTHROWvoid_dispatch_once(dispatch_once_t *predicate, dispatch_block_t block){ if (DISPATCH_EXPECT(*predicate, ~0l) != ~0l) { dispatch_once(predicate, block); }}#define dispatch_once _dispatch_once 这段代码位于头文件中，并内联只调用者的代码块。DISPATCH_EXPECT宏告诉编译器去告知CPU：*predicate = ~0l是更有可能发生的分支。这可以提高分支预判的准确性，继而提升执行效率。基本上，这里只有一个普通的if语句，没有设置任何屏障。调用dispatch_once的执行速度接近0.5纳秒的黄金标准。 在dispatch_once实现文件中可以看到写入端的实现，在block执行后立即执行了下面的宏： 1dispatch_atomic_maximally_synchronizing_barrier(); 在英特尔的CPU中，这个宏使用了cpuid指令，在其他的CPU框架中也会产生类似的指令。 结论多线程是最奇怪和复杂的地方，现代的CPU在背后做了很多不为认知的事情。内存屏障允许你告知硬件按照你需要的顺序执行代码，但是相应的需要在性能上做出牺牲。dispatch_once有着独一无二的需求，让CPU不走寻常路：在相关的内存写入完成之前牺牲足够多的等待时间，但是确保每一次读取都是高效安全的且不需要额外的内存屏障。","link":"/2016/08/08/%E6%8F%AD%E7%A7%98dispatch_once/"},{"title":"《李光耀观天下》读后感","text":"《李光耀观天下》这本书是以李光耀先生的自述性自传，全书向读者阐述自己对当今这个世界的观点与看法。面对复杂多变的世界形势，他总能保持中立客观，并且抓住事情的本质。其字里行间透露着一种谦虚与客观的态度，言语中蕴藏着深刻的学问与广阔的见识。 相对于这边书的中文译名《李光耀观天下》， 我更喜欢它的英文名称《One Man’s View of the World》。英文书名似乎给人一种更为谦虚与中立的感觉，也许只是我个人感觉罢了。 读完此书之后，由于自己世界观的不健全，只对于书中关于的一些比较熟悉的国家的分析与见解印象比较认同，主要的亚洲国家，比如中日韩朝等。而对于其他国家的，特别是中东地区的阿拉伯国家，因为缺乏对这些国家的了解，只能处于一种认知与被动接受的角度去看待相关的分析。换言之，这本书带给我是一个新的看待世界的视角，从而进一步完善我的世界观。 书中除了最后四章，前面起章都是以国家为基本单位，阐述了李光耀先生对每个国家现状的分析以及未来发展的预测。最后四章分别分析了全球经济、能源与气候、个人生活以及与联邦德国总理赫尔穆特·施密特先生的对话。由于自己目前能力有限，没能站在一个更高中的角度提炼并串联每一个章节的中心思想，所以只能是按照书中原有的组织结构依次总结自己关于每个章节的心得体会。 中国：一个强大的中央中国有着悠久的历史，历朝历代都是通过一个强大的中央政权来治理国家，这一点在中国人心中已经根深蒂固。因此，西方国家提倡的一人一票的民主选举制度是不能再中国出现。中国的特殊性也决定了中国需要开辟一条属于自己的道路。此外，在中国这片土地上不再可能出现大规模的动乱或者反政府活动了。从“乌坎事件”可以得出两点结论：一是共产党能保持它的掌控地位，在党的领导下社会可以恢复秩序。二是共产党拥有强大的国家安全机器，可以运用软硬兼施的方式控制局势。与此同时，共产党是支持民众反对腐败的地方官的，而民众也是支持共产党，反对的只是腐败的地方官。 中国经历改革开放，在过去的四十年经济突飞猛进，重新以重要大国的形象出现在国际舞台。中国人也变得崇尚多元爱好的充满理想。随着全国各地的变化，中国的政治也必须变革。然而中国地域广阔，人口基数大，维持社会稳定是根本前提，因此制度改革的进度一定是缓慢的。此外，中国目前的法制不健全，更多的是依赖于人制，这与中国的特殊国情和历史渊源有关。不论将来中国如何发展体制和制度，完全都是中国式的，并且有一个不变的核心：强大的中央政权。 中国能发展到今天这个地步离不开历届领导人的贡献。毛泽东作为开国主席，主张革命之后再革命，尽管其主导的“文化大革命”给新中国带来毁灭性的打击，但是仍不能掩盖他的光芒。第二代领导人邓小平作为改革开放的领路人，扭转了中国的发展方向，给中国带来了翻天覆地的改变。第三代领导人是邓小平选拔的江泽民，进一步的加快了中国四个现代化的建设步伐。第四代领导人胡锦涛是一位整合者，为人沉着冷静，思考缜密，面临着城镇化与贫富差距等多项挑战，并作出了一些根本性的改变。第五代领导人习近平能将中国带向何处尚不可知。但是历届领导人都有一个共同的特点就是不露锋芒，保持谦逊。 为了营造和维持一个有利于经济发展的国际环境，中国只寻求和平崛起，绝不称霸。但是在关乎主权和领土完整等原则性问题，中国是丝毫不会退让与妥协的。其中，中日的纠纷在于钓鱼岛归属问题，中美则会出现的最大危机是在台湾问题上。李光耀先生认为随着中国大陆与台湾在经济等多方面的联系日趋紧密，台湾与大陆重新统一只是时间问题，这是任何国家无非阻挡的。 当今的中国，由于经济发展速度过快，以至于社会其他方面没能跟上步伐实现同步发展，意味着高速发展的背后隐藏着各种各样的问题。首先是新一代中国年轻人的观念转变，他们不像经历过战争、革命和改革的老一辈中国人明白和平稳定的珍贵。新一代的年轻人看到的更多是当下中国的强盛，并以这样的姿态自居，这样导致在面对一些国际敏感话题是容易自傲。其次是中国社会贫富差距的进一步加大，以及为了眼前发展经济从而忽略了环境与长远发展，这无疑是国内稳定与经济发展潜在隐患。最后是经济发展将面临瓶颈，最容易实现经济发展的时期已经过去，为了确保今后几十年的经济能持续增长，整个经济战略需要调整。 美国：陷入困境但优势仍在由于中国的崛起以及中国亚洲有着距离上的优势，导致美国在亚太地区的影响力正在削弱。为了应对这一势力格局的变化，打算重新将战略重心移回本区域。除中国之外的其他亚洲国家希望美国持续参与本区域的事务，以平衡中国的影响力，有助于保持亚太区域的稳定和安全。但是美国能否长期履行承诺与美国的未来的经济发展有关系，发挥影响力需要有强大的经济做后盾。 美国的成功在于它活力十足的经济，这活力的来源是一种不可思议的能力，不仅能以更少资源去实现同等的产出，还能不断创新。这使得美国能够始终走在科技前沿，掌握话语权。此外，美国是一个开放自由，且由移民组成的社会，能够吸引并且留住人才。中国在吸引人才方面不如美国的原因之一在于语言问题，比起英语，华语是一门更难掌握的语言。美国竞争力的另一来源，是有许多遍布全国各地并相互竞争的卓越中心，每个中心都认为本身能媲美其他中心，从而构成了美国这样一个多元的社会。而中国则完全不同，中国人相信只有中央强大，中国才能繁荣。最后，美国拥有一种颂扬勇闯天下的文化。对于成功的企业家会获得应有的社会地位和认可，对于创业失败的情况认为是通往终极成功的必要过程，不会因此而受到鄙视。 美国面临着很多严重问题。首先是债务问题。比起一些欧元国家，美国面临的债务问题相对轻微。部分原因在于美元是世界储备货币，这意味着美国享有比其他国家低许多的借贷成本。国会与总统对如何解决债务问题难以达成共识，他们更关注下一届选举。其次，美国公立学校的教育得不到重视，中下层人才的教育问题面临危机，不同于私立学校，公立学校的地方政府拨款受金融危机影响被进一步削减，而联邦政府又不能直接干涉。长久下去，美国的竞争力会逐渐下滑。除此之外，美国面临的问题还包括：基础设施差、阶级鸿沟加剧、种族歧视根深蒂固、拜金主义严重以及繁琐冗长的选举过程。 美国人属于乐观主义，从根本上相信未来会更好，更倾向于提前消费。完全不同于中国和日本人的未雨绸缪。美国作为世界第一强国，乐于担任世界警察的职务，但是有时候确得不偿失，进攻伊拉克和阿富汗就佐证。 欧洲：衰退与分歧欧元困境 欧洲现在有17国家加入欧元，整个欧洲现在处于一种财政没有整合而货币是通一的困境中。不同的欧元国家的财政预算和公民消费习惯差异很大，国家之间的发展速度和经济实力也存在差距，这些不协调因素逐步破坏者欧元一体化制度。欧元面临的困境是一个必然的历史结果。 解决欧元危机，有三个可行的方案。 完全整合。模仿美国建立有一个联邦储备局和一个财政部长，当某个洲出现经济困境，联邦政府会伸出援手，而其他州的民众也视他们为同胞，不会要求偿还。而在欧洲是行不通的，不同国家之间民族差异性大。而且欧洲各国的选民不大愿意将国家的财政大权交给一个中央机关。 欧元解体。每个国家有各自的财政部长并各自自行管理本国货币。当一个国家经济放缓，因为不受限于一种共同货币，可以采用“量化宽松”政策扩大货币供应量，使货币贬值，加大出口吸引力。欧元区国家则没办法采用这样的货币政策来刺激经济复苏。此外欧洲国家出于选举的压力，也不能通过消减福利，改革税收制度，放宽劳动力市场规则或延后退休等措施来加强国家竞争力。 局部解体。这种结局的可能性很多，竞争力相近的国家可组合成一个新共同体，从而分成不同层次的欧洲。每个层次以不同的速度发展。 福利社会和僵化的劳动力市场法律 欧洲走向衰退的另一个原因在于：难以维继的福利制度和僵化的劳动力市场法律。随着二战红利的殆尽和全球化市场经济的发展，欧洲工人的竞争力逐步削弱，工资也自然下降，对社会福利的依赖也越大。福利制度一定制定就很难往下调整，政府处于选举的压力，往往尽力满足民众的要求。 如果说福利开支的维持在一定水平的话，问题或许还可以受到控制。可事实是这类开支的随时间递增的，占国家总收入的比重逐步上升。原因之一民粹主义者要求更多福利。 福利社会最坏的影响，在于它削弱了人们努力奋斗的动力。如果社会保障体系设计成不管一个人努力工作或是悠闲生活都能得到同样的好处，那么努力的工作的意义变得渺小。 欧洲一体化的理想幻灭 欧洲如果能实现一体化，不论从和平的角度还是经济发展的角度都是一个最佳选择。然而现实是欧洲不可能完全融合。首先欧洲国家未能成功的实现货币一体化，更何况实现政治和军队一体化。原因在于欧洲国家都有自己悠久的历史与光荣的传统，并且各自引以为豪。此外，欧洲其他国家也不会接受英语作为唯一的工作语言，因为语言背后有着荣耀和文学，他们都想保留本身的语言。 尽管欧洲在国家的地位和话语权减弱，但是不会对其生活水平造成同等的影响。这片大陆有着高水平的教育和技能，足以让欧洲人过上好生活。个别国家将有些衰退，但会根据自身的竞争力达到一个稳定的状态。 日本，走向平庸关于日本，人口的老龄化加上持续下降的生育率，相较于经济停滞不前和政治领导人虚弱等问题，人口问题成为了日本面临的最大问题。任何社会的经济主力军都是年轻人，年轻人群体的比重逐渐减小，也意味着经济的萎缩。即便是像中国这样的人口大国，在实时计划生育近30年后，随着人口红利的消失，开始出现老龄化和生育率低的问题，于是在2013年放宽生育政策，开发二胎，试图调整和改善社会人口组成结构。由此可见人口问题对经济是多么重要。 日本人口问题的产生原因是多方面的，其中包括： 日本女性的社会角色开始由传统的家庭主妇向现代的职业女性转变 日本企业对女性的包容性差，让职业女性很难兼顾家庭和工作，导致生育成本过高 日本民族的种族纯洁性观念强，日本社会对外国移民极为抗拒，即便是对日侨移民也是如此 即便如此，不可否认日本是一个了不起的民族，公民素质很高，团队精神举世无双。这些特质让日本在未来的一段时间内仍能在世界经济强国中有一席之地。但是日本正在走向平庸也是不争的事实。 朝 韩，偷天换日谈及朝鲜和韩国，绕不开的话题的朝鲜半岛局势。就目前而言，朝鲜半岛局势在可预计的未来不会有什么变化。即不可能和平统一又不可能爆发战争。 和平统一的阻力在于，一方面朝鲜与韩国的经济实力差距悬殊，韩国暂时不愿意为了和平统一而付出巨大的经济利益。而是希望朝鲜能够对外开放，发展经济，在双方差距缩小到一定程度时才考虑和平统一的可行性；另一方面，作为朝鲜邻国的中国不愿意看到朝韩统一，这意味美国可能将会在朝鲜设立军事基地，更近一步的威胁中国。 爆发战争的可能性也几乎为零。一方面尽管朝鲜有核武器，对韩国包括首尔在内的重要城市有直接的杀伤力。但是朝鲜的核武器更多在于巩固金氏政权；另一方面，朝鲜的工业水平与韩国差距太大，即便的真的发动战争也很可能战败。 目前来说，朝鲜的经济仍然停滞不前，国内人民的温饱问题都没能得到解决。韩国则仍然保持经济增长，得益于三星、LG和现代等国际品牌企业。虽然同日本一样面临生育率低和人口老龄化问题，但是韩国愿意接纳外国移民，所以这问题能够得到缓解。 印度：受种性制度羁绊印度是一个由多种族组成的国家，印度境内使用的民族语言多达400种。印度有着中国的人口规模，却不同于中国一样有共同使用的语言：普通话。印度语言环境的多元化无疑是国家管理的一大障碍。 印度从来都不是一个单一性的实体，不同于中国超过90%的人口比例是汉族。因此，我们不能把中国和印度两大文明相提并论。印度不具备中国那样的决心和专一。 这种分离情况也体现在印度的政治体系上。地区的领导人不会按照联邦政府的意志办事，他们的委任来源于百姓的选票。 此外，种姓制度使得印度情况更为复杂，成为了阻碍其发展的另外一个重要的原因。印度分为婆罗门人（僧侣阶级）、吠舍人（平民阶级）和达利人（贱民阶级）。不同的阶级直接等级分明，不能通婚。从宏观的层面来看，种姓制度限制了各阶级的基因库的多样化。 由于印度国内的官僚化和阶级化，导致许多有才干的印度人到国外寻求机遇，并且一去不回，造成人才流失，进一步影响国家发展。 此外，印度的基础建设落后，虽然人口红利优势明显，但是却很难得到国外投资方的青睐。 综上，首先，印度虽然是民主制度，然而却没能体现民主带来的优势。其次，由于印度有着悠久的历史，社会内有一些根本的势力难以改变。印度受制于内部构造结构和种姓制度的束缚，几乎无法挣脱。 马来西亚：分道扬镳在李光耀先生看来，马来西亚和新加坡是同根同生的，当年英国离开时留给两个国家大致相同的遗产，两国在后殖民时期的发展水平也旗鼓相当。可以说两个国家离开殖民统治之后处于同一起跑线。 然而，两个国家的领导人选择两条完全不一样的发展道路。马来西亚放弃了英语选择建立一个以马来语为主的国家，并且是属于马来人的马来西亚。新加坡则选择建立一个以英语为主的多元种族化的国家。正所谓道不同不相为谋，两个国家最终没能结成联盟，分道扬镳。 马来西亚随着马来人的比重越来越重，其他种族的权益得不到保障，从而造成了人才流失严重。马来人的特权已经在马来西亚社会根深蒂固，因为即便是新的领导人有意促进种族和谐加强团结，有意提出一些保障其他种族的权益的举措，但是实际上往往是力不从心，因为他们需要大多数马来人的选票来赢的竞选。 由于马来西亚和新加坡的发展道路截然不同，且均不能改变对方的想法，二者学会了和平相处，接受彼此的不同。 印度尼西亚：偏离中央印度尼西亚是由分散在5000公里范围内的1.75万个岛屿组成，有超过200个民族，是一个多元化的国家。 在哈比比出任印尼总统之前，印尼是全世界政治上最集权的国家之一。苏加诺和苏哈托都依赖于中央集权来管理这个地理上分散的国家。除了利用国家机器镇压叛乱和维持团结之外，苏加诺选择了马来语而非爪哇语作为印尼的官方语言，尽管爪哇族是印尼的主要民族，苏加诺本身是爪哇人，且印尼的经济和文化中心的首都雅加达也位于爪哇岛。这一举措不仅解决了印尼各地区的交流沟通问题，还有利于维护国家团结稳定。 在哈比比担任总统之后，政府开始走地方化道路。中央权力的下方不仅加速了地区经济的发展，也维持了国家统一。然而，地方化是一个不可逆转的过程，一旦权力下放到地方就不可能再收回。 地方化对于印尼是发展是一件好事，但是并不能解决印尼面临的所有问题。除了面对传统的挑战，印尼还需要面对新的挑战。其中包括中央的政治僵局、基础建设的落后和贪污成风的现状。 印尼目前发展虽然良好，但是其本质上是以天然资源为基础的经济体，印尼国民也过于依赖土地的馈赠，而非靠双手谋生。印尼因为其丰富的资源能够吸引国外的巨额投资，从而获得持续的经济增长。然而，自然资源总有耗尽的一天，届时再纠正印尼国民已经养成的闲散的生活态度不是一件容易的事情。 泰国：苏醒的社会底层在他信·西那瓦就任之前，泰国的精英阶层垄断了整个政治局面，执政方针主要以首都的利益为考量。 在他信担任泰国首相之后，将原本被曼谷既得利益集团和中产阶级独占的资源转移到泰国较为贫穷的地区，颠覆了泰国的政治现状。他信为农民提供贷款，给贫困家庭的学生颁发海外奖学金，为城市贫民提供政府津贴的住房，让穷人享受医疗保障。 他信的这些政策严重的威胁和影响到曼谷精英阶层的利益，他信的政府在2006年的军事政变中被推翻。泰国的首都陷入巨大的动荡，主要有两股军事力量相互抗衡，分别是保皇派的黄衫军和支持他信的红杉军。 在泰国，军人向来是扮演者主要的角色。但是随着年轻一代对王室的尊敬日渐减弱，黄衫军的实力也日渐衰退。整个社会还是沿着他信开创的道路继续前进，许多农民加入中产阶级，协助推高国内消费。泰国的发展态势会是良好的。 越南：解不开的社会主义思维枷锁越南同中国一样是一个忠于社会主义道理的国家，在中国改革开放几年之后，越南也决定推行自由市场改革。然而，越南老一辈共产党领袖的思维基本上无法跳出社会主义的枷锁。他们始终都拿不出像中国领导人一样的真正决心，去彻底改变整个制度。 和中国不同，越南没有像邓小平那样既在干部中有不可动摇的崇高地位，又坚信改革是唯一出路的领导人。究其原因在于，在改革开放之前十几年间中国在不断的摸索和积累经验，为改革打下了基础。而此时的越南正与美国进行残酷的越南战争，与此同时很多了解资本主义运行规律的成功商人也纷纷逃离了越南。 越南人是东南亚最能干和精力最充沛的人民之一，但愿在老一代共产党领导人谢世之后，新一代年轻人接班之后，能够肯定自由市场的重要性，让越南进入一个新篇章。 缅甸：将领改变路向缅甸军政府在2011年开始改革，将缅甸从死胡同中挽救过来，然而这种彻底的改变，既不是源于深刻的自我反省或真实的顿悟，也不是一个濒临倒台的独裁政权急于自救的举动，而是别无选择。 对比于有着同样自然资源和气候条件的泰国，通过开发市场变得富裕，缅甸却停滞不前，整个国家固步自封近40年。直到2011年无路可走才选择掉头。","link":"/2018/05/16/%E6%9D%8E%E5%85%89%E8%80%80%E8%A7%82%E5%A4%A9%E4%B8%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"RunLoop","slug":"RunLoop","link":"/tags/RunLoop/"},{"name":"音视频","slug":"音视频","link":"/tags/%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"H264","slug":"H264","link":"/tags/H264/"},{"name":"JS","slug":"JS","link":"/tags/JS/"},{"name":"KVO","slug":"KVO","link":"/tags/KVO/"},{"name":"macOSX","slug":"macOSX","link":"/tags/macOSX/"},{"name":"Category","slug":"Category","link":"/tags/Category/"},{"name":"Objective-C","slug":"Objective-C","link":"/tags/Objective-C/"},{"name":"Coffee","slug":"Coffee","link":"/tags/Coffee/"},{"name":"TCP&#x2F;IP","slug":"TCP-IP","link":"/tags/TCP-IP/"},{"name":"传输协议","slug":"传输协议","link":"/tags/%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/"},{"name":"拥塞控制","slug":"拥塞控制","link":"/tags/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"},{"name":"Cocoa","slug":"Cocoa","link":"/tags/Cocoa/"},{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"三体","slug":"三体","link":"/tags/%E4%B8%89%E4%BD%93/"},{"name":"哲学","slug":"哲学","link":"/tags/%E5%93%B2%E5%AD%A6/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"PlistBuddy","slug":"PlistBuddy","link":"/tags/PlistBuddy/"},{"name":"英语","slug":"英语","link":"/tags/%E8%8B%B1%E8%AF%AD/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"ARC","slug":"ARC","link":"/tags/ARC/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"时序模型","slug":"时序模型","link":"/tags/%E6%97%B6%E5%BA%8F%E6%A8%A1%E5%9E%8B/"},{"name":"经济","slug":"经济","link":"/tags/%E7%BB%8F%E6%B5%8E/"},{"name":"UTC","slug":"UTC","link":"/tags/UTC/"},{"name":"Swift","slug":"Swift","link":"/tags/Swift/"},{"name":"Runtime","slug":"Runtime","link":"/tags/Runtime/"},{"name":"人类简史","slug":"人类简史","link":"/tags/%E4%BA%BA%E7%B1%BB%E7%AE%80%E5%8F%B2/"},{"name":"GCD","slug":"GCD","link":"/tags/GCD/"},{"name":"传记","slug":"传记","link":"/tags/%E4%BC%A0%E8%AE%B0/"}],"categories":[{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"Cocoa","slug":"编程/Cocoa","link":"/categories/%E7%BC%96%E7%A8%8B/Cocoa/"},{"name":"C++","slug":"编程/C","link":"/categories/%E7%BC%96%E7%A8%8B/C/"},{"name":"音视频","slug":"编程/音视频","link":"/categories/%E7%BC%96%E7%A8%8B/%E9%9F%B3%E8%A7%86%E9%A2%91/"},{"name":"JS","slug":"编程/JS","link":"/categories/%E7%BC%96%E7%A8%8B/JS/"},{"name":"macOSX","slug":"编程/macOSX","link":"/categories/%E7%BC%96%E7%A8%8B/macOSX/"},{"name":"Objective-C","slug":"编程/Objective-C","link":"/categories/%E7%BC%96%E7%A8%8B/Objective-C/"},{"name":"随想","slug":"随想","link":"/categories/%E9%9A%8F%E6%83%B3/"},{"name":"TCP&#x2F;IP","slug":"编程/TCP-IP","link":"/categories/%E7%BC%96%E7%A8%8B/TCP-IP/"},{"name":"WebRTC","slug":"编程/WebRTC","link":"/categories/%E7%BC%96%E7%A8%8B/WebRTC/"},{"name":"iOS","slug":"编程/iOS","link":"/categories/%E7%BC%96%E7%A8%8B/iOS/"},{"name":"书评","slug":"书评","link":"/categories/%E4%B9%A6%E8%AF%84/"},{"name":"影评","slug":"影评","link":"/categories/%E5%BD%B1%E8%AF%84/"},{"name":"数据结构","slug":"编程/数据结构","link":"/categories/%E7%BC%96%E7%A8%8B/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Xcode","slug":"编程/Xcode","link":"/categories/%E7%BC%96%E7%A8%8B/Xcode/"},{"name":"英语","slug":"英语","link":"/categories/%E8%8B%B1%E8%AF%AD/"},{"name":"汇编","slug":"编程/汇编","link":"/categories/%E7%BC%96%E7%A8%8B/%E6%B1%87%E7%BC%96/"},{"name":"OpevCV","slug":"编程/OpevCV","link":"/categories/%E7%BC%96%E7%A8%8B/OpevCV/"},{"name":"Hexo","slug":"编程/Hexo","link":"/categories/%E7%BC%96%E7%A8%8B/Hexo/"},{"name":"算法","slug":"编程/算法","link":"/categories/%E7%BC%96%E7%A8%8B/%E7%AE%97%E6%B3%95/"},{"name":"Swift","slug":"编程/Swift","link":"/categories/%E7%BC%96%E7%A8%8B/Swift/"}]}